{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e62d23-ca7e-4c4d-8ea7-08cddb8f12ab",
   "metadata": {},
   "source": [
    "======FairFed============\n",
    "\n",
    "-> Init Models for clients\n",
    "\n",
    "-> Get statistics of the dataset\n",
    "\n",
    "-> start training\n",
    "\n",
    "      -> for each round-> assigning agg global model to all clients\n",
    "\n",
    "-> for each client\n",
    "\n",
    "        > Update its weights based on local and global fairness\n",
    "        \n",
    "        > store it\n",
    "-> SecAgg applied on the server side\n",
    "\n",
    "Total data for weights: WM + WW + BM + BW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae9b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import glob\n",
    "import sys, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from folktables import ACSDataSource, ACSEmployment,ACSIncome\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from scipy.stats import multivariate_normal\n",
    "import torch, random, copy, os\n",
    "from collections import OrderedDict\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23e284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e8550ad",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a70374e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "else:\n",
    "    # CUDA is not available\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6badffcd-029a-47e7-9d4e-40b52d32b39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4eb7f6d-5757-494b-8d6a-1192058aee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 14 : input shape\n",
    "        # 9-> we have 9 columns in data \n",
    "        self.layer1 = nn.Linear(14, 512)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(256, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e6ddc-37c5-4a04-ba53-7215bb513904",
   "metadata": {},
   "source": [
    "# assigning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b03167-c1a8-48ce-887b-80a9d50f7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignModel:\n",
    "    def __init__(self, global_model_base_path, selected_clients,algo=\"FF\"):      \n",
    "        self.global_model_path = f\"{global_model_base_path}/global_model_{algo}_OE.pt\"\n",
    "        self.selected_clients = selected_clients\n",
    "\n",
    "    def save_global_model(self, model):\n",
    "        torch.save(model.state_dict(), self.global_model_path)\n",
    "\n",
    "    def save_client_models(self, model):\n",
    "        for client_id in self.selected_clients:\n",
    "            client_model_path = f\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/client_{client_id}_model.pth\"\n",
    "            torch.save(model.state_dict(), client_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52352bb-381e-4af7-baf1-e5900e214c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a24c1cb2-bf5f-4164-a4d5-9251d6358acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, batch_size):\n",
    "        self.client_id: int = None\n",
    "        self.valset: DataLoader = None\n",
    "        self.trainset: DataLoader = None\n",
    "        self.testset: DataLoader = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")         \n",
    "        self.model = DeepNet().to(self.device)\n",
    "        self.learning_rate=0.001\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "        self.optimizer: torch.optim.Optimizer = torch.optim.Adam(\n",
    "            self.model.parameters(), lr=self.learning_rate\n",
    "        )\n",
    "        \n",
    "        self.Batch = batch_size\n",
    "        self.fainess_score=0\n",
    "        self.local_epochs=5\n",
    "        self.client_df = pd.DataFrame()\n",
    "        self.selected_clients=[0,1,2,3]\n",
    "\n",
    "        self.client_fairness=0\n",
    "        self.global_fairness=0\n",
    "        \n",
    "        self.model_dir=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "\n",
    "        #data_random_split_fairFed\n",
    "        #data_fairFed\n",
    "        self.data_dir=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/data_subGsplit_fairFed/\"\n",
    "        \n",
    "    def get_client_local_dataset(self):                \n",
    "        \n",
    "        with open( self.data_dir+\"/clients_training.pkl\", \"rb\") as f:\n",
    "            self.trainset = pickle.load(f)\n",
    "            \n",
    "        with open( self.data_dir+\"/clients_validation.pkl\", \"rb\") as f:\n",
    "            self.valset = pickle.load(f)\n",
    "         \n",
    "        with open( self.data_dir+\"/clients_testing_wrong.pkl\", \"rb\") as f:\n",
    "            self.testset  = pickle.load(f)\n",
    "\n",
    "        self.trainset = self.trainset[self.client_id]\n",
    "        self.valset = self.valset[self.client_id]       \n",
    "        self.testset = self.testset[self.client_id]\n",
    "\n",
    "    def get_stats(self):\n",
    "        # 1 male 0 female\n",
    "        total_pr_Y1_A0 = 0\n",
    "        total_pr_Y1_A1 = 0\n",
    "        len_of_entire_data=0\n",
    "        \n",
    "        for client_id in self.selected_clients:\n",
    "            self.client_id=client_id\n",
    "            self.get_client_local_dataset()\n",
    "            len_of_entire_data+=len(self.trainset.dataset)\n",
    "            for inputs, labels, A in self.trainset:\n",
    "                pr_Y1_A1 = torch.sum((labels == 1) & (A == 1)).item()\n",
    "                pr_Y1_A0 = torch.sum((labels == 1) & (A == 0)).item()\n",
    "                # len_of_entire_data+=len(self.trainset)\n",
    "                total_pr_Y1_A1 += pr_Y1_A1\n",
    "                total_pr_Y1_A0 += pr_Y1_A0\n",
    "                \n",
    "            # print(\"len_of_entire_data::\",len_of_entire_data)\n",
    "            # print(\"pr_Y1_A1 and pr_Y1_A0\",total_pr_Y1_A1,\"::\",total_pr_Y1_A0)\n",
    "            # print(total_pr_Y1_A0/len(self.trainset),\" , \",print(total_pr_Y1_A1/len(self.trainset)))        \n",
    "        \n",
    "        return [total_pr_Y1_A1/len_of_entire_data,total_pr_Y1_A0/len_of_entire_data]\n",
    "        \n",
    "    def calculate_fairness_client(self,client_id,y_hat, A, Y,server_acc,client_acc,len_client_data):\n",
    "        # Calculate counts using torch.sum\n",
    "        y_hat, A, Y = y_hat.to(self.device), A.to(self.device), Y.to(self.device)\n",
    "\n",
    "        # 1: Male, 0: Female\n",
    "        predict_Y_male = torch.sum((y_hat[(A == 1) & (Y == 1)] == 1)).item()\n",
    "        predict_Y_female = torch.sum((y_hat[(A == 0) & (Y == 1)] == 1)).item()\n",
    "        \n",
    "        count_Y_male = torch.sum((Y[(A == 1) & (Y == 1)] == 1)).item()\n",
    "        count_Y_female = torch.sum((Y[(A == 0) & (Y == 1)] == 1)).item()\n",
    "    \n",
    "        \n",
    "        fairness_score=0\n",
    "        #this assingment could be wrong\n",
    "        prob_Y_male=0\n",
    "        prob_Y_female=0\n",
    "        diff_of_acc=0\n",
    "        # Calculate probabilities\n",
    "        if count_Y_male > 0: \n",
    "            prob_Y_male = predict_Y_male / count_Y_male\n",
    "            \n",
    "        elif count_Y_female > 0:\n",
    "            prob_Y_female = predict_Y_female / count_Y_female\n",
    "\n",
    "        else:\n",
    "            # Cal sever_acc from client using Eq.\n",
    "            total_len_data=sum(len_client_data)   \n",
    "            temp_server_acc=0\n",
    "            # get global acc\n",
    "            for i in range(len(self.selected_clients)):\n",
    "                temp_server_acc+=client_acc[i]*(len_client_data[i]/total_len_data)\n",
    "                \n",
    "            diff_of_acc = abs(client_acc[client_id]-temp_server_acc)\n",
    "            \n",
    "        fairness_score = prob_Y_male - prob_Y_female\n",
    "        # print(\"\\n  fairness_score\",fairness_score)\n",
    "            \n",
    "        # print(\" client fairness_score\",fairness_score)\n",
    "            \n",
    "        return  fairness_score,diff_of_acc\n",
    "\n",
    "    def calculate_ser_fairness(self,client_id,y_hat, A, Y,statistics,server_acc,client_acc,len_client_data):\n",
    "        # print(\"calculate_ser_fairness statistics\",statistics)\n",
    "        y_hat, A, Y = y_hat.to(self.device), A.to(self.device), Y.to(self.device)\n",
    "\n",
    "        # for individual clients!\n",
    "        #Pr(Ŷ=1|A=1, Y=1)  #male      \n",
    "        predict_Y_male = torch.sum((y_hat[(A == 1) & (Y == 1)] == 1)).item() #get total\n",
    "        #Pr(A=0, Y=1)\n",
    "        count_Y_male = torch.sum((A == 1) & (Y == 1)).item() \n",
    "        count_male = torch.sum(A == 1).item()\n",
    "        \n",
    "\n",
    "        #Pr(Ŷ=1|A=0, Y=1)  #Female      \n",
    "        predict_Y_female = torch.sum((y_hat[(A == 0) & (Y == 1)] == 1)).item()  #get total\n",
    "        #Pr(A=1, Y=1)\n",
    "        count_Y_female = torch.sum((A == 0) & (Y == 1)).item()\n",
    "        count_female = torch.sum(A == 0).item()\n",
    "        \n",
    "        if count_Y_male>0 and count_male>0:\n",
    "            # print(\"if_male\")\n",
    "            step_2_eq_male=count_Y_male/count_male            \n",
    "            predict_Y_male=predict_Y_male/count_Y_male #Pr(Ŷ=1|A=0, Y=1)            \n",
    "            step_3_male=((predict_Y_male * step_2_eq_male)/statistics[0]) \n",
    "        else:\n",
    "            # print(\"else_male\")\n",
    "            step_3_male=0\n",
    "            \n",
    "        if count_Y_female>0 and count_female>0 :\n",
    "            # print(\"if_female\")\n",
    "            step_2_eq_female=count_Y_female/count_female\n",
    "            predict_Y_female=predict_Y_female/count_Y_female   #Pr(Ŷ=1|A=1, Y=1)\n",
    "            step_3_female= ((predict_Y_female * step_2_eq_female)/statistics[1])\n",
    "        else:\n",
    "            # print(\"else_female\")\n",
    "            step_3_female=0\n",
    "\n",
    "        temp_fairness_server=step_3_male-step_3_female\n",
    "            \n",
    "        return temp_fairness_server\n",
    "\n",
    "    def get_client_weights(self):        \n",
    "        # self.client_id = client_id\n",
    "        \n",
    "        clients_weights=[]\n",
    "        clients_weights_val=[]\n",
    "        for client_id in self.selected_clients:\n",
    "            self.client_id=client_id\n",
    "            self.get_client_local_dataset()\n",
    "            clients_weights.append(len(self.trainset.dataset))\n",
    "            clients_weights_val.append(len(self.valset.dataset))\n",
    "\n",
    "        return clients_weights,clients_weights_val\n",
    "        \n",
    "    def train_FA(self, client_id: int, model_path,learning_rate=0.001,num_epochs=5):\n",
    "        self.model.load_state_dict(torch.load(model_path,map_location=self.device))\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"epoch\",epoch)\n",
    "            for x, y,z in self.trainset:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                logits = self.model(x)\n",
    "                loss = self.criterion(logits, y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "        # models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "        model_path_1 = os.path.join(self.model_dir, f\"client_{client_id}_model.pth\")          \n",
    "        torch.save(self.model.state_dict(), model_path_1)\n",
    "        print(f\"client_{client_id} is updated \\n\\n\\n\" )\n",
    "                \n",
    "        return list(self.model.state_dict().values()), len(self.trainset.dataset)\n",
    "       \n",
    "        \n",
    "    def train_FF(self, client_id: int, model_path,statistics,server_acc,clients_acc,len_client_data, num_epochs=5, learning_rate=0.001):\n",
    "        self.client_id = client_id\n",
    "        self.get_client_local_dataset()\n",
    "        # print(\"len_of_entire_data FF\",len(self.trainset))\n",
    "        # Define loss function and optimizer\n",
    "        \n",
    "        self.fainess_score=0\n",
    "      \n",
    "        self.model.load_state_dict(torch.load(model_path,map_location=self.device))\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            # Set the model to training mode\n",
    "\n",
    "            for inputs, labels, sens in self.trainset:\n",
    "                \n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs).to(self.device)\n",
    "                loss = self.criterion(outputs, labels.float())\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # Calculate and print the training accuracy for this epoch (optional)\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            size = 0\n",
    "            loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            predicted_labels = []\n",
    "            true_labels = []\n",
    "            final_fairness=[]\n",
    "            final_fairness_server=[]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                print(\"======Validation========\")\n",
    "                for inputs, labels,sens in self.valset:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    outputs = self.model(inputs)\n",
    "                    loss += self.criterion(outputs, labels)\n",
    "                    predicted = outputs > 0.5\n",
    "\n",
    "                    predicted_labels.extend(predicted.cpu().numpy())\n",
    "                    true_labels.extend(labels.cpu().numpy())                   \n",
    "                    \n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()                   \n",
    "\n",
    "            loss = loss / len(self.valset)        \n",
    "            acc = correct/total\n",
    " \n",
    "            fairNess_per_batch,diff_of_acc=self.calculate_fairness_client(self.client_id,torch.round(outputs).squeeze(), sens.squeeze(), labels.squeeze(),\n",
    "                                                       server_acc,\n",
    "                                                       clients_acc,\n",
    "                                                       len_client_data)\n",
    "            final_fairness.append(fairNess_per_batch)\n",
    "            self.fainess_score=np.mean(final_fairness)\n",
    "\n",
    "            #this is needed for Eq.7: global fairness\n",
    "            fairNess_per_batch_server=self.calculate_ser_fairness(self.client_id,torch.round(outputs).squeeze(), sens.squeeze(), labels.squeeze(),\n",
    "                                                                  statistics,\n",
    "                                                                  server_acc,\n",
    "                                                                  clients_acc,\n",
    "                                                                  len_client_data)\n",
    "            final_fairness_server.append(fairNess_per_batch_server)            \n",
    "            ser_score=np.mean(final_fairness_server)\n",
    "                        \n",
    "            precision = precision_score(true_labels, predicted_labels,zero_division=0.0)            \n",
    "            recall = recall_score(true_labels, predicted_labels)\n",
    "            \n",
    "            # accuracy = 100 * correct / total\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Val Accuracy: {acc:.5f}, Val Fairness: {self.fainess_score:.5f}, Val Recall: {recall:.5f}\")\n",
    "\n",
    "            # print(f\"Epoch {epoch+1}/{num_epochs}, Val Accuracy: {acc:.5f}\")\n",
    "            # print(f\"Epoch {epoch+1}/{num_epochs}, Val Fairness: {self.fainess_score:.5f}\")\n",
    "            # print(f\"Epoch {epoch+1}/{num_epochs}, Val Recall: {recall:.5f}\")\n",
    "\n",
    "\n",
    "        # Optionally, save the trained model parameters\n",
    "        #store model client model\n",
    "        # models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "        model_path_1 = os.path.join(self.model_dir, f\"client_{client_id}_model.pth\")          \n",
    "        torch.save(self.model.state_dict(), model_path_1)\n",
    "        print(f\"client_{client_id} is updated and its fairness score wrt global_model {ser_score} \\n\\n\\n\" )\n",
    "\n",
    "        \n",
    "        return list(self.model.state_dict().values()), len(self.trainset.dataset),self.model.state_dict(), self.fainess_score, ser_score\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def client_evaluate(self, val=False):\n",
    "        \n",
    "        size = 0\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "        len_of_data=[]\n",
    "        all_client_acc=[]\n",
    "        \n",
    "        # models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "                 \n",
    "        for client_id in self.selected_clients:\n",
    "            \n",
    "            # to get the client specific split\n",
    "            \n",
    "            self.client_id=client_id\n",
    "            self.get_client_local_dataset()\n",
    "            \n",
    "            model_path = os.path.join(self.model_dir, f\"client_{client_id}_model.pth\")            \n",
    "        \n",
    "            self.model.load_state_dict(torch.load(model_path,map_location=self.device))\n",
    "\n",
    "            self.model.eval()\n",
    "\n",
    "            # for inputs, targets,sens in self.testset:\n",
    "            for inputs, targets,sens in self.valset:\n",
    "                \n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                loss += self.criterion(outputs, targets)\n",
    "                predicted = outputs > 0.5\n",
    "                \n",
    "                predicted_labels.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(targets.cpu().numpy())\n",
    "                \n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "                \n",
    "                len_of_data.append(len(self.testset))\n",
    "            \n",
    "            loss = loss / len(self.testset)\n",
    "            acc = correct / total\n",
    "            all_client_acc.append(acc)\n",
    "                        \n",
    "            precision = precision_score(true_labels, predicted_labels,zero_division=0.0)\n",
    "            \n",
    "            recall = recall_score(true_labels, predicted_labels)\n",
    "                            \n",
    "        return loss, acc, precision, recall,len_of_data, all_client_acc\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def server_evaluate(self,path,statistics,all_client_acc,len_of_data):\n",
    "\n",
    "        # print(\"Global Model testing Starts\")\n",
    "        # print(\"kindly check the Path. Select it based on FedAvg Model\")\n",
    "        # print(\"warning: Test data has already been used\")\n",
    "        # temp_path_data=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/\"\n",
    "\n",
    "        with open(self.data_dir+\"/server_testing_client.pkl\", \"rb\") as f:\n",
    "            testset  = pickle.load(f)\n",
    "                    \n",
    "        # path=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model_2.pt\"\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(path,map_location=self.device))\n",
    "        self.model.eval()\n",
    "        size = 0\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "        final_fairness=[]\n",
    "\n",
    "        self.testset=testset[1]\n",
    "        for inputs, targets,sens in self.testset:\n",
    "            \n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "            \n",
    "            outputs = self.model(inputs)\n",
    "            loss += self.criterion(outputs, targets)\n",
    "            predicted = outputs > 0.5\n",
    "            \n",
    "#            print(\"predicted\",predicted)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(targets.cpu().numpy())\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "        \n",
    "        loss = loss / len(self.testset)\n",
    "        ser_acc = correct / total\n",
    "        \n",
    "        fairNess_per_batch=self.calculate_ser_fairness(self.client_id,torch.round(outputs).squeeze(), sens.squeeze(),\n",
    "                                                                   targets.squeeze(),\n",
    "                                                                  statistics,\n",
    "                                                                  ser_acc,\n",
    "                                                                  all_client_acc,\n",
    "                                                                  len_of_data)\n",
    "\n",
    "        final_fairness.append(fairNess_per_batch)\n",
    "        fairness_global=np.mean(final_fairness)\n",
    "\n",
    "        # print(\"loss: %f\\n\" % (loss))\n",
    "        \n",
    "        # print(f\"Global Testing Accuracy: {ser_acc:.5%}\")\n",
    "        # print(f\" Global Fairness: {fairness_global:.5f}%\")\n",
    "        precision = precision_score(true_labels, predicted_labels,zero_division=0.0)\n",
    "        recall = recall_score(true_labels, predicted_labels)\n",
    "        \n",
    "        # print(f\"Global Precision: {precision:.5%}\")\n",
    "        # print(f\"Global Recall: {recall:.5%}\")\n",
    "        \n",
    "        return loss, ser_acc, precision, recall,fairness_global\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b458637-f192-4be8-b5eb-9f20e7ce4e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199eb51c-d78b-44f1-86b0-e8b325ce899c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Serverbase:\n",
    "    def __init__ (self,model,beta):\n",
    "        self.beta=beta\n",
    "        self.model = model\n",
    "        self.global_model=model\n",
    "        self.num_rounds=2\n",
    "        self.local_epoch=2\n",
    "        self.optimizer=2\n",
    "        self.lr=0.001\n",
    "        \n",
    "        self.batch_size=32\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    \n",
    "        self.updated_params_cache = []\n",
    "        self.weights_cache = []\n",
    "        self.weights_total_cache=[]\n",
    "        self.model_dict = []\n",
    "        \n",
    "        self.global_params_dict: OrderedDict[str : torch.Tensor] = None\n",
    "\n",
    "        self.backbone=DeepNet\n",
    "        _dummy_model = self.backbone()\n",
    "        self.global_params_dict = OrderedDict(_dummy_model.state_dict())\n",
    "\n",
    "        self.temp_dir=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "\n",
    "        self.fair_global_t_step=0\n",
    "        self.fair_local_client=0   \n",
    "        \n",
    "        self.acc_clients=[]\n",
    "        self.clients_id=[]\n",
    "        self.precision_clients=[]\n",
    "        self.recall_clients=[]\n",
    "        \n",
    "        self.global_acc=0\n",
    "        self.fairness_diff=[]\n",
    "        self.clients_weights=[]\n",
    "        self.final_agg_weights_clients=[]\n",
    "        self.selected_clients=[0,1,2,3]\n",
    "        self.statistics=0\n",
    "        self.clients_weights=[]\n",
    "\n",
    "    def global_fairness(self,weights, temp_ser_fairness): \n",
    "        # all_clients_fairness is based on equation: 7\n",
    "        # upper part is done in client class\n",
    "        # self.statistics cal. pr(y=1,a=0)\n",
    "        \n",
    "        # print(\"global_fairness::\",all_clients_fairness)\n",
    "        # print(\"weights::\",weights)\n",
    "        \n",
    "        weight_sum = sum(weights)  \n",
    "        final_global_score=0\n",
    "        \n",
    "        for i in range(len(temp_ser_fairness)):\n",
    "            temp=weights[i]/weight_sum            \n",
    "            final_global_score+=temp*temp_ser_fairness[i]\n",
    "            \n",
    "        self.fair_global=final_global_score\n",
    "\n",
    "    \n",
    "        \n",
    "    def fedAlgo(self, num_rounds = 2, local_epochs = 2, learning_rate = 0.001, optimizer = 'adam',algo=\"FF\"):\n",
    "        \n",
    "        client = Client(batch_size=64)\n",
    "       \n",
    "        model_path=os.path.join(self.temp_dir, f\"global_model_{algo}_OE.pt\") \n",
    "         \n",
    "        #before we start the training, we need statistics\n",
    "        print(\"Getting data statistics....\")\n",
    "        self.statistics= client.get_stats()      \n",
    "        \n",
    "        print(\"self.statistics\",self.statistics)\n",
    "\n",
    "        #validation total  weights_cache = WW+ WM+ BM+ BW\n",
    "        self.weights_total_cache, self.weights_cache=client.get_client_weights()\n",
    "        \n",
    "        # weight_sum = sum(self.weights_cache)  \n",
    "        # self.weights_cache =  weight_sum/torch.tensor(self.weights_cache, device=self.device)\n",
    "        \n",
    "        # self.weights_total_cache, self.weights_cache=client.get_client_weights()\n",
    "        \n",
    "        \n",
    "        for round_ in tqdm(range(num_rounds)):\n",
    "  \n",
    "            #each round we need empty lists\n",
    "            self.updated_params_cache = []\n",
    "            # self.weights_cache = []\n",
    "            self.model_dict=[]\n",
    "            self.clients_weights=[]\n",
    "            self.final_agg_weights_clients=[]\n",
    "            self.fair_global=0\n",
    "            self.fair_local_all_client=[]\n",
    "            temp_ser_fairness=[]\n",
    "\n",
    "            print (\"round::\",round_)\n",
    "            \n",
    "             # clients and server acc for calculating Fairness whenever fairness_client is undefined\n",
    "        \n",
    "            loss_client, acc_client,precision, recall,len_of_data,all_client_acc = client.client_evaluate() \n",
    "\n",
    "            # to ge the acc of global model \n",
    "            loss_client, accuracy_server, pre_server, recall_ser,fairness_global = client.server_evaluate(model_path,self.statistics,all_client_acc,len_of_data)\n",
    "\n",
    "            # print(\"all_client_acc:: \", all_client_acc)\n",
    "            # print(\"self.weights_cache:\",self.weights_cache)\n",
    "            \n",
    "            # print(\"self.weights_total_cache:\",self.weights_total_cache)\n",
    "            temp_global_acc = [acc * (weight / sum(self.weights_cache)) for acc, weight in zip(all_client_acc, self.weights_cache)]\n",
    "            self.global_acc=sum(temp_global_acc)   \n",
    "            self.acc_clients= all_client_acc\n",
    "            \n",
    "            for client_id in self.selected_clients:\n",
    "                            \n",
    "                \n",
    "                # weight is length of dataset\n",
    "                \n",
    "                # Clone the model from server and assign it back to the clients                 \n",
    "\n",
    "                if algo==\"FF\":\n",
    "                    \n",
    "                    updated_params, weight, model_dict_list,fairness_client,ser_fairness = client.train_FF(client_id, \n",
    "                                                                                                             model_path, \n",
    "                                                                                                             statistics=self.statistics,\n",
    "                                                                                                             server_acc=accuracy_server,\n",
    "                                                                                                             clients_acc=all_client_acc,\n",
    "                                                                                                             len_client_data=len_of_data,\n",
    "                                                                                                             num_epochs=local_epochs, \n",
    "                                                                                                             learning_rate=learning_rate)        \n",
    "                                \n",
    "                    \n",
    "                    self.updated_params_cache.append(updated_params)\n",
    "                    #not sure how to pass updated weights to next round\n",
    "                    # self.weights_cache.append(weight)\n",
    "                    self.model_dict.append(model_dict_list)\n",
    "                    temp_ser_fairness.append(ser_fairness)\n",
    "                                        \n",
    "                    # self.global_acc=acc_server\n",
    "                    self.fair_local_client=fairness_client\n",
    "                    self.fair_local_all_client.append(fairness_client)\n",
    "                \n",
    "                if algo==\"FA\":\n",
    "                    updated_params, weight, = client.train_FA(client_id, model_path,\n",
    "                                                              num_epochs=local_epochs,\n",
    "                                                              learning_rate=learning_rate)\n",
    "                                                                                            \n",
    "                                \n",
    "                    # store it for SecAgg\n",
    "                    self.updated_params_cache.append(updated_params)\n",
    "                    # self.weights_cache.append(weight)\n",
    "                    \n",
    "\n",
    "            # print(\"temp_ser_fairness::\",temp_ser_fairness)\n",
    "            # print(\"global self.weights_cache::\",self.weights_cache)\n",
    "            self.global_fairness(self.weights_cache, temp_ser_fairness)\n",
    "\n",
    "            print(\"for round\", round_,\", global fairness, accuracy, and recall are: \",self.fair_global,\", \",\n",
    "                                                                                  accuracy_server,\", \",\n",
    "                                                                                  recall_ser,\"\\n\\n\\n\")\n",
    "            \n",
    "            if algo==\"FF\":\n",
    "                # agg all the weights on serverside\n",
    "                # Update the weights of each client\n",
    "                self.aggregate_client_weight_FedFair_FedAVG(self.updated_params_cache,self.model_dict, self.weights_cache,self.acc_clients,\n",
    "                                                            self.global_acc,self.fair_local_client,\n",
    "                                                             self.fair_global, self.fair_local_all_client)\n",
    "                \n",
    "                \n",
    "            elif algo==\"FA\":\n",
    "                self.aggregate_parameters_FedAvg(self.updated_params_cache,self.weights_cache)\n",
    "            else:\n",
    "                print(\"--Choose Algo --\")\n",
    "                break\n",
    "        \n",
    "            \n",
    "            torch.save(self.global_model.state_dict(), os.path.join(self.temp_dir, f\"global_model_{algo}_OE.pt\"),)\n",
    "\n",
    "            \n",
    "    @torch.no_grad()\n",
    "    def aggregate_parameters_FedAvg(self, updated_params_cache, weights_cache):\n",
    "        \n",
    "        weight_sum = sum(weights_cache)          \n",
    "        weights = torch.tensor(weights_cache, device=self.device) / weight_sum\n",
    "\n",
    "        print(\"weight\",weights)\n",
    "        \n",
    "        aggregated_params = []\n",
    "\n",
    "        for params in zip(*updated_params_cache):\n",
    "            aggregated_params.append(\n",
    "                torch.sum(weights * torch.stack(params, dim=-1), dim=-1)\n",
    "            )\n",
    "        \n",
    "        aggregated_model_params = {}\n",
    "        global_state_dict_keys = list(self.global_model.state_dict().keys())\n",
    "        \n",
    "        for param_name, param_value in zip(global_state_dict_keys, aggregated_params):\n",
    "            aggregated_model_params[param_name] = param_value\n",
    "\n",
    "\n",
    "        # aggregated_model_params = {param_name: param_value for param_name, param_value in zip(self.global_model.state_dict().keys(), aggregated_params)}\n",
    "\n",
    "        self.global_model.load_state_dict(aggregated_model_params)\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def aggregate_client_weight_FedFair_FedAVG (self,updated_params_cache, model_dict_list ,weights_cache, acc_clients, global_acc,fairness_client,fairness_global,fairness_all_client):\n",
    "\n",
    "        # weights = torch.tensor(weights_cache, device=self.device) / weight_sum\n",
    "\n",
    "        # print(\"client and G acc\",acc_clients,\" :: \", global_acc)\n",
    "        # weight_sum = sum(weights_cache)  \n",
    "\n",
    "        # temp=self.weights_cache\n",
    "        # temp_list=[]\n",
    "        # print(\" Init weights::\",weights_cache)\n",
    "        print(\"Before weights-1 (W/w):: \",self.weights_cache)\n",
    "        \n",
    "        weight_sum = sum(self.weights_cache)  \n",
    "        # weights =  weight_sum/torch.tensor(self.weights_cache, device=self.device)\n",
    "        self.weights_cache =  weight_sum/torch.tensor(self.weights_cache, device=self.device)\n",
    "        \n",
    "        print(\"Before weights -2 (W/w):: \",self.weights_cache)       \n",
    "        # mean_fairness=np.mean(fairness_all_client)\n",
    "        mean_acc=np.mean(acc_clients)                \n",
    "        \n",
    "        for i in range(len(self.weights_cache)):\n",
    "            # Delta_t_C_i=abs(self.fair_global-fairness_all_client[i])\n",
    "            # self.weights_cache[i]=temp[i]-self.beta*(Delta_t_C_i-mean_fairness)\n",
    "            Delta_t_C_i=abs(global_acc-acc_clients[i])\n",
    "            self.weights_cache[i]=self.weights_cache[i]-self.beta*abs(mean_acc-Delta_t_C_i)\n",
    "                  \n",
    "        print(\"After weights_:: \",self.weights_cache)\n",
    "        \n",
    "        # weights_cache=self.weights_cache\n",
    "        weight_sum_2 = sum(self.weights_cache)  \n",
    "        weights = torch.tensor(self.weights_cache, device=self.device) / weight_sum_2\n",
    "\n",
    "        print(\"After weights_ Prob:: \",weights)\n",
    "        \n",
    "        aggregated_params = []\n",
    "\n",
    "        for params in zip(*updated_params_cache):\n",
    "            aggregated_params.append(\n",
    "                torch.sum(weights * torch.stack(params, dim=-1), dim=-1)\n",
    "            )\n",
    "        \n",
    "        aggregated_model_params = {}\n",
    "        global_state_dict_keys = list(self.global_model.state_dict().keys())\n",
    "        \n",
    "        for param_name, param_value in zip(global_state_dict_keys, aggregated_params):\n",
    "            aggregated_model_params[param_name] = param_value\n",
    "\n",
    "        self.global_model.load_state_dict(aggregated_model_params)\n",
    "  \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def aggregate_parameters_FedAvg_updated(self, model_dict_list):        \n",
    "        w_avg = copy.deepczopy(model_dict_list[0])\n",
    "        for k in w_avg.keys():\n",
    "            for i in range(1, len(model_dict_list)):\n",
    "                w_avg[k] += model_dict_list[i][k]\n",
    "            w_avg[k] = torch.div(w_avg[k], len(model_dict_list))\n",
    "    \n",
    "        self.global_model.load_state_dict(w_avg)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf995c8-5238-44f1-aa4d-e927101b0a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb97600f-7474-47ae-bd82-89bcad80e6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm is  FF\n",
      "Getting data statistics....\n",
      "self.statistics [0.21462357114702404, 0.1967327990189638]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                        | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:: 0\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.77273, Val Fairness: 0.85714, Val Recall: 0.66525\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.77987, Val Fairness: 0.85714, Val Recall: 0.72063\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.78247, Val Fairness: 0.71429, Val Recall: 0.69507\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.79437, Val Fairness: 0.85714, Val Recall: 0.70237\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.80303, Val Fairness: 0.85714, Val Recall: 0.73828\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.80368, Val Fairness: 0.71429, Val Recall: 0.66038\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.80346, Val Fairness: 0.85714, Val Recall: 0.70055\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.81126, Val Fairness: 0.85714, Val Recall: 0.78271\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.80649, Val Fairness: 0.85714, Val Recall: 0.80767\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.80931, Val Fairness: 0.71429, Val Recall: 0.67985\n",
      "client_0 is updated and its fairness score wrt global_model 1.9413835322926234 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.76015, Val Fairness: -0.68000, Val Recall: 0.77209\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.77034, Val Fairness: -0.68000, Val Recall: 0.67793\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.77580, Val Fairness: -0.76000, Val Recall: 0.76968\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.76633, Val Fairness: -0.84000, Val Recall: 0.84307\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.78417, Val Fairness: -0.84000, Val Recall: 0.76775\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.78380, Val Fairness: -0.68000, Val Recall: 0.70304\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.78417, Val Fairness: -0.64000, Val Recall: 0.71801\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.78999, Val Fairness: -0.64000, Val Recall: 0.73346\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.78562, Val Fairness: -0.80000, Val Recall: 0.80734\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.78944, Val Fairness: -0.76000, Val Recall: 0.76871\n",
      "client_1 is updated and its fairness score wrt global_model -1.7559580668663481 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.79831, Val Fairness: 0.81818, Val Recall: 0.78757\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.80692, Val Fairness: 0.81818, Val Recall: 0.81417\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.80883, Val Fairness: 0.90909, Val Recall: 0.86136\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.81443, Val Fairness: 1.00000, Val Recall: 0.86933\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.81102, Val Fairness: 1.00000, Val Recall: 0.89434\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.81998, Val Fairness: 0.90909, Val Recall: 0.83599\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.81946, Val Fairness: 0.72727, Val Recall: 0.80608\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.82379, Val Fairness: 0.90909, Val Recall: 0.82103\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.82558, Val Fairness: 0.90909, Val Recall: 0.84310\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.82680, Val Fairness: 0.72727, Val Recall: 0.82839\n",
      "client_2 is updated and its fairness score wrt global_model 1.285329786897185 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.76516, Val Fairness: -1.00000, Val Recall: 0.75423\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.76938, Val Fairness: -1.00000, Val Recall: 0.76913\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.77261, Val Fairness: -1.00000, Val Recall: 0.79676\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.77667, Val Fairness: -1.00000, Val Recall: 0.76841\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.77683, Val Fairness: -0.50000, Val Recall: 0.74382\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.78166, Val Fairness: -1.00000, Val Recall: 0.77535\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.78012, Val Fairness: -1.00000, Val Recall: 0.71098\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.77453, Val Fairness: -1.00000, Val Recall: 0.84522\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.77766, Val Fairness: -0.50000, Val Recall: 0.81484\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35204/3241030428.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  weights = torch.tensor(self.weights_cache, device=self.device) / weight_sum_2\n",
      " 20%|██████████████████████▍                                                                                         | 1/5 [00:57<03:51, 57.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Val Accuracy: 0.78314, Val Fairness: -0.50000, Val Recall: 0.72458\n",
      "client_3 is updated and its fairness score wrt global_model -2.5415182546749775 \n",
      "\n",
      "\n",
      "\n",
      "for round 0 , global fairness, accuracy, and recall are:  -0.5429510002762717 ,  0.3668816454592993 ,  1.0 \n",
      "\n",
      "\n",
      "\n",
      "Before weights-1 (W/w)::  [4620, 5495, 17309, 18242]\n",
      "Before weights -2 (W/w)::  tensor([9.8844, 8.3105, 2.6383, 2.5033], device='cuda:0')\n",
      "After weights_::  tensor([9.5456, 7.9601, 2.2708, 2.1144], device='cuda:0')\n",
      "After weights_ Prob::  tensor([0.4361, 0.3636, 0.1037, 0.0966], device='cuda:0')\n",
      "round:: 1\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.80823, Val Fairness: 0.85714, Val Recall: 0.79915\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.79524, Val Fairness: 0.85714, Val Recall: 0.84540\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.81623, Val Fairness: 0.85714, Val Recall: 0.79610\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.81602, Val Fairness: 0.85714, Val Recall: 0.80706\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.81818, Val Fairness: 0.71429, Val Recall: 0.73159\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.81840, Val Fairness: 0.85714, Val Recall: 0.80158\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.81926, Val Fairness: 0.85714, Val Recall: 0.74559\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.82186, Val Fairness: 0.85714, Val Recall: 0.77967\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.80823, Val Fairness: 0.85714, Val Recall: 0.83688\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.81797, Val Fairness: 0.85714, Val Recall: 0.78332\n",
      "client_0 is updated and its fairness score wrt global_model 2.329660238751148 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.79509, Val Fairness: -0.68000, Val Recall: 0.73153\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.79527, Val Fairness: -0.80000, Val Recall: 0.77789\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.78890, Val Fairness: -0.56000, Val Recall: 0.66345\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.80146, Val Fairness: -0.84000, Val Recall: 0.77933\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.80291, Val Fairness: -0.64000, Val Recall: 0.75326\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.79836, Val Fairness: -0.64000, Val Recall: 0.69676\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.79381, Val Fairness: -0.64000, Val Recall: 0.68952\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.79836, Val Fairness: -0.64000, Val Recall: 0.75133\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.80000, Val Fairness: -0.76000, Val Recall: 0.75954\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.80164, Val Fairness: -0.68000, Val Recall: 0.74070\n",
      "client_1 is updated and its fairness score wrt global_model -1.571120375617259 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.82391, Val Fairness: 0.90909, Val Recall: 0.82030\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.82512, Val Fairness: 1.00000, Val Recall: 0.82814\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.82529, Val Fairness: 1.00000, Val Recall: 0.85695\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.82974, Val Fairness: 0.90909, Val Recall: 0.82300\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.83003, Val Fairness: 0.81818, Val Recall: 0.80865\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.80681, Val Fairness: 0.63636, Val Recall: 0.71402\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.83078, Val Fairness: 0.90909, Val Recall: 0.79738\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.83234, Val Fairness: 0.90909, Val Recall: 0.81442\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.82379, Val Fairness: 0.63636, Val Recall: 0.79051\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.83124, Val Fairness: 0.72727, Val Recall: 0.80351\n",
      "client_2 is updated and its fairness score wrt global_model 1.285329786897185 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.78253, Val Fairness: -0.50000, Val Recall: 0.71966\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.78484, Val Fairness: -0.50000, Val Recall: 0.69680\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.78654, Val Fairness: -0.50000, Val Recall: 0.75640\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.77382, Val Fairness: -0.50000, Val Recall: 0.84045\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.78802, Val Fairness: -0.50000, Val Recall: 0.72790\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.79251, Val Fairness: -1.00000, Val Recall: 0.77347\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.79087, Val Fairness: -0.50000, Val Recall: 0.76277\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.78829, Val Fairness: -0.50000, Val Recall: 0.73962\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.79262, Val Fairness: -0.50000, Val Recall: 0.78128\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35204/3241030428.py:220: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.weights_cache =  weight_sum/torch.tensor(self.weights_cache, device=self.device)\n",
      "/tmp/ipykernel_35204/3241030428.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  weights = torch.tensor(self.weights_cache, device=self.device) / weight_sum_2\n",
      " 40%|████████████████████████████████████████████▊                                                                   | 2/5 [01:55<02:52, 57.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Val Accuracy: 0.79569, Val Fairness: -1.00000, Val Recall: 0.80110\n",
      "client_3 is updated and its fairness score wrt global_model -5.083036509349955 \n",
      "\n",
      "\n",
      "\n",
      "for round 1 , global fairness, accuracy, and recall are:  tensor(0.0869, device='cuda:0') ,  0.7918075649294056 ,  0.7219688331432915 \n",
      "\n",
      "\n",
      "\n",
      "Before weights-1 (W/w)::  tensor([9.5456, 7.9601, 2.2708, 2.1144], device='cuda:0')\n",
      "Before weights -2 (W/w)::  tensor([ 2.2933,  2.7501,  9.6400, 10.3534], device='cuda:0')\n",
      "After weights_::  tensor([1.4851, 1.9441, 8.8355, 9.5454], device='cuda:0')\n",
      "After weights_ Prob::  tensor([0.0681, 0.0891, 0.4051, 0.4377], device='cuda:0')\n",
      "round:: 2\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.81429, Val Fairness: 0.85714, Val Recall: 0.83080\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.81645, Val Fairness: 0.85714, Val Recall: 0.82654\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.80887, Val Fairness: 1.00000, Val Recall: 0.81680\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.81775, Val Fairness: 0.85714, Val Recall: 0.77906\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.82056, Val Fairness: 0.85714, Val Recall: 0.78211\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.81169, Val Fairness: 0.85714, Val Recall: 0.83567\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.82143, Val Fairness: 0.85714, Val Recall: 0.80280\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.82900, Val Fairness: 0.85714, Val Recall: 0.79124\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.82143, Val Fairness: 0.85714, Val Recall: 0.80645\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.82121, Val Fairness: 0.85714, Val Recall: 0.79002\n",
      "client_0 is updated and its fairness score wrt global_model 2.329660238751148 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.80036, Val Fairness: -0.80000, Val Recall: 0.78465\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.79964, Val Fairness: -0.68000, Val Recall: 0.71946\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.79654, Val Fairness: -0.76000, Val Recall: 0.75905\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.79854, Val Fairness: -0.76000, Val Recall: 0.74553\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.79727, Val Fairness: -0.68000, Val Recall: 0.69483\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.80127, Val Fairness: -0.80000, Val Recall: 0.78706\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.79600, Val Fairness: -0.80000, Val Recall: 0.80879\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.80346, Val Fairness: -0.76000, Val Recall: 0.72477\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.80346, Val Fairness: -0.80000, Val Recall: 0.76678\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.80382, Val Fairness: -0.88000, Val Recall: 0.78754\n",
      "client_1 is updated and its fairness score wrt global_model -2.033214603739982 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.82368, Val Fairness: 0.81818, Val Recall: 0.77347\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.83153, Val Fairness: 0.81818, Val Recall: 0.80020\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.82362, Val Fairness: 0.81818, Val Recall: 0.76698\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.82188, Val Fairness: 0.63636, Val Recall: 0.76060\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.83257, Val Fairness: 0.72727, Val Recall: 0.79517\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.83379, Val Fairness: 1.00000, Val Recall: 0.84714\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.82425, Val Fairness: 0.72727, Val Recall: 0.78242\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.83517, Val Fairness: 0.81818, Val Recall: 0.84457\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.83425, Val Fairness: 0.81818, Val Recall: 0.80020\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.83234, Val Fairness: 0.90909, Val Recall: 0.82226\n",
      "client_2 is updated and its fairness score wrt global_model 1.606662233621481 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.79251, Val Fairness: -1.00000, Val Recall: 0.80356\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.79262, Val Fairness: -0.50000, Val Recall: 0.80501\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.79174, Val Fairness: -0.50000, Val Recall: 0.77550\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.79043, Val Fairness: -1.00000, Val Recall: 0.73861\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.78813, Val Fairness: -1.00000, Val Recall: 0.71445\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.79344, Val Fairness: -0.50000, Val Recall: 0.74787\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.78780, Val Fairness: -0.50000, Val Recall: 0.71358\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.78330, Val Fairness: -1.00000, Val Recall: 0.86634\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.79520, Val Fairness: -1.00000, Val Recall: 0.81311\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35204/3241030428.py:220: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.weights_cache =  weight_sum/torch.tensor(self.weights_cache, device=self.device)\n",
      "/tmp/ipykernel_35204/3241030428.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  weights = torch.tensor(self.weights_cache, device=self.device) / weight_sum_2\n",
      " 60%|███████████████████████████████████████████████████████████████████▏                                            | 3/5 [02:51<01:54, 57.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Val Accuracy: 0.79547, Val Fairness: -0.50000, Val Recall: 0.78663\n",
      "client_3 is updated and its fairness score wrt global_model -2.5415182546749775 \n",
      "\n",
      "\n",
      "\n",
      "for round 2 , global fairness, accuracy, and recall are:  tensor(-0.4840, device='cuda:0') ,  0.7986404043925397 ,  0.8199353857848727 \n",
      "\n",
      "\n",
      "\n",
      "Before weights-1 (W/w)::  tensor([1.4851, 1.9441, 8.8355, 9.5454], device='cuda:0')\n",
      "Before weights -2 (W/w)::  tensor([14.6859, 11.2186,  2.4685,  2.2849], device='cuda:0')\n",
      "After weights_::  tensor([13.8693, 10.4034,  1.6539,  1.4693], device='cuda:0')\n",
      "After weights_ Prob::  tensor([0.5063, 0.3797, 0.0604, 0.0536], device='cuda:0')\n",
      "round:: 3\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.81126, Val Fairness: 0.85714, Val Recall: 0.82593\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.82143, Val Fairness: 0.85714, Val Recall: 0.77602\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.81017, Val Fairness: 0.85714, Val Recall: 0.80889\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.81926, Val Fairness: 0.85714, Val Recall: 0.78819\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.81450, Val Fairness: 0.57143, Val Recall: 0.74559\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.82381, Val Fairness: 0.71429, Val Recall: 0.76202\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.82100, Val Fairness: 0.85714, Val Recall: 0.75898\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.81840, Val Fairness: 0.71429, Val Recall: 0.78028\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.82511, Val Fairness: 0.85714, Val Recall: 0.79854\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.81515, Val Fairness: 0.85714, Val Recall: 0.79550\n",
      "client_0 is updated and its fairness score wrt global_model 2.329660238751148 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.80018, Val Fairness: -0.76000, Val Recall: 0.80010\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.80218, Val Fairness: -0.84000, Val Recall: 0.74505\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.80655, Val Fairness: -0.80000, Val Recall: 0.77547\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.80091, Val Fairness: -0.72000, Val Recall: 0.71608\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.79891, Val Fairness: -0.76000, Val Recall: 0.77982\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.79800, Val Fairness: -0.84000, Val Recall: 0.77257\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.80000, Val Fairness: -0.80000, Val Recall: 0.77499\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.79509, Val Fairness: -0.64000, Val Recall: 0.69966\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.79217, Val Fairness: -0.72000, Val Recall: 0.69338\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.80237, Val Fairness: -0.76000, Val Recall: 0.75567\n",
      "client_1 is updated and its fairness score wrt global_model -1.7559580668663481 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.83251, Val Fairness: 0.90909, Val Recall: 0.82839\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.83072, Val Fairness: 0.90909, Val Recall: 0.80498\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.83667, Val Fairness: 0.81818, Val Recall: 0.81552\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.83055, Val Fairness: 0.63636, Val Recall: 0.78169\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.83702, Val Fairness: 0.81818, Val Recall: 0.83905\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.83743, Val Fairness: 0.90909, Val Recall: 0.81907\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.83789, Val Fairness: 0.90909, Val Recall: 0.81846\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.83650, Val Fairness: 0.90909, Val Recall: 0.83207\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.83494, Val Fairness: 0.63636, Val Recall: 0.79419\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.83852, Val Fairness: 0.90909, Val Recall: 0.81123\n",
      "client_2 is updated and its fairness score wrt global_model 1.606662233621481 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.78950, Val Fairness: -0.50000, Val Recall: 0.69463\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.78528, Val Fairness: -0.50000, Val Recall: 0.67467\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.79476, Val Fairness: -0.50000, Val Recall: 0.77767\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.79257, Val Fairness: -0.50000, Val Recall: 0.77260\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.79229, Val Fairness: -0.50000, Val Recall: 0.75206\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.79432, Val Fairness: -1.00000, Val Recall: 0.79546\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.79564, Val Fairness: -1.00000, Val Recall: 0.78461\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.79163, Val Fairness: -0.50000, Val Recall: 0.81643\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.79158, Val Fairness: -0.50000, Val Recall: 0.81745\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35204/3241030428.py:220: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.weights_cache =  weight_sum/torch.tensor(self.weights_cache, device=self.device)\n",
      "/tmp/ipykernel_35204/3241030428.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  weights = torch.tensor(self.weights_cache, device=self.device) / weight_sum_2\n",
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████▌                      | 4/5 [03:53<00:59, 59.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Val Accuracy: 0.79328, Val Fairness: -0.50000, Val Recall: 0.73181\n",
      "client_3 is updated and its fairness score wrt global_model -2.5415182546749775 \n",
      "\n",
      "\n",
      "\n",
      "for round 3 , global fairness, accuracy, and recall are:  tensor(0.4733, device='cuda:0') ,  0.8010807042008018 ,  0.8042569365260357 \n",
      "\n",
      "\n",
      "\n",
      "Before weights-1 (W/w)::  tensor([13.8693, 10.4034,  1.6539,  1.4693], device='cuda:0')\n",
      "Before weights -2 (W/w)::  tensor([ 1.9753,  2.6334, 16.5644, 18.6454], device='cuda:0')\n",
      "After weights_::  tensor([ 1.1581,  1.8184, 15.7503, 17.8278], device='cuda:0')\n",
      "After weights_ Prob::  tensor([0.0317, 0.0497, 0.4309, 0.4877], device='cuda:0')\n",
      "round:: 4\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.82424, Val Fairness: 0.85714, Val Recall: 0.78150\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.81926, Val Fairness: 0.85714, Val Recall: 0.79428\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.81450, Val Fairness: 0.85714, Val Recall: 0.81984\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.82381, Val Fairness: 0.85714, Val Recall: 0.80158\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.82446, Val Fairness: 0.85714, Val Recall: 0.78880\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.82056, Val Fairness: 0.85714, Val Recall: 0.77176\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.81818, Val Fairness: 0.85714, Val Recall: 0.84054\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.82338, Val Fairness: 0.85714, Val Recall: 0.75837\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.82684, Val Fairness: 0.71429, Val Recall: 0.76324\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.82229, Val Fairness: 0.85714, Val Recall: 0.80645\n",
      "client_0 is updated and its fairness score wrt global_model 2.329660238751148 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.79854, Val Fairness: -0.56000, Val Recall: 0.68856\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.80255, Val Fairness: -0.64000, Val Recall: 0.74457\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.80109, Val Fairness: -0.76000, Val Recall: 0.76581\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.80309, Val Fairness: -0.80000, Val Recall: 0.76726\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.79818, Val Fairness: -0.72000, Val Recall: 0.71608\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.80109, Val Fairness: -0.64000, Val Recall: 0.72477\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.80419, Val Fairness: -0.76000, Val Recall: 0.75133\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.80055, Val Fairness: -0.80000, Val Recall: 0.78513\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.80018, Val Fairness: -0.76000, Val Recall: 0.76678\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.80164, Val Fairness: -0.80000, Val Recall: 0.76099\n",
      "client_1 is updated and its fairness score wrt global_model -1.8483769124908929 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.83691, Val Fairness: 1.00000, Val Recall: 0.86001\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.83639, Val Fairness: 0.81818, Val Recall: 0.80988\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.83916, Val Fairness: 0.81818, Val Recall: 0.85364\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.83621, Val Fairness: 0.81818, Val Recall: 0.81270\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.83823, Val Fairness: 0.81818, Val Recall: 0.82888\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.83835, Val Fairness: 0.81818, Val Recall: 0.82925\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.83621, Val Fairness: 0.81818, Val Recall: 0.82851\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.83587, Val Fairness: 0.81818, Val Recall: 0.80216\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.83852, Val Fairness: 0.90909, Val Recall: 0.83354\n",
      "======Validation========\n",
      "Epoch 10/10, Val Accuracy: 0.83870, Val Fairness: 1.00000, Val Recall: 0.85462\n",
      "client_2 is updated and its fairness score wrt global_model 1.7673284569836294 \n",
      "\n",
      "\n",
      "\n",
      "======Validation========\n",
      "Epoch 1/10, Val Accuracy: 0.79054, Val Fairness: -0.50000, Val Recall: 0.82728\n",
      "======Validation========\n",
      "Epoch 2/10, Val Accuracy: 0.79525, Val Fairness: -0.50000, Val Recall: 0.73268\n",
      "======Validation========\n",
      "Epoch 3/10, Val Accuracy: 0.79871, Val Fairness: -1.00000, Val Recall: 0.77767\n",
      "======Validation========\n",
      "Epoch 4/10, Val Accuracy: 0.79520, Val Fairness: -1.00000, Val Recall: 0.78302\n",
      "======Validation========\n",
      "Epoch 5/10, Val Accuracy: 0.79739, Val Fairness: -0.50000, Val Recall: 0.76465\n",
      "======Validation========\n",
      "Epoch 6/10, Val Accuracy: 0.79624, Val Fairness: -0.50000, Val Recall: 0.75192\n",
      "======Validation========\n",
      "Epoch 7/10, Val Accuracy: 0.79492, Val Fairness: -0.50000, Val Recall: 0.77767\n",
      "======Validation========\n",
      "Epoch 8/10, Val Accuracy: 0.79613, Val Fairness: -0.50000, Val Recall: 0.75105\n",
      "======Validation========\n",
      "Epoch 9/10, Val Accuracy: 0.79366, Val Fairness: -0.50000, Val Recall: 0.75394\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35204/3241030428.py:220: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.weights_cache =  weight_sum/torch.tensor(self.weights_cache, device=self.device)\n",
      "/tmp/ipykernel_35204/3241030428.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  weights = torch.tensor(self.weights_cache, device=self.device) / weight_sum_2\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:51<00:00, 58.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Val Accuracy: 0.79805, Val Fairness: -0.50000, Val Recall: 0.77116\n",
      "client_3 is updated and its fairness score wrt global_model -2.5415182546749775 \n",
      "\n",
      "\n",
      "\n",
      "for round 4 , global fairness, accuracy, and recall are:  tensor(-0.4962, device='cuda:0') ,  0.8026843297890883 ,  0.7595020904599011 \n",
      "\n",
      "\n",
      "\n",
      "Before weights-1 (W/w)::  tensor([ 1.1581,  1.8184, 15.7503, 17.8278], device='cuda:0')\n",
      "Before weights -2 (W/w)::  tensor([31.5632, 20.1028,  2.3209,  2.0504], device='cuda:0')\n",
      "After weights_::  tensor([30.7404, 19.2881,  1.5055,  1.2333], device='cuda:0')\n",
      "After weights_ Prob::  tensor([0.5826, 0.3655, 0.0285, 0.0234], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# FairFed \"FF\" and FedAVG \"FA\"\n",
    "\n",
    "algo=\"FF\" \n",
    "\n",
    "if algo==\"FA\":\n",
    "    print(\"Comment out part1 and part2 def_fairFed \")\n",
    "    \n",
    "else:\n",
    "    print(\"Algorithm is \", algo)\n",
    "    \n",
    "global_model_base_path = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models\"\n",
    "shutil.rmtree(global_model_base_path)\n",
    "os.mkdir(global_model_base_path)\n",
    "\n",
    "selected_clients = [0, 1, 2, 3]\n",
    "\n",
    "assigner = AssignModel(global_model_base_path, selected_clients,algo)\n",
    "\n",
    "temp_model = DeepNet()  # Replace with your model instantiation\n",
    "assigner.save_global_model(temp_model)\n",
    "assigner.save_client_models(temp_model)\n",
    "\n",
    "\n",
    "model = DeepNet()\n",
    "server = Serverbase(model,beta=1)\n",
    "server.fedAlgo(num_rounds=5,local_epochs=10,learning_rate = 0.001,algo=algo)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b8580-35d9-4889-9a91-9e6fe5c52a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # client_acc [0.621039359719329, 0.621039359719329, 0.621039359719329, 0.621039359719329]\n",
    " # client_acc [0.7801227935533385, 0.7802324306545335, 0.7809998903628989, 0.7817810547089135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77244b-4b61-4dee-b028-991dbaac5299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a696f369-f476-4ff5-ba94-0f44bf35833e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.4361, 0.3636, 0.1037, 0.0966])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6226f-dea7-4c5d-8e72-8938b57a11f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d090012-28e5-4b94-80ea-b4e348064e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b9c6b0-6dc8-44be-971c-47462a1d4136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ff52d-72c5-4992-a4ae-a951fdd65c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c73ed-150f-4475-a231-d480907cf0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437160e4-0154-4499-9ce2-b6a0fb94586b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b992740-d18d-4eba-9877-711f8163358a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f83f39-f37a-498b-93ee-5e76c687f147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948b9d04-ee69-4a06-9a69-3a3b613845c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ddbca-d926-4438-a87c-cbcf5c7a21a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8bf962-9e8e-49a9-8906-a5a7e1f15f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659224ac-f672-45c2-8e5d-ce8134364325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef10fb66-4dec-4ce9-88f5-2e14cfc67c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e953d-ac99-427f-9ad4-23bc75b5ce67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d9cf53-575f-46d2-ba79-2d1ec7be83c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925aa82e-0ac0-461d-9a58-aad391860f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
