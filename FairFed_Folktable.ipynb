{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e62d23-ca7e-4c4d-8ea7-08cddb8f12ab",
   "metadata": {},
   "source": [
    "======FairFed============\n",
    "\n",
    "-> Init Models for clients\n",
    "\n",
    "-> Get statistics of the dataset\n",
    "\n",
    "-> start training\n",
    "\n",
    "-> for each client\n",
    "\n",
    "        > Update its weights based on local and global fairness\n",
    "        \n",
    "        > store it\n",
    "-> SecAgg applied on the server side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae9b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import glob\n",
    "import sys, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from folktables import ACSDataSource, ACSEmployment,ACSIncome\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from scipy.stats import multivariate_normal\n",
    "import torch, random, copy, os\n",
    "from collections import OrderedDict\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4bea641-8d82-477c-8c94-ce49034ebf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPR\n",
    "# Gender: \n",
    "# 1: Male, 0: Female\n",
    "# Fairness: Male- Female\n",
    "# eq-4: Global- TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23e284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e8550ad",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70374e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "else:\n",
    "    # CUDA is not available\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6badffcd-029a-47e7-9d4e-40b52d32b39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4eb7f6d-5757-494b-8d6a-1192058aee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 14 : input shape\n",
    "        # 9-> we have 9 columns in data \n",
    "        self.layer1 = nn.Linear(14, 512)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(256, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e6ddc-37c5-4a04-ba53-7215bb513904",
   "metadata": {},
   "source": [
    "# assigning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b03167-c1a8-48ce-887b-80a9d50f7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignModel:\n",
    "    def __init__(self, global_model_base_path, selected_clients,algo=\"FF\"):      \n",
    "        self.global_model_path = f\"{global_model_base_path}/global_model_{algo}.pt\"\n",
    "        self.selected_clients = selected_clients\n",
    "\n",
    "    def save_global_model(self, model):\n",
    "        torch.save(model.state_dict(), self.global_model_path)\n",
    "\n",
    "    def save_client_models(self, model):\n",
    "        for client_id in self.selected_clients:\n",
    "            client_model_path = f\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/client_{client_id}_model.pth\"\n",
    "            torch.save(model.state_dict(), client_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52352bb-381e-4af7-baf1-e5900e214c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a24c1cb2-bf5f-4164-a4d5-9251d6358acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self):\n",
    "        self.client_id: int = None\n",
    "        self.valset: DataLoader = None\n",
    "        self.trainset: DataLoader = None\n",
    "        self.testset: DataLoader = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")         \n",
    "        self.model = DeepNet().to(self.device)\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "\n",
    "        self.fainess_score=0\n",
    "\n",
    "        self.client_df = pd.DataFrame()\n",
    "        self.selected_clients=[0,1,2,3]\n",
    "\n",
    "        self.client_fairness=0\n",
    "        self.global_fairness=0\n",
    "\n",
    "        \n",
    "    def get_client_local_dataset(self):\n",
    "                \n",
    "        temp_path_data=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/data_fairFed\"\n",
    "        \n",
    "        with open(temp_path_data+\"/clients_training.pkl\", \"rb\") as f:\n",
    "            self.trainset = pickle.load(f)\n",
    "            \n",
    "        with open(temp_path_data+\"/clients_validation.pkl\", \"rb\") as f:\n",
    "            self.valset = pickle.load(f)\n",
    "         \n",
    "        with open(temp_path_data+\"/clients_testing_wrong.pkl\", \"rb\") as f:\n",
    "            self.testset  = pickle.load(f)\n",
    "\n",
    "        self.trainset = self.trainset[self.client_id]\n",
    "        self.valset = self.valset[self.client_id]       \n",
    "        self.testset = self.testset[self.client_id]\n",
    "\n",
    "    def get_stats(self):\n",
    "        # 1 male 0 female\n",
    "        total_pr_Y1_A0 = 0\n",
    "        total_pr_Y1_A1 = 0\n",
    "\n",
    "        for client_id in self.selected_clients:\n",
    "            self.client_id=client_id\n",
    "            self.get_client_local_dataset()\n",
    "            for inputs, labels, A in self.trainset:\n",
    "                pr_Y1_A1 = torch.sum((labels == 1) & (A == 1)).item()\n",
    "                pr_Y1_A0 = torch.sum((labels == 1) & (A == 0)).item()\n",
    "          \n",
    "                total_pr_Y1_A0 += pr_Y1_A0\n",
    "                total_pr_Y1_A1 += pr_Y1_A1\n",
    "        temp_sum=total_pr_Y1_A0+total_pr_Y1_A1\n",
    "        return [total_pr_Y1_A1/temp_sum,total_pr_Y1_A0/temp_sum]\n",
    "        \n",
    "    def calculate_fairness(self,y_hat, A, Y,server_acc,client_acc,len_client_data):\n",
    "        # Calculate counts using torch.sum\n",
    "        y_hat, A, Y = y_hat.to(self.device), A.to(self.device), Y.to(self.device)\n",
    "\n",
    "        # 1: Male, 0: Female\n",
    "        predict_Y_male = torch.sum((y_hat[(A == 1) & (Y == 1)] == 1)).item()\n",
    "        predict_Y_female = torch.sum((y_hat[(A == 0) & (Y == 1)] == 1)).item()\n",
    "        \n",
    "        count_Y_male = torch.sum((Y[(A == 1) & (Y == 1)] == 1)).item()\n",
    "        count_Y_female = torch.sum((Y[(A == 0) & (Y == 1)] == 1)).item()\n",
    "    \n",
    "        # Calculate probabilities\n",
    "        \n",
    "        if count_Y_male > 0 and count_Y_female > 0:\n",
    "            prob_Y_male = predict_Y_male / count_Y_male\n",
    "            prob_Y_female = predict_Y_female / count_Y_female\n",
    "            fairness_score = prob_Y_male - prob_Y_female\n",
    "        else:\n",
    "            # Cal sever_acc from client using Eq.\n",
    "            total_len_data=sum(len_client_data)   \n",
    "            temp_server_acc=0\n",
    "            for i in range(len(self.selected_clients)):\n",
    "                temp_server_acc+=client_acc[i]*(len_client_data[i]/total_len_data)\n",
    "                \n",
    "                \n",
    "            avg_acc_client=sum(client_acc) /len(client_acc)\n",
    "            fairness_score= abs(avg_acc_client-server_acc)\n",
    "            # print(\"Else calculate_fairness fairness_score\",fairness_score)\n",
    "            \n",
    "        return  fairness_score\n",
    "\n",
    "    def calculate_ser_fairness(self,y_hat, A, Y,statistics,server_acc,client_acc,len_client_data):\n",
    "        # print(\"calculate_ser_fairness statistics\",statistics)\n",
    "        y_hat, A, Y = y_hat.to(self.device), A.to(self.device), Y.to(self.device)\n",
    "\n",
    "        # for individual clients!\n",
    "        #Male \n",
    "        predict_Y_male = torch.sum((y_hat[(A == 1) & (Y == 1)] == 1)).item() #get total\n",
    "        #Pr(A=0, Y=1)\n",
    "        count_Y_male = torch.sum((A == 1) & (Y == 1)).item() \n",
    "        #Pr(Ŷ=1|A=1, Y=1)  #Female      \n",
    "        predict_Y_female = torch.sum((y_hat[(A == 0) & (Y == 1)] == 1)).item()  #get total\n",
    "        #Pr(A=1, Y=1)\n",
    "        count_Y_female = torch.sum((A == 0) & (Y == 1)).item()\n",
    "        \n",
    "        if count_Y_male>0 and count_Y_female>0:\n",
    "            predict_Y_male=predict_Y_male/count_Y_male #Pr(Ŷ=1|A=0, Y=1)\n",
    "            predict_Y_female=predict_Y_female/count_Y_female   #Pr(Ŷ=1|A=1, Y=1)\n",
    "            temp_fairness_server=((predict_Y_male * count_Y_male)/statistics[0]) - ((predict_Y_female * count_Y_female)/statistics[1])\n",
    "        else:\n",
    "            # Cal sever_acc from client using Eq.\n",
    "            total_len_data=sum(len_client_data)   \n",
    "            temp_server_acc=0\n",
    "            for i in range(len(self.selected_clients)):\n",
    "                temp_server_acc+=client_acc[i]*(len_client_data[i]/total_len_data)\n",
    "                \n",
    "                \n",
    "            avg_acc_client=sum(client_acc) /len(client_acc)\n",
    "            temp_fairness_server= abs(avg_acc_client-server_acc)\n",
    "            # print(\"Else calculate_ser_fairness\",temp_fairness_server)\n",
    "\n",
    "        # print(\"calculate_ser_fairness temp_fairness_server\",self.client_id,temp_fairness_server)\n",
    "        return temp_fairness_server\n",
    "\n",
    "\n",
    "    def train(self, client_id: int, model_path,statistics,server_acc,clients_acc,len_client_data, num_epochs=5, learning_rate=0.001):\n",
    "        self.client_id = client_id\n",
    "        self.get_client_local_dataset()\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.fainess_score=0\n",
    "      \n",
    "        self.model.load_state_dict(torch.load(model_path,map_location=self.device))\n",
    "        for epoch in range(num_epochs):\n",
    "            # Set the model to training mode\n",
    "            self.model.train()\n",
    "\n",
    "            for inputs, labels, sens in self.trainset:\n",
    "                \n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs).to(self.device)\n",
    "                loss = self.criterion(outputs, labels.float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Calculate and print the training accuracy for this epoch (optional)\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            size = 0\n",
    "            loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            predicted_labels = []\n",
    "            true_labels = []\n",
    "            final_fairness=[]\n",
    "            final_fairness_server=[]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                print(\"======Validation========\")\n",
    "                for inputs, labels,sens in self.valset:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    outputs = self.model(inputs)\n",
    "                    loss += self.criterion(outputs, labels)\n",
    "                    predicted = outputs > 0.5\n",
    "\n",
    "                    predicted_labels.extend(predicted.cpu().numpy())\n",
    "                    true_labels.extend(labels.cpu().numpy())                   \n",
    "                    \n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()                   \n",
    "\n",
    "            loss = loss / len(self.valset)        \n",
    "            acc = correct/total\n",
    " \n",
    "            fairNess_per_batch=self.calculate_fairness(torch.round(outputs).squeeze(), sens.squeeze(), labels.squeeze(),\n",
    "                                                       server_acc,\n",
    "                                                       clients_acc,\n",
    "                                                      len_client_data)\n",
    "            final_fairness.append(fairNess_per_batch)\n",
    "            self.fainess_score=np.mean(final_fairness)\n",
    "\n",
    "            fairNess_per_batch_server=self.calculate_ser_fairness(torch.round(outputs).squeeze(), sens.squeeze(), labels.squeeze(),\n",
    "                                                                  statistics,\n",
    "                                                                  server_acc,\n",
    "                                                                  clients_acc,\n",
    "                                                                 len_client_data)\n",
    "            final_fairness_server.append(fairNess_per_batch_server)            \n",
    "            ser_score=np.mean(final_fairness_server)\n",
    "                        \n",
    "            precision = precision_score(true_labels, predicted_labels,zero_division=0.0)            \n",
    "            recall = recall_score(true_labels, predicted_labels)\n",
    "            \n",
    "            # accuracy = 100 * correct / total\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Val Accuracy: {acc:.5f}%\")\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Val Fairness: {self.fainess_score:.5f}%\")\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Val Recall: {recall:.5f}%\")\n",
    "\n",
    "\n",
    "        # Optionally, save the trained model parameters\n",
    "        #store model\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "        # Return the trained model parameters\n",
    "        return list(self.model.state_dict().values()), len(self.trainset.dataset),self.model.state_dict(), self.fainess_score, ser_score\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def client_evaluate(self, val=False):\n",
    "        \n",
    "        size = 0\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "        len_of_data=[]\n",
    "        all_client_acc=[]\n",
    "        \n",
    "        models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "                 \n",
    "        for client_id in self.selected_clients:\n",
    "            \n",
    "            model_path = os.path.join(models_directory, f\"client_{client_id}_model.pth\")            \n",
    "        \n",
    "            self.model.load_state_dict(torch.load(model_path,map_location=self.device))\n",
    "\n",
    "            self.model.eval()\n",
    "\n",
    "            for inputs, targets,sens in self.testset:\n",
    "                \n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                loss += self.criterion(outputs, targets)\n",
    "                predicted = outputs > 0.5\n",
    "                \n",
    "                predicted_labels.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(targets.cpu().numpy())\n",
    "                \n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "                \n",
    "                len_of_data.append(len(self.testset))\n",
    "            \n",
    "            loss = loss / len(self.testset)\n",
    "            acc = correct / total\n",
    "            all_client_acc.append(acc)\n",
    "                        \n",
    "            precision = precision_score(true_labels, predicted_labels,zero_division=0.0)\n",
    "            \n",
    "            recall = recall_score(true_labels, predicted_labels)\n",
    "                            \n",
    "        return loss, acc, precision, recall,len_of_data, all_client_acc\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def server_evaluate(self,path,all_client_acc,len_of_data):\n",
    "\n",
    "        # print(\"Global Model testing Starts\")\n",
    "        # print(\"kindly check the Path. Select it based on FedAvg Model\")\n",
    "        # print(\"warning: Test data has already been used\")\n",
    "        temp_path_data=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/\"\n",
    "\n",
    "        with open(temp_path_data+\"/testing_client.pkl\", \"rb\") as f:\n",
    "            testset  = pickle.load(f)\n",
    "            \n",
    "        \n",
    "        # path=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model_2.pt\"\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(path,map_location=self.device))\n",
    "        self.model.eval()\n",
    "        size = 0\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "        final_fairness=[]\n",
    "\n",
    "        self.testset=testset[1]\n",
    "        for inputs, targets,sens in self.testset:\n",
    "            \n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "            \n",
    "            outputs = self.model(inputs)\n",
    "            loss += self.criterion(outputs, targets)\n",
    "            predicted = outputs > 0.5\n",
    "\n",
    "            \n",
    "#            print(\"predicted\",predicted)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(targets.cpu().numpy())\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "        \n",
    "        loss = loss / len(self.testset)\n",
    "        ser_acc = correct / total\n",
    "\n",
    "        fairNess_per_batch=self.calculate_fairness(torch.round(outputs).squeeze(), sens.squeeze(), targets.squeeze(),\n",
    "                                                    ser_acc,\n",
    "                                                    all_client_acc,\n",
    "                                                    len_of_data)\n",
    "        final_fairness.append(fairNess_per_batch)\n",
    "        fairness_global=np.mean(final_fairness)\n",
    "\n",
    "        # print(\"loss: %f\\n\" % (loss))\n",
    "        \n",
    "        # print(f\"Global Testing Accuracy: {ser_acc:.5%}\")\n",
    "        # print(f\" Global Fairness: {fairness_global:.5f}%\")\n",
    "        precision = precision_score(true_labels, predicted_labels,zero_division=0.0)\n",
    "        \n",
    "        recall = recall_score(true_labels, predicted_labels)\n",
    "        \n",
    "        # print(f\"Global Precision: {precision:.5%}\")\n",
    "        # print(f\"Global Recall: {recall:.5%}\")\n",
    "        \n",
    "        return loss, ser_acc, precision, recall,fairness_global\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "199eb51c-d78b-44f1-86b0-e8b325ce899c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Serverbase:\n",
    "    def __init__ (self,model):\n",
    "        self.model = model\n",
    "        self.global_model=model\n",
    "        self.num_rounds=2\n",
    "        self.local_epoch=2\n",
    "        self.optimizer=2\n",
    "        self.lr=0.001\n",
    "        self.beta=1\n",
    "        self.batch_size=32\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "    \n",
    "        self.updated_params_cache = []\n",
    "        self.weights_cache = []\n",
    "        self.model_dict = []\n",
    "        \n",
    "        self.global_params_dict: OrderedDict[str : torch.Tensor] = None\n",
    "\n",
    "        self.backbone=DeepNet\n",
    "        _dummy_model = self.backbone()\n",
    "        self.global_params_dict = OrderedDict(_dummy_model.state_dict())\n",
    "\n",
    "        self.temp_dir=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "\n",
    "        self.fair_global_t_step=0\n",
    "        self.fair_local_client=0   \n",
    "        \n",
    "        self.acc_clients=[]\n",
    "        self.clients_id=[]\n",
    "        self.precision_clients=[]\n",
    "        self.recall_clients=[]\n",
    "        \n",
    "        self.global_acc=0\n",
    "        self.fairness_diff=[]\n",
    "        self.clients_weights=[]\n",
    "        self.final_agg_weights_clients=[]\n",
    "        self.selected_clients=[0,1,2,3]\n",
    "        self.statistics=0\n",
    "\n",
    "    def global_fairness(self,weights, all_clients_fairness): \n",
    "        # all_clients_fairness is based on equation: 7\n",
    "        # upper part is done in client class\n",
    "        # self.statistics cal. pr(y=1,a=0)\n",
    "        \n",
    "        # print(\"global_fairness::\",all_clients_fairness)\n",
    "        # print(\"weights::\",weights)\n",
    "        \n",
    "        weight_sum = sum(weights)  \n",
    "        final_global_score=0\n",
    "        \n",
    "        for i in range(len(all_clients_fairness)):\n",
    "            temp=weights[i]/weight_sum            \n",
    "            final_global_score+=temp*all_clients_fairness[i]\n",
    "            \n",
    "        self.fair_global=final_global_score\n",
    "\n",
    "    \n",
    "        \n",
    "    def fairFed(self, num_rounds = 2, local_epochs = 2, learning_rate = 0.001, beta = 1, optimizer = 'adam',algo=\"FF\"):\n",
    "        \n",
    "        client = Client()\n",
    "        path=f\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model_{algo}.pt\"\n",
    "        models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "        \n",
    "        #before we start the training, we need statistics\n",
    "        print(\"Getting data statistics....\")\n",
    "        self.statistics= client.get_stats()      \n",
    "        \n",
    "\n",
    "        for round_ in tqdm(range(num_rounds)):\n",
    "  \n",
    "            #each round we need empty lists\n",
    "            self.updated_params_cache = []\n",
    "            self.weights_cache = []\n",
    "            self.model_dict=[]\n",
    "            self.clients_weights=[]\n",
    "            self.final_agg_weights_clients=[]\n",
    "            self.fair_global=0\n",
    "            temp_ser_fairness=[]\n",
    "\n",
    "            print (\"round::\",round_)\n",
    "            \n",
    "             # clients and server acc for calculating Fairness whenever fairness_client is undefined\n",
    "        \n",
    "            loss_client, acc_client,precision, recall,len_of_data,all_client_acc = client.client_evaluate() \n",
    "            \n",
    "            loss_client, accuracy_server, pre_server, recall_ser,fairness_global = client.server_evaluate(path,all_client_acc,len_of_data)\n",
    "\n",
    "            \n",
    "            for client_id in self.selected_clients:\n",
    "                self.global_acc=0\n",
    "                \n",
    "                print(\"client_id:: \",client_id)\n",
    "                # weight is length of dataset\n",
    "\n",
    "                \n",
    "                #take a model of particular client\n",
    "                model_path = os.path.join(models_directory, f\"client_{client_id}_model.pth\")                       \n",
    "                \n",
    "                updated_params_list, weight, model_dict_list,fairness_client,ser_fairness = client.train(client_id, \n",
    "                                                                                                         model_path, \n",
    "                                                                                                         statistics=self.statistics,\n",
    "                                                                                                         server_acc=accuracy_server,\n",
    "                                                                                                         clients_acc=all_client_acc,\n",
    "                                                                                                         len_client_data=len_of_data,\n",
    "                                                                                                         num_epochs=local_epochs, \n",
    "                                                                                                         learning_rate=learning_rate)        \n",
    "                            \n",
    "                # store it for SecAgg\n",
    "                self.updated_params_cache.append(updated_params_list)\n",
    "                self.weights_cache.append(weight)\n",
    "                self.model_dict.append(model_dict_list)\n",
    "                temp_ser_fairness.append(ser_fairness)\n",
    "                \n",
    "                # print(\"temp_ser_fairness\",temp_ser_fairness)\n",
    "                #store it for FairFed agg\n",
    "                \n",
    "                # self.global_acc=acc_server\n",
    "                self.fair_local_client=fairness_client                \n",
    "            \n",
    "            self.global_fairness(self.weights_cache, temp_ser_fairness)\n",
    "\n",
    "            print(\"for round\", round_,\", global fairness, accuracy, and recall are: \",self.fair_global,\", \",\n",
    "                                                                                  accuracy_server,\", \",\n",
    "                                                                                  recall_ser,\"\\n\\n\\n\")\n",
    "\n",
    "            # Update the weights of each client\n",
    "            # self.aggregate_client_weight_FedFair_part_1(self.model_dict, self.weights_cache,self.acc_clients, self.global_acc,self.fair_local_client,\n",
    "            #                                      self.fair_global)\n",
    "            # self.client_weights_update_part_2(self.clients_weights)\n",
    "\n",
    "            # agg all the weights on serverside\n",
    "            if algo==\"FF\":\n",
    "                self.aggregate_parameters_FedAvg_updated(self.final_agg_weights_clients)\n",
    "            elif algo==\"FA\":\n",
    "                self.aggregate_parameters_FedAvg(self.updated_params_cache,self.weights_cache)\n",
    "            else:\n",
    "                print(\"--Choose Algo --\")\n",
    "                break\n",
    "        \n",
    "            \n",
    "            torch.save(self.global_model.state_dict(), os.path.join(self.temp_dir, f\"global_model_{algo}.pt\"),)\n",
    "\n",
    "            \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def aggregate_parameters_FedAvg(self, updated_params_cache, weights_cache):\n",
    "        weight_sum = sum(weights_cache)  \n",
    "        \n",
    "        weights = torch.tensor(weights_cache, device=self.device) / weight_sum\n",
    "        \n",
    "        aggregated_params = []\n",
    "\n",
    "        for params in zip(*updated_params_cache):\n",
    "            aggregated_params.append(\n",
    "                torch.sum(weights * torch.stack(params, dim=-1), dim=-1)\n",
    "            )\n",
    "\n",
    "        self.global_params_dict = OrderedDict(\n",
    "            zip(self.global_params_dict.keys(), aggregated_params)\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def aggregate_parameters_FedAvg_updated(self, model_dict_list):        \n",
    "        w_avg = copy.deepcopy(model_dict_list[0])\n",
    "        for k in w_avg.keys():\n",
    "            for i in range(1, len(model_dict_list)):\n",
    "                w_avg[k] += model_dict_list[i][k]\n",
    "            w_avg[k] = torch.div(w_avg[k], len(model_dict_list))\n",
    "    \n",
    "        self.global_model.load_state_dict(w_avg)\n",
    "\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def aggregate_client_weight_FedFair_part_1 (self, model_dict_list ,weights_cache, acc_clients, global_acc,fairness_client,fairness_global):\n",
    "        \n",
    "\n",
    "        Delta_t_C_i = abs(self.fair_global - self.fair_local_client) \n",
    "        \n",
    "        for client_id in range(len(self.selected_clients)):\n",
    "        \n",
    "            w_avg = copy.deepcopy(model_dict_list[client_id])\n",
    "            temp = copy.deepcopy(model_dict_list[client_id])\n",
    "            \n",
    "            for k in w_avg.keys():\n",
    "                for i in range(1, len(model_dict_list)):\n",
    "                    w_avg[k] += model_dict_list[i][k]\n",
    "                w_avg[k] = torch.div(w_avg[k], len(model_dict_list))\n",
    "                \n",
    "                w_avg[k]=temp[k]-(self.beta*(Delta_t_C_i-w_avg[k]))\n",
    "                \n",
    "            self.clients_weights.append(w_avg)\n",
    "\n",
    "            \n",
    "    def client_weights_update_part_2(self,agg_weights):\n",
    "        sum_params = OrderedDict()\n",
    "        \n",
    "        for model in agg_weights:\n",
    "            for name, param in model.items():\n",
    "                if name in sum_params:\n",
    "                    sum_params[name] += param\n",
    "                else:\n",
    "                    sum_params[name] = param\n",
    "\n",
    "            updated_client_weights = OrderedDict()\n",
    "            \n",
    "            for name, param in model.items():\n",
    "                updated_param = torch.div(param, sum_params[name])\n",
    "                updated_client_weights[name] = updated_param\n",
    "\n",
    "                self.final_agg_weights_clients.append(updated_client_weights)\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf995c8-5238-44f1-aa4d-e927101b0a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb97600f-7474-47ae-bd82-89bcad80e6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment out part1 and part2 def_fairFed \n",
      "Getting data statistics....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                   | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:: 0\n",
      "client_id::  0\n",
      "======Validation========\n",
      "Epoch 1/5, Val Accuracy: 0.76212%\n",
      "Epoch 1/5, Val Fairness: 0.01208%\n",
      "Epoch 1/5, Val Recall: 0.80584%\n",
      "======Validation========\n",
      "Epoch 2/5, Val Accuracy: 0.78312%\n",
      "Epoch 2/5, Val Fairness: 0.01208%\n",
      "Epoch 2/5, Val Recall: 0.69994%\n",
      "======Validation========\n",
      "Epoch 3/5, Val Accuracy: 0.78745%\n",
      "Epoch 3/5, Val Fairness: 0.01208%\n",
      "Epoch 3/5, Val Recall: 0.69507%\n",
      "======Validation========\n",
      "Epoch 4/5, Val Accuracy: 0.79286%\n",
      "Epoch 4/5, Val Fairness: 0.01208%\n",
      "Epoch 4/5, Val Recall: 0.70359%\n",
      "======Validation========\n",
      "Epoch 5/5, Val Accuracy: 0.78225%\n",
      "Epoch 5/5, Val Fairness: 0.01208%\n",
      "Epoch 5/5, Val Recall: 0.58186%\n",
      "client_id::  1\n",
      "======Validation========\n",
      "Epoch 1/5, Val Accuracy: 0.75541%\n",
      "Epoch 1/5, Val Fairness: 0.01208%\n",
      "Epoch 1/5, Val Recall: 0.82424%\n",
      "======Validation========\n",
      "Epoch 2/5, Val Accuracy: 0.76397%\n",
      "Epoch 2/5, Val Fairness: 0.01208%\n",
      "Epoch 2/5, Val Recall: 0.81458%\n",
      "======Validation========\n",
      "Epoch 3/5, Val Accuracy: 0.77925%\n",
      "Epoch 3/5, Val Fairness: 0.01208%\n",
      "Epoch 3/5, Val Recall: 0.80444%\n",
      "======Validation========\n",
      "Epoch 4/5, Val Accuracy: 0.78581%\n",
      "Epoch 4/5, Val Fairness: 0.01208%\n",
      "Epoch 4/5, Val Recall: 0.75761%\n",
      "======Validation========\n",
      "Epoch 5/5, Val Accuracy: 0.78708%\n",
      "Epoch 5/5, Val Fairness: 0.01208%\n",
      "Epoch 5/5, Val Recall: 0.71366%\n",
      "client_id::  2\n",
      "======Validation========\n",
      "Epoch 1/5, Val Accuracy: 0.79935%\n",
      "Epoch 1/5, Val Fairness: 0.01208%\n",
      "Epoch 1/5, Val Recall: 0.82532%\n",
      "======Validation========\n",
      "Epoch 2/5, Val Accuracy: 0.80594%\n",
      "Epoch 2/5, Val Fairness: 0.01208%\n",
      "Epoch 2/5, Val Recall: 0.76428%\n",
      "======Validation========\n",
      "Epoch 3/5, Val Accuracy: 0.81050%\n",
      "Epoch 3/5, Val Fairness: 0.01208%\n",
      "Epoch 3/5, Val Recall: 0.76771%\n",
      "======Validation========\n",
      "Epoch 4/5, Val Accuracy: 0.80363%\n",
      "Epoch 4/5, Val Fairness: 0.01208%\n",
      "Epoch 4/5, Val Recall: 0.72689%\n",
      "======Validation========\n",
      "Epoch 5/5, Val Accuracy: 0.82246%\n",
      "Epoch 5/5, Val Fairness: 0.01208%\n",
      "Epoch 5/5, Val Recall: 0.80865%\n",
      "client_id::  3\n",
      "======Validation========\n",
      "Epoch 1/5, Val Accuracy: 0.76423%\n",
      "Epoch 1/5, Val Fairness: 0.01208%\n",
      "Epoch 1/5, Val Recall: 0.76045%\n",
      "======Validation========\n",
      "Epoch 2/5, Val Accuracy: 0.77031%\n",
      "Epoch 2/5, Val Fairness: 0.01208%\n",
      "Epoch 2/5, Val Recall: 0.76407%\n",
      "======Validation========\n",
      "Epoch 3/5, Val Accuracy: 0.77661%\n",
      "Epoch 3/5, Val Fairness: 0.01208%\n",
      "Epoch 3/5, Val Recall: 0.74382%\n",
      "======Validation========\n",
      "Epoch 4/5, Val Accuracy: 0.77645%\n",
      "Epoch 4/5, Val Fairness: 0.01208%\n",
      "Epoch 4/5, Val Recall: 0.83220%\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████▌                             | 1/2 [00:28<00:28, 28.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Val Accuracy: 0.78100%\n",
      "Epoch 5/5, Val Fairness: 0.01208%\n",
      "Epoch 5/5, Val Recall: 0.76870%\n",
      "for round 0 , global fairness, accuracy, and recall are:  0.012078994821371702 ,  0.3668816454592993 ,  1.0 \n",
      "\n",
      "\n",
      "\n",
      "round:: 1\n",
      "client_id::  0\n",
      "======Validation========\n",
      "Epoch 1/5, Val Accuracy: 0.80216%\n",
      "Epoch 1/5, Val Fairness: 0.14555%\n",
      "Epoch 1/5, Val Recall: 0.78698%\n",
      "======Validation========\n",
      "Epoch 2/5, Val Accuracy: 0.80606%\n",
      "Epoch 2/5, Val Fairness: 0.14555%\n",
      "Epoch 2/5, Val Recall: 0.73707%\n",
      "======Validation========\n",
      "Epoch 3/5, Val Accuracy: 0.80346%\n",
      "Epoch 3/5, Val Fairness: 0.14555%\n",
      "Epoch 3/5, Val Recall: 0.79245%\n",
      "======Validation========\n",
      "Epoch 4/5, Val Accuracy: 0.80974%\n",
      "Epoch 4/5, Val Fairness: 0.14555%\n",
      "Epoch 4/5, Val Recall: 0.69142%\n",
      "======Validation========\n",
      "Epoch 5/5, Val Accuracy: 0.80974%\n",
      "Epoch 5/5, Val Fairness: 0.14555%\n",
      "Epoch 5/5, Val Recall: 0.76446%\n",
      "client_id::  1\n",
      "======Validation========\n",
      "Epoch 1/5, Val Accuracy: 0.79126%\n",
      "Epoch 1/5, Val Fairness: 0.14555%\n",
      "Epoch 1/5, Val Recall: 0.76678%\n",
      "======Validation========\n",
      "Epoch 2/5, Val Accuracy: 0.79308%\n",
      "Epoch 2/5, Val Fairness: 0.14555%\n",
      "Epoch 2/5, Val Recall: 0.75278%\n",
      "======Validation========\n",
      "Epoch 3/5, Val Accuracy: 0.79108%\n",
      "Epoch 3/5, Val Fairness: 0.14555%\n",
      "Epoch 3/5, Val Recall: 0.78271%\n",
      "======Validation========\n",
      "Epoch 4/5, Val Accuracy: 0.79327%\n",
      "Epoch 4/5, Val Fairness: 0.14555%\n",
      "Epoch 4/5, Val Recall: 0.78175%\n",
      "======Validation========\n",
      "Epoch 5/5, Val Accuracy: 0.79381%\n",
      "Epoch 5/5, Val Fairness: 0.14555%\n",
      "Epoch 5/5, Val Recall: 0.75278%\n",
      "client_id::  2\n",
      "======Validation========\n",
      "Epoch 1/5, Val Accuracy: 0.82662%\n",
      "Epoch 1/5, Val Fairness: 0.14555%\n",
      "Epoch 1/5, Val Recall: 0.82508%\n",
      "======Validation========\n",
      "Epoch 2/5, Val Accuracy: 0.82431%\n",
      "Epoch 2/5, Val Fairness: 0.14555%\n",
      "Epoch 2/5, Val Recall: 0.83942%\n",
      "======Validation========\n",
      "Epoch 3/5, Val Accuracy: 0.82720%\n",
      "Epoch 3/5, Val Fairness: 0.14555%\n",
      "Epoch 3/5, Val Recall: 0.82140%\n",
      "======Validation========\n",
      "Epoch 4/5, Val Accuracy: 0.82651%\n",
      "Epoch 4/5, Val Fairness: 0.14555%\n",
      "Epoch 4/5, Val Recall: 0.80547%\n",
      "======Validation========\n",
      "Epoch 5/5, Val Accuracy: 0.83032%\n",
      "Epoch 5/5, Val Fairness: 0.14555%\n",
      "Epoch 5/5, Val Recall: 0.80951%\n",
      "client_id::  3\n",
      "======Validation========\n",
      "Epoch 1/5, Val Accuracy: 0.76812%\n",
      "Epoch 1/5, Val Fairness: 0.14555%\n",
      "Epoch 1/5, Val Recall: 0.86562%\n",
      "======Validation========\n",
      "Epoch 2/5, Val Accuracy: 0.78566%\n",
      "Epoch 2/5, Val Fairness: 0.14555%\n",
      "Epoch 2/5, Val Recall: 0.80081%\n",
      "======Validation========\n",
      "Epoch 3/5, Val Accuracy: 0.78423%\n",
      "Epoch 3/5, Val Fairness: 0.14555%\n",
      "Epoch 3/5, Val Recall: 0.79488%\n",
      "======Validation========\n",
      "Epoch 4/5, Val Accuracy: 0.78730%\n",
      "Epoch 4/5, Val Fairness: 0.14555%\n",
      "Epoch 4/5, Val Recall: 0.82829%\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 2/2 [01:01<00:00, 30.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Val Accuracy: 0.78040%\n",
      "Epoch 5/5, Val Fairness: 0.14555%\n",
      "Epoch 5/5, Val Recall: 0.85535%\n",
      "for round 1 , global fairness, accuracy, and recall are:  0.14555174742180343 ,  0.6331183545407008 ,  0.0 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# FairFed \"FF\" and FedAVG \"FA\"\n",
    "\n",
    "algo=\"FA\" \n",
    "\n",
    "if algo==\"FA\":\n",
    "    print(\"Comment out part1 and part2 def_fairFed \")\n",
    "    \n",
    "else:\n",
    "    print(\"Algorithm is \", algo)\n",
    "    \n",
    "global_model_base_path = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models\"\n",
    "shutil.rmtree(global_model_base_path)\n",
    "os.mkdir(global_model_base_path)\n",
    "\n",
    "selected_clients = [0, 1, 2, 3]\n",
    "\n",
    "assigner = AssignModel(global_model_base_path, selected_clients,algo)\n",
    "\n",
    "temp_model = DeepNet()  # Replace with your model instantiation\n",
    "assigner.save_global_model(temp_model)\n",
    "assigner.save_client_models(temp_model)\n",
    "\n",
    "\n",
    "model = DeepNet()\n",
    "server = Serverbase(model)\n",
    "server.fairFed(num_rounds=2,local_epochs=5,learning_rate = 0.001, beta = 1,algo=algo)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b8580-35d9-4889-9a91-9e6fe5c52a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dceab3e-95e5-4632-b546-71af084db801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da6c4e-a098-47fd-be66-e6ff275679c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558d74f-aeef-4ec7-a86b-23e1fe0fe93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77244b-4b61-4dee-b028-991dbaac5299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696f369-f476-4ff5-ba94-0f44bf35833e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
