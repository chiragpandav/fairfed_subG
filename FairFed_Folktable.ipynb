{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e62d23-ca7e-4c4d-8ea7-08cddb8f12ab",
   "metadata": {},
   "source": [
    "======FairFed============\n",
    "\n",
    "-> Init Models for clients\n",
    "\n",
    "-> Get statistics of the dataset\n",
    "\n",
    "-> start training\n",
    "\n",
    "      -> for each round-> assigning agg global model to all clients\n",
    "\n",
    "-> for each client\n",
    "\n",
    "        > Update its weights based on local and global fairness\n",
    "        \n",
    "        > store it\n",
    "-> SecAgg applied on the server side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4ae9b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import glob\n",
    "import sys, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from folktables import ACSDataSource, ACSEmployment,ACSIncome\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from scipy.stats import multivariate_normal\n",
    "import torch, random, copy, os\n",
    "from collections import OrderedDict\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c4bea641-8d82-477c-8c94-ce49034ebf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPR\n",
    "# Gender: \n",
    "# 1: Male, 0: Female\n",
    "# Fairness: Male- Female\n",
    "# eq-4: Global- TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23e284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e8550ad",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a70374e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "else:\n",
    "    # CUDA is not available\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6badffcd-029a-47e7-9d4e-40b52d32b39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f4eb7f6d-5757-494b-8d6a-1192058aee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 14 : input shape\n",
    "        # 9-> we have 9 columns in data \n",
    "        self.layer1 = nn.Linear(14, 512)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(256, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e6ddc-37c5-4a04-ba53-7215bb513904",
   "metadata": {},
   "source": [
    "# assigning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "97b03167-c1a8-48ce-887b-80a9d50f7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignModel:\n",
    "    def __init__(self, global_model_base_path, selected_clients,algo=\"FF\"):      \n",
    "        self.global_model_path = f\"{global_model_base_path}/global_model_{algo}.pt\"\n",
    "        self.selected_clients = selected_clients\n",
    "\n",
    "    def save_global_model(self, model):\n",
    "        torch.save(model.state_dict(), self.global_model_path)\n",
    "\n",
    "    def save_client_models(self, model):\n",
    "        for client_id in self.selected_clients:\n",
    "            client_model_path = f\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/client_{client_id}_model.pth\"\n",
    "            torch.save(model.state_dict(), client_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52352bb-381e-4af7-baf1-e5900e214c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a24c1cb2-bf5f-4164-a4d5-9251d6358acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, batch_size):\n",
    "        self.client_id: int = None\n",
    "        self.valset: DataLoader = None\n",
    "        self.trainset: DataLoader = None\n",
    "        self.testset: DataLoader = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")         \n",
    "        self.model = DeepNet().to(self.device)\n",
    "        self.learning_rate=0.001\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "        self.optimizer: torch.optim.Optimizer = torch.optim.Adam(\n",
    "            self.model.parameters(), lr=self.learning_rate\n",
    "        )\n",
    "        \n",
    "        self.Batch = batch_size\n",
    "\n",
    "        self.fainess_score=0\n",
    "        self.local_epochs=5\n",
    "        self.client_df = pd.DataFrame()\n",
    "        self.selected_clients=[0,1,2,3]\n",
    "\n",
    "        self.client_fairness=0\n",
    "        self.global_fairness=0\n",
    "\n",
    "        \n",
    "    def get_client_local_dataset(self):\n",
    "                \n",
    "        temp_path_data=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/data_fairFed\"\n",
    "        \n",
    "        with open(temp_path_data+\"/clients_training.pkl\", \"rb\") as f:\n",
    "            self.trainset = pickle.load(f)\n",
    "            \n",
    "        with open(temp_path_data+\"/clients_validation.pkl\", \"rb\") as f:\n",
    "            self.valset = pickle.load(f)\n",
    "         \n",
    "        with open(temp_path_data+\"/clients_testing_wrong.pkl\", \"rb\") as f:\n",
    "            self.testset  = pickle.load(f)\n",
    "\n",
    "        self.trainset = self.trainset[self.client_id]\n",
    "        self.valset = self.valset[self.client_id]       \n",
    "        self.testset = self.testset[self.client_id]\n",
    "\n",
    "    def get_stats(self):\n",
    "        # 1 male 0 female\n",
    "        total_pr_Y1_A0 = 0\n",
    "        total_pr_Y1_A1 = 0\n",
    "        len_of_entire_data=0\n",
    "        \n",
    "        for client_id in self.selected_clients:\n",
    "            self.client_id=client_id\n",
    "            self.get_client_local_dataset()\n",
    "            len_of_entire_data+=len(self.trainset.dataset)\n",
    "            for inputs, labels, A in self.trainset:\n",
    "                pr_Y1_A1 = torch.sum((labels == 1) & (A == 1)).item()\n",
    "                pr_Y1_A0 = torch.sum((labels == 1) & (A == 0)).item()\n",
    "                # len_of_entire_data+=len(self.trainset)\n",
    "                total_pr_Y1_A1 += pr_Y1_A1\n",
    "                total_pr_Y1_A0 += pr_Y1_A0\n",
    "                \n",
    "            # print(\"len_of_entire_data::\",len_of_entire_data)\n",
    "            # print(\"pr_Y1_A1 and pr_Y1_A0\",total_pr_Y1_A1,\"::\",total_pr_Y1_A0)\n",
    "            # print(total_pr_Y1_A0/len(self.trainset),\" , \",print(total_pr_Y1_A1/len(self.trainset)))        \n",
    "        \n",
    "        return [total_pr_Y1_A1/len_of_entire_data,total_pr_Y1_A0/len_of_entire_data]\n",
    "        \n",
    "    def calculate_fairness_client(self,client_id,y_hat, A, Y,server_acc,client_acc,len_client_data):\n",
    "        # Calculate counts using torch.sum\n",
    "        y_hat, A, Y = y_hat.to(self.device), A.to(self.device), Y.to(self.device)\n",
    "\n",
    "        # 1: Male, 0: Female\n",
    "        predict_Y_male = torch.sum((y_hat[(A == 1) & (Y == 1)] == 1)).item()\n",
    "        predict_Y_female = torch.sum((y_hat[(A == 0) & (Y == 1)] == 1)).item()\n",
    "        \n",
    "        count_Y_male = torch.sum((Y[(A == 1) & (Y == 1)] == 1)).item()\n",
    "        count_Y_female = torch.sum((Y[(A == 0) & (Y == 1)] == 1)).item()\n",
    "    \n",
    "        # Calculate probabilities\n",
    "  \n",
    "        if count_Y_male > 0 and count_Y_female > 0:\n",
    "            prob_Y_male = predict_Y_male / count_Y_male\n",
    "            prob_Y_female = predict_Y_female / count_Y_female\n",
    "            fairness_score = prob_Y_male - prob_Y_female\n",
    "            \n",
    "        else:\n",
    "            # Cal sever_acc from client using Eq.\n",
    "            total_len_data=sum(len_client_data)   \n",
    "            temp_server_acc=0\n",
    "            # get global acc\n",
    "            for i in range(len(self.selected_clients)):\n",
    "                temp_server_acc+=client_acc[i]*(len_client_data[i]/total_len_data)\n",
    "                \n",
    "            fairness_score= abs(client_acc[client_id]-temp_server_acc)\n",
    "    \n",
    "            # print(\"\\n Else fairness_score\",fairness_score)\n",
    "            \n",
    "        # print(\" client fairness_score\",fairness_score)\n",
    "            \n",
    "        return  fairness_score\n",
    "\n",
    "    def calculate_ser_fairness(self,client_id,y_hat, A, Y,statistics,server_acc,client_acc,len_client_data):\n",
    "        # print(\"calculate_ser_fairness statistics\",statistics)\n",
    "        y_hat, A, Y = y_hat.to(self.device), A.to(self.device), Y.to(self.device)\n",
    "\n",
    "        # for individual clients!\n",
    "        #Pr(Ŷ=1|A=1, Y=1)  #male      \n",
    "        predict_Y_male = torch.sum((y_hat[(A == 1) & (Y == 1)] == 1)).item() #get total\n",
    "        #Pr(A=0, Y=1)\n",
    "        count_Y_male = torch.sum((A == 1) & (Y == 1)).item() \n",
    "        count_male = torch.sum(A == 1).item()\n",
    "        \n",
    "\n",
    "        #Pr(Ŷ=1|A=0, Y=1)  #Female      \n",
    "        predict_Y_female = torch.sum((y_hat[(A == 0) & (Y == 1)] == 1)).item()  #get total\n",
    "        #Pr(A=1, Y=1)\n",
    "        count_Y_female = torch.sum((A == 0) & (Y == 1)).item()\n",
    "        count_female = torch.sum(A == 0).item()\n",
    "\n",
    "        \n",
    "        \n",
    "        if count_Y_male>0 and count_male>0:\n",
    "            print(\"if_male\")\n",
    "            step_2_eq_male=count_Y_male/count_male            \n",
    "            predict_Y_male=predict_Y_male/count_Y_male #Pr(Ŷ=1|A=0, Y=1)            \n",
    "            step_3_male=((predict_Y_male * step_2_eq_male)/statistics[0]) \n",
    "        else:\n",
    "            print(\"else_male\")\n",
    "            step_3_male=0\n",
    "            \n",
    "        if count_Y_female>0 and count_female>0 :\n",
    "            print(\"if_female\")\n",
    "            step_2_eq_female=count_Y_female/count_female\n",
    "            predict_Y_female=predict_Y_female/count_Y_female   #Pr(Ŷ=1|A=1, Y=1)\n",
    "            step_3_female= ((predict_Y_female * step_2_eq_female)/statistics[1])\n",
    "        else:\n",
    "            print(\"else_female\")\n",
    "            step_3_female=0\n",
    "\n",
    "        temp_fairness_server=step_3_male-step_3_female\n",
    "            \n",
    "        # else:\n",
    "        #     print(\"else calculate_ser_fairness\")\n",
    "        #     # Cal sever_acc from client using Eq.\n",
    "        #     total_len_data=sum(len_client_data)   \n",
    "        #     temp_server_acc=0\n",
    "        #     for i in range(len(self.selected_clients)):\n",
    "        #         temp_server_acc+=client_acc[i]*(len_client_data[i]/total_len_data)\n",
    "                \n",
    "        #     fairness_score= abs(client_acc[client_id]-temp_server_acc)\n",
    "            \n",
    "        #     avg_acc_client=sum(client_acc) /len(client_acc)\n",
    "        #     temp_fairness_server= abs(avg_acc_client-server_acc)\n",
    "        #      abs(client_acc[client_id]-temp_server_acc)\n",
    "        #     # print(\"Else calculate_ser_fairness\",temp_fairness_server)\n",
    "\n",
    "        # print(\"calculate_ser_fairness temp_fairness_server\",self.client_id,temp_fairness_server)\n",
    "        return temp_fairness_server\n",
    "\n",
    "    def train_FA(self, client_id: int, model_path,learning_rate=0.001,num_epochs=5):\n",
    "        self.model.load_state_dict(torch.load(model_path,map_location=self.device))\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"epoch\",epoch)\n",
    "            for x, y,z in self.trainset:\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                logits = self.model(x)\n",
    "                loss = self.criterion(logits, y)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "        models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "        model_path_1 = os.path.join(models_directory, f\"client_{client_id}_model.pth\")          \n",
    "        torch.save(self.model.state_dict(), model_path_1)\n",
    "        print(f\"client_{client_id} is updated \\n\\n\\n\" )\n",
    "                \n",
    "        return list(self.model.state_dict().values()), len(self.trainset.dataset)\n",
    "       \n",
    "        \n",
    "    def train_FF(self, client_id: int, model_path,statistics,server_acc,clients_acc,len_client_data, num_epochs=5, learning_rate=0.001):\n",
    "        self.client_id = client_id\n",
    "        self.get_client_local_dataset()\n",
    "        # print(\"len_of_entire_data FF\",len(self.trainset))\n",
    "        # Define loss function and optimizer\n",
    "        \n",
    "        self.fainess_score=0\n",
    "      \n",
    "        self.model.load_state_dict(torch.load(model_path,map_location=self.device))\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            # Set the model to training mode\n",
    "\n",
    "            for inputs, labels, sens in self.trainset:\n",
    "                \n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs).to(self.device)\n",
    "                loss = self.criterion(outputs, labels.float())\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # Calculate and print the training accuracy for this epoch (optional)\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            size = 0\n",
    "            loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            predicted_labels = []\n",
    "            true_labels = []\n",
    "            final_fairness=[]\n",
    "            final_fairness_server=[]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                print(\"======Validation========\")\n",
    "                for inputs, labels,sens in self.valset:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    outputs = self.model(inputs)\n",
    "                    loss += self.criterion(outputs, labels)\n",
    "                    predicted = outputs > 0.5\n",
    "\n",
    "                    predicted_labels.extend(predicted.cpu().numpy())\n",
    "                    true_labels.extend(labels.cpu().numpy())                   \n",
    "                    \n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()                   \n",
    "\n",
    "            loss = loss / len(self.valset)        \n",
    "            acc = correct/total\n",
    " \n",
    "            fairNess_per_batch=self.calculate_fairness_client(self.client_id,torch.round(outputs).squeeze(), sens.squeeze(), labels.squeeze(),\n",
    "                                                       server_acc,\n",
    "                                                       clients_acc,\n",
    "                                                       len_client_data)\n",
    "            final_fairness.append(fairNess_per_batch)\n",
    "            self.fainess_score=np.mean(final_fairness)\n",
    "\n",
    "            #this is needed for Eq.7: global fairness\n",
    "            fairNess_per_batch_server=self.calculate_ser_fairness(self.client_id,torch.round(outputs).squeeze(), sens.squeeze(), labels.squeeze(),\n",
    "                                                                  statistics,\n",
    "                                                                  server_acc,\n",
    "                                                                  clients_acc,\n",
    "                                                                  len_client_data)\n",
    "            final_fairness_server.append(fairNess_per_batch_server)            \n",
    "            ser_score=np.mean(final_fairness_server)\n",
    "                        \n",
    "            precision = precision_score(true_labels, predicted_labels,zero_division=0.0)            \n",
    "            recall = recall_score(true_labels, predicted_labels)\n",
    "            \n",
    "            # accuracy = 100 * correct / total\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Val Accuracy: {acc:.5f}\")\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Val Fairness: {self.fainess_score:.5f}\")\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Val Recall: {recall:.5f}\")\n",
    "\n",
    "\n",
    "        # Optionally, save the trained model parameters\n",
    "        #store model client model\n",
    "        models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "        model_path_1 = os.path.join(models_directory, f\"client_{client_id}_model.pth\")          \n",
    "        torch.save(self.model.state_dict(), model_path_1)\n",
    "        print(f\"client_{client_id} is updated and its fairness score wrt global_model {ser_score} \\n\\n\\n\" )\n",
    "\n",
    "        \n",
    "        return list(self.model.state_dict().values()), len(self.trainset.dataset),self.model.state_dict(), self.fainess_score, ser_score\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def client_evaluate(self, val=False):\n",
    "        \n",
    "        size = 0\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "        len_of_data=[]\n",
    "        all_client_acc=[]\n",
    "        \n",
    "        models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "                 \n",
    "        for client_id in self.selected_clients:\n",
    "            \n",
    "            model_path = os.path.join(models_directory, f\"client_{client_id}_model.pth\")            \n",
    "        \n",
    "            self.model.load_state_dict(torch.load(model_path,map_location=self.device))\n",
    "\n",
    "            self.model.eval()\n",
    "\n",
    "            for inputs, targets,sens in self.testset:\n",
    "                \n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                loss += self.criterion(outputs, targets)\n",
    "                predicted = outputs > 0.5\n",
    "                \n",
    "                predicted_labels.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(targets.cpu().numpy())\n",
    "                \n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "                \n",
    "                len_of_data.append(len(self.testset))\n",
    "            \n",
    "            loss = loss / len(self.testset)\n",
    "            acc = correct / total\n",
    "            all_client_acc.append(acc)\n",
    "                        \n",
    "            precision = precision_score(true_labels, predicted_labels,zero_division=0.0)\n",
    "            \n",
    "            recall = recall_score(true_labels, predicted_labels)\n",
    "                            \n",
    "        return loss, acc, precision, recall,len_of_data, all_client_acc\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def server_evaluate(self,path,statistics,all_client_acc,len_of_data):\n",
    "\n",
    "        # print(\"Global Model testing Starts\")\n",
    "        # print(\"kindly check the Path. Select it based on FedAvg Model\")\n",
    "        # print(\"warning: Test data has already been used\")\n",
    "        temp_path_data=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/\"\n",
    "\n",
    "        with open(temp_path_data+\"/testing_client.pkl\", \"rb\") as f:\n",
    "            testset  = pickle.load(f)\n",
    "            \n",
    "        \n",
    "        # path=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model_2.pt\"\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(path,map_location=self.device))\n",
    "        self.model.eval()\n",
    "        size = 0\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "        final_fairness=[]\n",
    "\n",
    "        self.testset=testset[1]\n",
    "        for inputs, targets,sens in self.testset:\n",
    "            \n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "            \n",
    "            outputs = self.model(inputs)\n",
    "            loss += self.criterion(outputs, targets)\n",
    "            predicted = outputs > 0.5\n",
    "\n",
    "            \n",
    "#            print(\"predicted\",predicted)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(targets.cpu().numpy())\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "        \n",
    "        loss = loss / len(self.testset)\n",
    "        ser_acc = correct / total\n",
    "        \n",
    "        fairNess_per_batch=self.calculate_ser_fairness(self.client_id,torch.round(outputs).squeeze(), sens.squeeze(),\n",
    "                                                                   targets.squeeze(),\n",
    "                                                                  statistics,\n",
    "                                                                  ser_acc,\n",
    "                                                                  all_client_acc,\n",
    "                                                                  len_of_data)\n",
    "        \n",
    "        # fairNess_per_batch=self.calculate_ser_fairness(torch.round(outputs).squeeze(), sens.squeeze(), targets.squeeze(),\n",
    "        #                                             ser_acc,\n",
    "        #                                             all_client_acc,\n",
    "        #                                             len_of_data)\n",
    "        final_fairness.append(fairNess_per_batch)\n",
    "        fairness_global=np.mean(final_fairness)\n",
    "\n",
    "        # print(\"loss: %f\\n\" % (loss))\n",
    "        \n",
    "        # print(f\"Global Testing Accuracy: {ser_acc:.5%}\")\n",
    "        # print(f\" Global Fairness: {fairness_global:.5f}%\")\n",
    "        precision = precision_score(true_labels, predicted_labels,zero_division=0.0)\n",
    "        \n",
    "        recall = recall_score(true_labels, predicted_labels)\n",
    "        \n",
    "        # print(f\"Global Precision: {precision:.5%}\")\n",
    "        # print(f\"Global Recall: {recall:.5%}\")\n",
    "        \n",
    "        return loss, ser_acc, precision, recall,fairness_global\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b458637-f192-4be8-b5eb-9f20e7ce4e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "199eb51c-d78b-44f1-86b0-e8b325ce899c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Serverbase:\n",
    "    def __init__ (self,model):\n",
    "        self.model = model\n",
    "        self.global_model=model\n",
    "        self.num_rounds=2\n",
    "        self.local_epoch=2\n",
    "        self.optimizer=2\n",
    "        self.lr=0.001\n",
    "        self.beta=1\n",
    "        self.batch_size=32\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    \n",
    "        self.updated_params_cache = []\n",
    "        self.weights_cache = []\n",
    "        self.model_dict = []\n",
    "        \n",
    "        self.global_params_dict: OrderedDict[str : torch.Tensor] = None\n",
    "\n",
    "        self.backbone=DeepNet\n",
    "        _dummy_model = self.backbone()\n",
    "        self.global_params_dict = OrderedDict(_dummy_model.state_dict())\n",
    "\n",
    "        self.temp_dir=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "\n",
    "        self.fair_global_t_step=0\n",
    "        self.fair_local_client=0   \n",
    "        \n",
    "        self.acc_clients=[]\n",
    "        self.clients_id=[]\n",
    "        self.precision_clients=[]\n",
    "        self.recall_clients=[]\n",
    "        \n",
    "        self.global_acc=0\n",
    "        self.fairness_diff=[]\n",
    "        self.clients_weights=[]\n",
    "        self.final_agg_weights_clients=[]\n",
    "        self.selected_clients=[0,1,2,3]\n",
    "        self.statistics=0\n",
    "\n",
    "    def global_fairness(self,weights, temp_ser_fairness): \n",
    "        # all_clients_fairness is based on equation: 7\n",
    "        # upper part is done in client class\n",
    "        # self.statistics cal. pr(y=1,a=0)\n",
    "        \n",
    "        # print(\"global_fairness::\",all_clients_fairness)\n",
    "        # print(\"weights::\",weights)\n",
    "        \n",
    "        weight_sum = sum(weights)  \n",
    "        final_global_score=0\n",
    "        \n",
    "        for i in range(len(temp_ser_fairness)):\n",
    "            temp=weights[i]/weight_sum            \n",
    "            final_global_score+=temp*temp_ser_fairness[i]\n",
    "            \n",
    "        self.fair_global=final_global_score\n",
    "\n",
    "    \n",
    "        \n",
    "    def fedAlgo(self, num_rounds = 2, local_epochs = 2, learning_rate = 0.001, beta = 1, optimizer = 'adam',algo=\"FF\"):\n",
    "        \n",
    "        client = Client(batch_size=64)\n",
    "        path=f\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model_{algo}.pt\"\n",
    "        models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "        \n",
    "        #before we start the training, we need statistics\n",
    "        print(\"Getting data statistics....\")\n",
    "        self.statistics= client.get_stats()      \n",
    "        \n",
    "        print(\"self.statistics\",self.statistics)\n",
    "        for round_ in tqdm(range(num_rounds)):\n",
    "  \n",
    "            #each round we need empty lists\n",
    "            self.updated_params_cache = []\n",
    "            self.weights_cache = []\n",
    "            self.model_dict=[]\n",
    "            self.clients_weights=[]\n",
    "            self.final_agg_weights_clients=[]\n",
    "            self.fair_global=0\n",
    "            self.fair_local_all_client=[]\n",
    "            temp_ser_fairness=[]\n",
    "\n",
    "            print (\"round::\",round_)\n",
    "            \n",
    "             # clients and server acc for calculating Fairness whenever fairness_client is undefined\n",
    "        \n",
    "            loss_client, acc_client,precision, recall,len_of_data,all_client_acc = client.client_evaluate() \n",
    "\n",
    "            # to ge the acc of global model \n",
    "            loss_client, accuracy_server, pre_server, recall_ser,fairness_global = client.server_evaluate(path,self.statistics,all_client_acc,len_of_data)\n",
    "\n",
    "            \n",
    "            for client_id in self.selected_clients:\n",
    "                self.global_acc=0\n",
    "                \n",
    "                \n",
    "                # weight is length of dataset\n",
    "                \n",
    "                # Clone the model from server and assign it back to the clients\n",
    "                model_path=os.path.join(self.temp_dir, f\"global_model_{algo}.pt\") \n",
    "\n",
    "                if algo==\"FF\":\n",
    "                    \n",
    "                    updated_params, weight, model_dict_list,fairness_client,ser_fairness = client.train_FF(client_id, \n",
    "                                                                                                             model_path, \n",
    "                                                                                                             statistics=self.statistics,\n",
    "                                                                                                             server_acc=accuracy_server,\n",
    "                                                                                                             clients_acc=all_client_acc,\n",
    "                                                                                                             len_client_data=len_of_data,\n",
    "                                                                                                             num_epochs=local_epochs, \n",
    "                                                                                                             learning_rate=learning_rate)        \n",
    "                                \n",
    "                    print(\"updated_params FF\",type(updated_params[0]))\n",
    "                    self.updated_params_cache.append(updated_params)\n",
    "                    #not sure how to pass updated weights to next round\n",
    "                    self.weights_cache.append(weight)\n",
    "                    self.model_dict.append(model_dict_list)\n",
    "                    temp_ser_fairness.append(ser_fairness)\n",
    "                    \n",
    "                    \n",
    "                    # self.global_acc=acc_server\n",
    "                    self.fair_local_client=fairness_client\n",
    "                    self.fair_local_all_client.append(fairness_client)\n",
    "                \n",
    "                if algo==\"FA\":\n",
    "                    updated_params, weight, = client.train_FA(client_id, model_path,\n",
    "                                                              num_epochs=local_epochs,\n",
    "                                                              learning_rate=learning_rate)\n",
    "                                                                                            \n",
    "                                \n",
    "                    # store it for SecAgg\n",
    "                    self.updated_params_cache.append(updated_params)\n",
    "                    self.weights_cache.append(weight)\n",
    "                    \n",
    "\n",
    "            print(\"temp_ser_fairness::\",temp_ser_fairness)\n",
    "            self.global_fairness(self.weights_cache, temp_ser_fairness)\n",
    "\n",
    "            print(\"for round\", round_,\", global fairness, accuracy, and recall are: \",self.fair_global,\", \",\n",
    "                                                                                  accuracy_server,\", \",\n",
    "                                                                                  recall_ser,\"\\n\\n\\n\")\n",
    "            \n",
    "            if algo==\"FF\":\n",
    "                # agg all the weights on serverside\n",
    "                # Update the weights of each client\n",
    "                self.aggregate_client_weight_FedFair_FedAVG(self.updated_params_cache,self.model_dict, self.weights_cache,self.acc_clients,\n",
    "                                                            self.global_acc,self.fair_local_client,\n",
    "                                                             self.fair_global, self.fair_local_all_client)\n",
    "                \n",
    "                # self.aggregate_client_weight_FedFair_part_1(self.model_dict, self.weights_cache,self.acc_clients,\n",
    "                #                                             self.global_acc,self.fair_local_client,\n",
    "                #                                              self.fair_global, self.fair_local_all_client)\n",
    "                # self.client_weights_update_part_2(self.clients_weights)\n",
    "                # self.aggregate_parameters_FedAvg_updated(self.final_agg_weights_clients)\n",
    "                \n",
    "            elif algo==\"FA\":\n",
    "                self.aggregate_parameters_FedAvg(self.updated_params_cache,self.weights_cache)\n",
    "            else:\n",
    "                print(\"--Choose Algo --\")\n",
    "                break\n",
    "        \n",
    "            \n",
    "            torch.save(self.global_model.state_dict(), os.path.join(self.temp_dir, f\"global_model_{algo}.pt\"),)\n",
    "\n",
    "            \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def aggregate_parameters_FedAvg(self, updated_params_cache, weights_cache):\n",
    "        weight_sum = sum(weights_cache)  \n",
    "        \n",
    "        weights = torch.tensor(weights_cache, device=self.device) / weight_sum\n",
    "        \n",
    "        aggregated_params = []\n",
    "\n",
    "        for params in zip(*updated_params_cache):\n",
    "            aggregated_params.append(\n",
    "                torch.sum(weights * torch.stack(params, dim=-1), dim=-1)\n",
    "            )\n",
    "        \n",
    "        aggregated_model_params = {}\n",
    "        global_state_dict_keys = list(self.global_model.state_dict().keys())\n",
    "        \n",
    "        for param_name, param_value in zip(global_state_dict_keys, aggregated_params):\n",
    "            aggregated_model_params[param_name] = param_value\n",
    "\n",
    "\n",
    "        # aggregated_model_params = {param_name: param_value for param_name, param_value in zip(self.global_model.state_dict().keys(), aggregated_params)}\n",
    "\n",
    "        self.global_model.load_state_dict(aggregated_model_params)\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def aggregate_client_weight_FedFair_FedAVG (self,updated_params_cache, model_dict_list ,weights_cache, acc_clients, global_acc,fairness_client,fairness_global,fairness_all_client):\n",
    "\n",
    "        mean_fairness=np.mean(fairness_all_client)\n",
    "        \n",
    "        # Delta_t_C_i = abs(self.fair_global - self.fair_local_client) \n",
    "        \n",
    "        temp=weights_cache\n",
    "        temp_list=[]\n",
    "        \n",
    "        # print(\"client fairness\",fairness_all_client)\n",
    "        print(\"fair_global\",self.fair_global)\n",
    "        print(\"weights_cache:: \",weights_cache)\n",
    "        for i in range(len(temp)):\n",
    "             Delta_t_C_i=abs(self.fair_global-fairness_all_client[i])\n",
    "             self.weights_cache[i]=temp[i]-(self.beta*(Delta_t_C_i-mean_fairness))\n",
    "             print(\"self.weights_cache[i] \",self.weights_cache[i])\n",
    "\n",
    "        weights_cache=self.weights_cache\n",
    "        weight_sum = sum(weights_cache)  \n",
    "        \n",
    "        weights = torch.tensor(weights_cache, device=self.device) / weight_sum\n",
    "        \n",
    "        aggregated_params = []\n",
    "\n",
    "        for params in zip(*updated_params_cache):\n",
    "            aggregated_params.append(\n",
    "                torch.sum(weights * torch.stack(params, dim=-1), dim=-1)\n",
    "            )\n",
    "        \n",
    "        aggregated_model_params = {}\n",
    "        global_state_dict_keys = list(self.global_model.state_dict().keys())\n",
    "        \n",
    "        for param_name, param_value in zip(global_state_dict_keys, aggregated_params):\n",
    "            aggregated_model_params[param_name] = param_value\n",
    "\n",
    "  \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def aggregate_parameters_FedAvg_updated(self, model_dict_list):        \n",
    "        w_avg = copy.deepcopy(model_dict_list[0])\n",
    "        for k in w_avg.keys():\n",
    "            for i in range(1, len(model_dict_list)):\n",
    "                w_avg[k] += model_dict_list[i][k]\n",
    "            w_avg[k] = torch.div(w_avg[k], len(model_dict_list))\n",
    "    \n",
    "        self.global_model.load_state_dict(w_avg)\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def aggregate_client_weight_FedFair_part_1 (self, model_dict_list ,weights_cache, acc_clients, global_acc,fairness_client,fairness_global,fairness_all_client):\n",
    "\n",
    "        \n",
    "        Delta_t_C_i = abs(self.fair_global - self.fair_local_client) \n",
    "        \n",
    "        \n",
    "        for client_id in range(len(self.selected_clients)):\n",
    "        \n",
    "            w_avg = copy.deepcopy(model_dict_list[client_id])\n",
    "            temp = copy.deepcopy(model_dict_list[client_id])\n",
    "            \n",
    "            for k in w_avg.keys():\n",
    "                for i in range(1, len(model_dict_list)):\n",
    "                    w_avg[k] += model_dict_list[i][k]\n",
    "                w_avg[k] = torch.div(w_avg[k], len(model_dict_list))\n",
    "                \n",
    "                w_avg[k]=temp[k]-(self.beta*(Delta_t_C_i-w_avg[k]))\n",
    "                \n",
    "            self.clients_weights.append(w_avg)\n",
    "\n",
    "            \n",
    "    def client_weights_update_part_2(self,agg_weights):\n",
    "        # print(\"Before agg_weights:: \", agg_weights[0]['layer1.weight'])     .\n",
    "        # total_weights=0\n",
    "        # for model in agg_weights:\n",
    "        #     for param in model.values():\n",
    "        #         total_weights += param.sum().item()\n",
    "        \n",
    "        # print(\"\\n total_weights\",total_weights)   \n",
    "        \n",
    "        temp=copy.deepcopy(agg_weights)\n",
    "        sum_params = temp[0]\n",
    "        \n",
    "        for model in temp[1:]:\n",
    "            for name, param in model.items():\n",
    "                \n",
    "                if name in sum_params:\n",
    "                    sum_params[name] += param\n",
    "                    \n",
    "        total_sum = sum(torch.sum(param) for param in sum_params.values())  \n",
    "        print(\"\\ntotal_sum\",total_sum)\n",
    "        \n",
    "        for model in agg_weights:\n",
    "             for name in model.keys():\n",
    "                 # print(\"name\",name,\"\\n\")\n",
    "                 # print(\"\\n model\",model[name])\n",
    "                 # print(\"\\n sum_params[name]\",sum_params[name])               \n",
    "                 # print(\"\\n model[name]  /= sum_params[name]\",model[name]  /total_sum)\n",
    "                 \n",
    "                 # model[name]  /= sum_params[name]\n",
    "                 model[name]  /= total_sum\n",
    "             # print(\"type of mdoel\", model)\n",
    "             self.final_agg_weights_clients.append(model)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf995c8-5238-44f1-aa4d-e927101b0a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bb97600f-7474-47ae-bd82-89bcad80e6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm is  FF\n",
      "Getting data statistics....\n",
      "self.statistics [0.21462357114702404, 0.1967327990189638]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                   | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round:: 0\n",
      "if_male\n",
      "if_female\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 1/4, Val Accuracy: 0.77987\n",
      "Epoch 1/4, Val Fairness: 0.37764\n",
      "Epoch 1/4, Val Recall: 0.72246\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 2/4, Val Accuracy: 0.78961\n",
      "Epoch 2/4, Val Fairness: 0.37764\n",
      "Epoch 2/4, Val Recall: 0.63907\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 3/4, Val Accuracy: 0.78701\n",
      "Epoch 3/4, Val Fairness: 0.37764\n",
      "Epoch 3/4, Val Recall: 0.63725\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 4/4, Val Accuracy: 0.78723\n",
      "Epoch 4/4, Val Fairness: 0.37764\n",
      "Epoch 4/4, Val Recall: 0.75472\n",
      "client_0 is updated and its fairness score wrt global_model 1.9413835322926234 \n",
      "\n",
      "\n",
      "\n",
      "updated_params FF <class 'torch.Tensor'>\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 1/4, Val Accuracy: 0.76779\n",
      "Epoch 1/4, Val Fairness: 0.37764\n",
      "Epoch 1/4, Val Recall: 0.78320\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 2/4, Val Accuracy: 0.77070\n",
      "Epoch 2/4, Val Fairness: 0.37764\n",
      "Epoch 2/4, Val Recall: 0.77885\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 3/4, Val Accuracy: 0.77507\n",
      "Epoch 3/4, Val Fairness: 0.37764\n",
      "Epoch 3/4, Val Recall: 0.79334\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 4/4, Val Accuracy: 0.77980\n",
      "Epoch 4/4, Val Fairness: 0.37764\n",
      "Epoch 4/4, Val Recall: 0.81603\n",
      "client_1 is updated and its fairness score wrt global_model -1.8483769124908929 \n",
      "\n",
      "\n",
      "\n",
      "updated_params FF <class 'torch.Tensor'>\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 1/4, Val Accuracy: 0.79635\n",
      "Epoch 1/4, Val Fairness: 0.37764\n",
      "Epoch 1/4, Val Recall: 0.77384\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 2/4, Val Accuracy: 0.79069\n",
      "Epoch 2/4, Val Fairness: 0.37764\n",
      "Epoch 2/4, Val Recall: 0.69968\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 3/4, Val Accuracy: 0.80952\n",
      "Epoch 3/4, Val Fairness: 0.37764\n",
      "Epoch 3/4, Val Recall: 0.77899\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 4/4, Val Accuracy: 0.81189\n",
      "Epoch 4/4, Val Fairness: 0.37764\n",
      "Epoch 4/4, Val Recall: 0.78782\n",
      "client_2 is updated and its fairness score wrt global_model 1.4459960102593332 \n",
      "\n",
      "\n",
      "\n",
      "updated_params FF <class 'torch.Tensor'>\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 1/4, Val Accuracy: 0.76899\n",
      "Epoch 1/4, Val Fairness: 0.37764\n",
      "Epoch 1/4, Val Recall: 0.72472\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 2/4, Val Accuracy: 0.75567\n",
      "Epoch 2/4, Val Fairness: 0.37764\n",
      "Epoch 2/4, Val Recall: 0.86518\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 3/4, Val Accuracy: 0.77629\n",
      "Epoch 3/4, Val Fairness: 0.37764\n",
      "Epoch 3/4, Val Recall: 0.80399\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████▊                                               | 1/5 [00:25<01:41, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "else_male\n",
      "if_female\n",
      "Epoch 4/4, Val Accuracy: 0.78084\n",
      "Epoch 4/4, Val Fairness: 0.37764\n",
      "Epoch 4/4, Val Recall: 0.76045\n",
      "client_3 is updated and its fairness score wrt global_model -5.083036509349955 \n",
      "\n",
      "\n",
      "\n",
      "updated_params FF <class 'torch.Tensor'>\n",
      "temp_ser_fairness:: [1.9413835322926234, -1.8483769124908929, 1.4459960102593332, -5.083036509349955]\n",
      "for round 0 , global fairness, accuracy, and recall are:  -1.0929001368820122 ,  0.3668816454592993 ,  1.0 \n",
      "\n",
      "\n",
      "\n",
      "fair_global -1.0929001368820122\n",
      "weights_cache::  [27424, 28357, 40171, 41046]\n",
      "self.weights_cache[i]  27422.907099863118\n",
      "self.weights_cache[i]  28355.907099863118\n",
      "self.weights_cache[i]  40169.90709986312\n",
      "self.weights_cache[i]  41044.90709986312\n",
      "round:: 1\n",
      "if_male\n",
      "if_female\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 1/4, Val Accuracy: 0.77013\n",
      "Epoch 1/4, Val Fairness: 0.76311\n",
      "Epoch 1/4, Val Recall: 0.51430\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 2/4, Val Accuracy: 0.78203\n",
      "Epoch 2/4, Val Fairness: 0.76311\n",
      "Epoch 2/4, Val Recall: 0.71698\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 3/4, Val Accuracy: 0.79307\n",
      "Epoch 3/4, Val Fairness: 0.76311\n",
      "Epoch 3/4, Val Recall: 0.69507\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 4/4, Val Accuracy: 0.79351\n",
      "Epoch 4/4, Val Fairness: 0.76311\n",
      "Epoch 4/4, Val Recall: 0.73463\n",
      "client_0 is updated and its fairness score wrt global_model 2.329660238751148 \n",
      "\n",
      "\n",
      "\n",
      "updated_params FF <class 'torch.Tensor'>\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 1/4, Val Accuracy: 0.76579\n",
      "Epoch 1/4, Val Fairness: 0.76890\n",
      "Epoch 1/4, Val Recall: 0.77740\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 2/4, Val Accuracy: 0.77489\n",
      "Epoch 2/4, Val Fairness: 0.76890\n",
      "Epoch 2/4, Val Recall: 0.74988\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 3/4, Val Accuracy: 0.77598\n",
      "Epoch 3/4, Val Fairness: 0.76890\n",
      "Epoch 3/4, Val Recall: 0.70739\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 4/4, Val Accuracy: 0.76815\n",
      "Epoch 4/4, Val Fairness: 0.76890\n",
      "Epoch 4/4, Val Recall: 0.84742\n",
      "client_1 is updated and its fairness score wrt global_model -2.033214603739982 \n",
      "\n",
      "\n",
      "\n",
      "updated_params FF <class 'torch.Tensor'>\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 1/4, Val Accuracy: 0.79022\n",
      "Epoch 1/4, Val Fairness: 0.77269\n",
      "Epoch 1/4, Val Recall: 0.72849\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 2/4, Val Accuracy: 0.78734\n",
      "Epoch 2/4, Val Fairness: 0.77269\n",
      "Epoch 2/4, Val Recall: 0.68166\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 3/4, Val Accuracy: 0.80247\n",
      "Epoch 3/4, Val Fairness: 0.77269\n",
      "Epoch 3/4, Val Recall: 0.73290\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 4/4, Val Accuracy: 0.81420\n",
      "Epoch 4/4, Val Fairness: 0.77269\n",
      "Epoch 4/4, Val Recall: 0.78328\n",
      "client_2 is updated and its fairness score wrt global_model 1.4459960102593332 \n",
      "\n",
      "\n",
      "\n",
      "updated_params FF <class 'torch.Tensor'>\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 1/4, Val Accuracy: 0.76434\n",
      "Epoch 1/4, Val Fairness: 0.77427\n",
      "Epoch 1/4, Val Recall: 0.78808\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 2/4, Val Accuracy: 0.77053\n",
      "Epoch 2/4, Val Fairness: 0.77427\n",
      "Epoch 2/4, Val Recall: 0.77752\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 3/4, Val Accuracy: 0.76708\n",
      "Epoch 3/4, Val Fairness: 0.77427\n",
      "Epoch 3/4, Val Recall: 0.83307\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████▌                                   | 2/5 [00:51<01:16, 25.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "else_male\n",
      "if_female\n",
      "Epoch 4/4, Val Accuracy: 0.77804\n",
      "Epoch 4/4, Val Fairness: 0.77427\n",
      "Epoch 4/4, Val Recall: 0.82424\n",
      "client_3 is updated and its fairness score wrt global_model -5.083036509349955 \n",
      "\n",
      "\n",
      "\n",
      "updated_params FF <class 'torch.Tensor'>\n",
      "temp_ser_fairness:: [2.329660238751148, -2.033214603739982, 1.4459960102593332, -5.083036509349955]\n",
      "for round 1 , global fairness, accuracy, and recall are:  -1.053434903906581 ,  0.6331183545407008 ,  0.0 \n",
      "\n",
      "\n",
      "\n",
      "fair_global -1.053434903906581\n",
      "weights_cache::  [27424, 28357, 40171, 41046]\n",
      "self.weights_cache[i]  27422.953193572503\n",
      "self.weights_cache[i]  28355.947410215416\n",
      "self.weights_cache[i]  40169.943618599\n",
      "self.weights_cache[i]  41044.942037997454\n",
      "round:: 2\n",
      "if_male\n",
      "if_female\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 1/4, Val Accuracy: 0.75952\n",
      "Epoch 1/4, Val Fairness: 0.77133\n",
      "Epoch 1/4, Val Recall: 0.76446\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 2/4, Val Accuracy: 0.78225\n",
      "Epoch 2/4, Val Fairness: 0.77133\n",
      "Epoch 2/4, Val Recall: 0.69020\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 3/4, Val Accuracy: 0.78528\n",
      "Epoch 3/4, Val Fairness: 0.77133\n",
      "Epoch 3/4, Val Recall: 0.67377\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 4/4, Val Accuracy: 0.79199\n",
      "Epoch 4/4, Val Fairness: 0.77133\n",
      "Epoch 4/4, Val Recall: 0.74680\n",
      "client_0 is updated and its fairness score wrt global_model 1.9413835322926234 \n",
      "\n",
      "\n",
      "\n",
      "updated_params FF <class 'torch.Tensor'>\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 1/4, Val Accuracy: 0.76360\n",
      "Epoch 1/4, Val Fairness: 0.77037\n",
      "Epoch 1/4, Val Recall: 0.77740\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 2/4, Val Accuracy: 0.77434\n",
      "Epoch 2/4, Val Fairness: 0.77037\n",
      "Epoch 2/4, Val Recall: 0.73636\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 3/4, Val Accuracy: 0.78344\n",
      "Epoch 3/4, Val Fairness: 0.77037\n",
      "Epoch 3/4, Val Recall: 0.73829\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 4/4, Val Accuracy: 0.78089\n",
      "Epoch 4/4, Val Fairness: 0.77037\n",
      "Epoch 4/4, Val Recall: 0.79961\n",
      "client_1 is updated and its fairness score wrt global_model -1.9407957581154374 \n",
      "\n",
      "\n",
      "\n",
      "updated_params FF <class 'torch.Tensor'>\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 1/4, Val Accuracy: 0.79930\n",
      "Epoch 1/4, Val Fairness: 0.77401\n",
      "Epoch 1/4, Val Recall: 0.79014\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 2/4, Val Accuracy: 0.80548\n",
      "Epoch 2/4, Val Fairness: 0.77401\n",
      "Epoch 2/4, Val Recall: 0.80755\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 3/4, Val Accuracy: 0.81068\n",
      "Epoch 3/4, Val Fairness: 0.77401\n",
      "Epoch 3/4, Val Recall: 0.76857\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 4/4, Val Accuracy: 0.81570\n",
      "Epoch 4/4, Val Fairness: 0.77401\n",
      "Epoch 4/4, Val Recall: 0.81454\n",
      "client_2 is updated and its fairness score wrt global_model 1.4459960102593332 \n",
      "\n",
      "\n",
      "\n",
      "updated_params FF <class 'torch.Tensor'>\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 1/4, Val Accuracy: 0.76275\n",
      "Epoch 1/4, Val Fairness: 0.77538\n",
      "Epoch 1/4, Val Recall: 0.68856\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 2/4, Val Accuracy: 0.77360\n",
      "Epoch 2/4, Val Fairness: 0.77538\n",
      "Epoch 2/4, Val Recall: 0.75886\n",
      "======Validation========\n",
      "else_male\n",
      "if_female\n",
      "Epoch 3/4, Val Accuracy: 0.77267\n",
      "Epoch 3/4, Val Fairness: 0.77538\n",
      "Epoch 3/4, Val Recall: 0.83972\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████▍                       | 3/5 [01:17<00:51, 25.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "else_male\n",
      "if_female\n",
      "Epoch 4/4, Val Accuracy: 0.77645\n",
      "Epoch 4/4, Val Fairness: 0.77538\n",
      "Epoch 4/4, Val Recall: 0.81513\n",
      "client_3 is updated and its fairness score wrt global_model -5.083036509349955 \n",
      "\n",
      "\n",
      "\n",
      "updated_params FF <class 'torch.Tensor'>\n",
      "temp_ser_fairness:: [1.9413835322926234, -1.9407957581154374, 1.4459960102593332, -5.083036509349955]\n",
      "for round 2 , global fairness, accuracy, and recall are:  -1.112029768010753 ,  0.6331183545407008 ,  0.0 \n",
      "\n",
      "\n",
      "\n",
      "fair_global -1.112029768010753\n",
      "weights_cache::  [27424, 28357, 40171, 41046]\n",
      "self.weights_cache[i]  27422.889416071263\n",
      "self.weights_cache[i]  28355.8903753959\n",
      "self.weights_cache[i]  40169.88672996228\n",
      "self.weights_cache[i]  41044.88535949852\n",
      "round:: 3\n",
      "else_male\n",
      "if_female\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 1/4, Val Accuracy: 0.77013\n",
      "Epoch 1/4, Val Fairness: 0.77182\n",
      "Epoch 1/4, Val Recall: 0.68168\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 2/4, Val Accuracy: 0.78355\n",
      "Epoch 2/4, Val Fairness: 0.77182\n",
      "Epoch 2/4, Val Recall: 0.72428\n",
      "======Validation========\n",
      "if_male\n",
      "else_female\n",
      "Epoch 3/4, Val Accuracy: 0.78268\n",
      "Epoch 3/4, Val Fairness: 0.77182\n",
      "Epoch 3/4, Val Recall: 0.70420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████▍                       | 3/5 [01:24<00:56, 28.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[186], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m DeepNet()\n\u001b[1;32m     25\u001b[0m server \u001b[38;5;241m=\u001b[39m Serverbase(model)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfedAlgo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlocal_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m)\u001b[49m  \n",
      "Cell \u001b[0;32mIn[185], line 103\u001b[0m, in \u001b[0;36mServerbase.fedAlgo\u001b[0;34m(self, num_rounds, local_epochs, learning_rate, beta, optimizer, algo)\u001b[0m\n\u001b[1;32m     99\u001b[0m model_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m algo\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFF\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 103\u001b[0m     updated_params, weight, model_dict_list,fairness_client,ser_fairness \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_FF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m                                                                                             \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                                                                                             \u001b[49m\u001b[43mstatistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m                                                                                             \u001b[49m\u001b[43mserver_acc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccuracy_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                                                                                             \u001b[49m\u001b[43mclients_acc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_client_acc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                                                                                             \u001b[49m\u001b[43mlen_client_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlen_of_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                                                                                             \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                                                                                             \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m        \n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdated_params FF\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28mtype\u001b[39m(updated_params[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdated_params_cache\u001b[38;5;241m.\u001b[39mappend(updated_params)\n",
      "Cell \u001b[0;32mIn[184], line 194\u001b[0m, in \u001b[0;36mClient.train_FF\u001b[0;34m(self, client_id, model_path, statistics, server_acc, clients_acc, len_client_data, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# Set the model to training mode\u001b[39;00m\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels, sens \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset:\n\u001b[1;32m    196\u001b[0m         inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    197\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inputs)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Downloads/Hiwi/gpu_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Downloads/Hiwi/gpu_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Downloads/Hiwi/gpu_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Downloads/Hiwi/gpu_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Downloads/Hiwi/gpu_env/lib/python3.10/site-packages/torch/utils/data/dataset.py:208\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Hiwi/gpu_env/lib/python3.10/site-packages/torch/utils/data/dataset.py:208\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# FairFed \"FF\" and FedAVG \"FA\"\n",
    "\n",
    "algo=\"FF\" \n",
    "\n",
    "if algo==\"FA\":\n",
    "    print(\"Comment out part1 and part2 def_fairFed \")\n",
    "    \n",
    "else:\n",
    "    print(\"Algorithm is \", algo)\n",
    "    \n",
    "global_model_base_path = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models\"\n",
    "shutil.rmtree(global_model_base_path)\n",
    "os.mkdir(global_model_base_path)\n",
    "\n",
    "selected_clients = [0, 1, 2, 3]\n",
    "\n",
    "assigner = AssignModel(global_model_base_path, selected_clients,algo)\n",
    "\n",
    "temp_model = DeepNet()  # Replace with your model instantiation\n",
    "assigner.save_global_model(temp_model)\n",
    "assigner.save_client_models(temp_model)\n",
    "\n",
    "\n",
    "model = DeepNet()\n",
    "server = Serverbase(model)\n",
    "server.fedAlgo(num_rounds=5,local_epochs=4,learning_rate = 0.001, beta = 1,algo=algo)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3460953a-df87-4b5f-b0aa-629c7d9a8e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21462357114702404, 0.1967327990189638)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_global -0.920953494483727\n",
    "weights_cache::  [27424, 28357, 40171, 41046]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b8580-35d9-4889-9a91-9e6fe5c52a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # client_acc [0.621039359719329, 0.621039359719329, 0.621039359719329, 0.621039359719329]\n",
    " # client_acc [0.7801227935533385, 0.7802324306545335, 0.7809998903628989, 0.7817810547089135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7f77244b-4b61-4dee-b028-991dbaac5299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136998"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27424+ 28357+ 40171+ 41046\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696f369-f476-4ff5-ba94-0f44bf35833e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6226f-dea7-4c5d-8e72-8938b57a11f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d090012-28e5-4b94-80ea-b4e348064e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b9c6b0-6dc8-44be-971c-47462a1d4136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "047ff52d-72c5-4992-a4ae-a951fdd65c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of weights across all models: -12.481867059133947\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create instances of your DeepNet model\n",
    "model1 = DeepNet()\n",
    "model2 = DeepNet()\n",
    "model3 = DeepNet()\n",
    "\n",
    "# Combine the models into a list\n",
    "models = [model1, model2, model3]\n",
    "\n",
    "# Initialize a variable to store the sum of weights\n",
    "total_weights = 0\n",
    "\n",
    "# Loop through the models and sum their parameters\n",
    "for model in models:\n",
    "    for param in model.parameters():\n",
    "        total_weights += param.sum().item()\n",
    "\n",
    "print(\"Sum of weights across all models:\", total_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c73ed-150f-4475-a231-d480907cf0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
