{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a322e06-a3b8-4f81-8a9f-5205dbef18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FedAvg\n",
    "# FedFair\n",
    "# data distribution that we used\n",
    "\n",
    "# Recall\n",
    "# FedAvg + FairFed + normal model\n",
    "\n",
    "# Plots withing notbooks\n",
    "# Plots for Acc vs subGroup\n",
    "# Recall of positive class\n",
    "# the data split we use...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae9b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import glob\n",
    "import sys, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from folktables import ACSDataSource, ACSEmployment,ACSIncome\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "import torch, random, copy, os\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4bea641-8d82-477c-8c94-ce49034ebf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPR\n",
    "# Gender: \n",
    "# 1: Male, 0: Female\n",
    "# Fairness: Male- Female\n",
    "# eq-4: Global- TPR\n",
    "\n",
    "# Fk = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d23e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8550ad",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a70374e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "else:\n",
    "    # CUDA is not available\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6badffcd-029a-47e7-9d4e-40b52d32b39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4eb7f6d-5757-494b-8d6a-1192058aee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 14 : input shape\n",
    "        # 9-> we have 9 columns in data \n",
    "        self.layer1 = nn.Linear(14, 512)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(256, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e6ddc-37c5-4a04-ba53-7215bb513904",
   "metadata": {},
   "source": [
    "# assigning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3bb04f7-7bfb-48f1-abd5-77b8e1196396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_model::: FedAVG\n",
      "global_model_2:: FairFair\n"
     ]
    }
   ],
   "source": [
    "#create global model and client models\n",
    "temp_model = DeepNet()\n",
    "# path=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model_FA.pt\"\n",
    "path=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model_FF.pt\"\n",
    "print(\"global_model::: FedAVG\")\n",
    "print(\"global_model_2:: FairFair\")\n",
    "torch.save(temp_model.state_dict(), path)\n",
    "\n",
    "# this has to be same in follwing code as well\n",
    "selected_clients=[0,1,2,3]\n",
    "\n",
    "for client_id in selected_clients:\n",
    "    client_model_path = f\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/client_{client_id}_model.pth\"\n",
    "    torch.save(temp_model.state_dict(), client_model_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52352bb-381e-4af7-baf1-e5900e214c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a24c1cb2-bf5f-4164-a4d5-9251d6358acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Client:\n",
    "    def __init__(self):\n",
    "        self.client_id: int = None\n",
    "        self.valset: DataLoader = None\n",
    "        self.trainset: DataLoader = None\n",
    "        self.testset: DataLoader = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")         \n",
    "        self.model = DeepNet().to(self.device)\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "\n",
    "        self.fainess_score=0\n",
    "\n",
    "        self.info_collection=[]\n",
    "        self.client_df = pd.DataFrame()\n",
    "        self.selected_clients=[0,1,2,3]\n",
    "\n",
    "        \n",
    "    def get_client_local_dataset(self):\n",
    "                \n",
    "        temp_path_data=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/data_fairFed\"\n",
    "        \n",
    "        with open(temp_path_data+\"/clients_training.pkl\", \"rb\") as f:\n",
    "            self.trainset = pickle.load(f)\n",
    "            \n",
    "        with open(temp_path_data+\"/clients_validation.pkl\", \"rb\") as f:\n",
    "            self.valset = pickle.load(f)\n",
    "         \n",
    "        with open(temp_path_data+\"/clients_testing_wrong.pkl\", \"rb\") as f:\n",
    "            self.testset  = pickle.load(f)\n",
    "\n",
    "        self.trainset = self.trainset[self.client_id]\n",
    "        self.valset = self.valset[self.client_id]       \n",
    "        self.testset = self.testset[self.client_id]\n",
    "\n",
    "    def get_stats(self):\n",
    "        # 1 male 0 female\n",
    "        total_pr_Y1_A0 = 0\n",
    "        total_pr_Y1_A1 = 0\n",
    "\n",
    "        for client_id in self.selected_clients:\n",
    "            self.client_id=client_id\n",
    "            self.get_client_local_dataset()\n",
    "            for inputs, labels, A in self.trainset:\n",
    "                pr_Y1_A1 = torch.sum((labels == 1) & (A == 1)).item()\n",
    "                pr_Y1_A0 = torch.sum((labels == 1) & (A == 0)).item()\n",
    "          \n",
    "\n",
    "                total_pr_Y1_A0 += pr_Y1_A0\n",
    "                total_pr_Y1_A1 += pr_Y1_A1\n",
    "        temp_sum=total_pr_Y1_A0+total_pr_Y1_A1\n",
    "        return [total_pr_Y1_A1/temp_sum,total_pr_Y1_A0/temp_sum]\n",
    "        \n",
    "    def calculate_fairness(self,y_hat, A, Y):\n",
    "        # Calculate counts using torch.sum\n",
    "        y_hat, A, Y = y_hat.to(self.device), A.to(self.device), Y.to(self.device)\n",
    "\n",
    "        # 1: Male, 0: Female\n",
    "        predict_Y_male = torch.sum((y_hat[(A == 1) & (Y == 1)] == 1)).item()\n",
    "        predict_Y_female = torch.sum((y_hat[(A == 0) & (Y == 1)] == 1)).item()\n",
    "        \n",
    "        count_Y_male = torch.sum((Y[(A == 1) & (Y == 1)] == 1)).item()\n",
    "        count_Y_female = torch.sum((Y[(A == 0) & (Y == 1)] == 1)).item()\n",
    "    \n",
    "        # Calculate probabilities\n",
    "        prob_Y_male = predict_Y_male / count_Y_male if count_Y_male > 0 else 0\n",
    "        prob_Y_female = predict_Y_female / count_Y_female if count_Y_female > 0 else 0\n",
    "    \n",
    "        # Calculate Fglobal\n",
    "        fairness_score = prob_Y_male - prob_Y_female\n",
    "        \n",
    "        return  fairness_score\n",
    "\n",
    "    def calculate_ser_fairness(self,y_hat, A, Y,statistics):\n",
    "        # print(\"calculate_ser_fairness statistics\",statistics)\n",
    "        y_hat, A, Y = y_hat.to(self.device), A.to(self.device), Y.to(self.device)\n",
    "\n",
    "        # for individual client!\n",
    "        #Male \n",
    "        predict_Y_male = torch.sum((y_hat[(A == 1) & (Y == 1)] == 1)).item() #get total\n",
    "        #Pr(A=0, Y=1)\n",
    "        count_Y_male = torch.sum((A == 1) & (Y == 1)).item() \n",
    "        #Pr(Ŷ=1|A=1, Y=1)  #Female      \n",
    "        predict_Y_female = torch.sum((y_hat[(A == 0) & (Y == 1)] == 1)).item()  #get total\n",
    "        #Pr(A=1, Y=1)\n",
    "        count_Y_female = torch.sum((A == 0) & (Y == 1)).item()\n",
    "        \n",
    "        if count_Y_male>0:\n",
    "            predict_Y_male=predict_Y_male/count_Y_male #Pr(Ŷ=1|A=0, Y=1)\n",
    "        \n",
    "        else:\n",
    "            predict_Y_male=0\n",
    "\n",
    "        if count_Y_female>0:\n",
    "            predict_Y_female=predict_Y_female/count_Y_female   #Pr(Ŷ=1|A=1, Y=1) \n",
    "        \n",
    "        else:\n",
    "            predict_Y_female=0\n",
    "        \n",
    "        # print(predict_Y_male*count_Y_male,\"::\",predict_Y_female*count_Y_female)\n",
    "\n",
    "        temp_fairness_server=((predict_Y_male * count_Y_male)/statistics[0]) - ((predict_Y_female * count_Y_female)/statistics[1])\n",
    "\n",
    "        # print(\"calculate_ser_fairness temp_fairness_server\",self.client_id,temp_fairness_server)\n",
    "        return temp_fairness_server\n",
    "\n",
    "\n",
    "    def train(self, client_id: int, model_path,statistics, num_epochs=5, learning_rate=0.001):\n",
    "        self.client_id = client_id\n",
    "        self.get_client_local_dataset()\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.fainess_score=0\n",
    "      \n",
    "        self.model.load_state_dict(torch.load(model_path,map_location=self.device))\n",
    "        for epoch in range(num_epochs):\n",
    "            # Set the model to training mode\n",
    "            self.model.train()\n",
    "\n",
    "            for inputs, labels, sens in self.trainset:\n",
    "                \n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs).to(self.device)\n",
    "                loss = self.criterion(outputs, labels.float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Calculate and print the training accuracy for this epoch (optional)\n",
    "            \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            size = 0\n",
    "            loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            predicted_labels = []\n",
    "            true_labels = []\n",
    "            final_fairness=[]\n",
    "            final_fairness_server=[]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                print(\"======Validation========\")\n",
    "                for inputs, labels,sens in self.valset:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    outputs = self.model(inputs)\n",
    "                    loss += self.criterion(outputs, labels)\n",
    "                    predicted = outputs > 0.5\n",
    "\n",
    "                    predicted_labels.extend(predicted.cpu().numpy())\n",
    "                    true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                    fairNess_per_batch=self.calculate_fairness(torch.round(outputs).squeeze(), sens.squeeze(), labels.squeeze())\n",
    "                    final_fairness.append(fairNess_per_batch)\n",
    "                    self.fainess_score=np.mean(final_fairness)\n",
    "\n",
    "                    fairNess_per_batch_server=self.calculate_ser_fairness(torch.round(outputs).squeeze(), sens.squeeze(), labels.squeeze(),statistics)\n",
    "                    final_fairness_server.append(fairNess_per_batch_server)\n",
    "                    ser_score=np.mean(final_fairness_server)\n",
    "\n",
    "                    \n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            loss = loss / len(self.valset)        \n",
    "            acc = correct / total\n",
    "            \n",
    "            # print(\"ser_score \",ser_score)\n",
    "            \n",
    "            precision = precision_score(true_labels, predicted_labels,zero_division=0.0)            \n",
    "            recall = recall_score(true_labels, predicted_labels)\n",
    "            \n",
    "            # accuracy = 100 * correct / total\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Val Accuracy: {acc:.5f}%\")\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Val Fairness: {self.fainess_score:.5f}%\")\n",
    "\n",
    "        # Optionally, save the trained model parameters\n",
    "        # client_model_path = f\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/client_{self.client_id}_model.pth\"\n",
    "        #store model\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "        # Return the trained model parameters\n",
    "        return list(self.model.state_dict().values()), len(self.trainset.dataset),self.model.state_dict(), self.fainess_score, ser_score\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def client_evaluate(self, val=False):\n",
    "        \n",
    "        size = 0\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "\n",
    "        \n",
    "        models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "                 \n",
    "        for client_id in self.selected_clients:\n",
    "            \n",
    "            print(\"===============Testing======================\")\n",
    "            # print(\" selected client for Testing:: \", client_id)\n",
    "            model_path = os.path.join(models_directory, f\"client_{client_id}_model.pth\")            \n",
    "        \n",
    "            self.model.load_state_dict(torch.load(model_path,map_location=self.device))\n",
    "\n",
    "            self.model.eval()\n",
    "\n",
    "            for inputs, targets,sens in self.testset:\n",
    "                \n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                loss += self.criterion(outputs, targets)\n",
    "                predicted = outputs > 0.5\n",
    "                \n",
    "                predicted_labels.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(targets.cpu().numpy())\n",
    "                \n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()                \n",
    "            \n",
    "            loss = loss / len(self.testset)\n",
    "            acc = correct / total\n",
    "            \n",
    "            # print(\"loss: %f\\n\" % (loss))\n",
    "            \n",
    "            \n",
    "            print(f\" Client Accuracy: {acc:.5%}\")\n",
    "    #         print(predicted_labels,\" :: \",true_labels)\n",
    "            precision = precision_score(true_labels, predicted_labels,zero_division=0.0)\n",
    "            \n",
    "            recall = recall_score(true_labels, predicted_labels)\n",
    "    \n",
    "            print(f\" Client Precision: {precision:.5%}\")\n",
    "            print(f\" Client Recall: {recall:.5%}\")\n",
    "            \n",
    "            print(\"\\n\\n\")\n",
    "            \n",
    "        return loss, acc,precision,recall\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def server_evaluate(self):\n",
    "\n",
    "        # print(\"Global Model testing Starts\")\n",
    "        # print(\"kindly check the Path. Select it based on FedAvg Model\")\n",
    "        # print(\"warning: Test data has already been used\")\n",
    "        temp_path_data=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/\"\n",
    "\n",
    "        with open(temp_path_data+\"/testing_client.pkl\", \"rb\") as f:\n",
    "            testset  = pickle.load(f)\n",
    "            \n",
    "        path=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model.pt\"\n",
    "        # path=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model_2.pt\"\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(path,map_location=self.device))\n",
    "        self.model.eval()\n",
    "        size = 0\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "        final_fairness=[]\n",
    "\n",
    "        self.testset=testset[1]\n",
    "        for inputs, targets,sens in self.testset:\n",
    "            \n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "            \n",
    "            outputs = self.model(inputs)\n",
    "            loss += self.criterion(outputs, targets)\n",
    "            predicted = outputs > 0.5\n",
    "\n",
    "            fairNess_per_batch=self.calculate_fairness(torch.round(outputs).squeeze(), sens.squeeze(), targets.squeeze())\n",
    "            final_fairness.append(fairNess_per_batch)\n",
    "            fairness_global=np.mean(final_fairness)\n",
    "            \n",
    "#            print(\"predicted\",predicted)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(targets.cpu().numpy())\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "        \n",
    "        loss = loss / len(self.testset)\n",
    "        acc = correct / total\n",
    "        \n",
    "        # print(\"loss: %f\\n\" % (loss))\n",
    "        \n",
    "        print(f\"Global Testing Accuracy: {acc:.5%}\")\n",
    "        print(f\" Global Fairness: {fairness_global:.5f}%\")\n",
    "        precision = precision_score(true_labels, predicted_labels,zero_division=0.0)\n",
    "        \n",
    "        recall = recall_score(true_labels, predicted_labels)\n",
    "        \n",
    "        print(f\"Global Precision: {precision:.5%}\")\n",
    "        print(f\"Global Recall: {recall:.5%}\")\n",
    "        \n",
    "        return loss, acc, precision, recall,fairness_global\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "199eb51c-d78b-44f1-86b0-e8b325ce899c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                        | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_id::  0\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.78052%\n",
      "Epoch 1/1, Val Fairness: 0.71191%\n",
      "client_id::  1\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.78089%\n",
      "Epoch 1/1, Val Fairness: -0.68470%\n",
      "client_id::  2\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.81195%\n",
      "Epoch 1/1, Val Fairness: 0.75273%\n",
      "client_id::  3\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████████████▍                                                                                         | 1/5 [00:07<00:30,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Val Accuracy: 0.77519%\n",
      "Epoch 1/1, Val Fairness: -0.79279%\n",
      "final_global_score::  6.690567043286983\n",
      "final_global_score::  -0.6720699260581267\n",
      "final_global_score::  12.424069503271616\n",
      "final_global_score::  0.1313011118729257\n",
      "self.fair_global_t_step:: 0.1313011118729257\n",
      "client_id::  0\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.78983%\n",
      "Epoch 1/1, Val Fairness: 0.68530%\n",
      "client_id::  1\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.78107%\n",
      "Epoch 1/1, Val Fairness: -0.76805%\n",
      "client_id::  2\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.81559%\n",
      "Epoch 1/1, Val Fairness: 0.82304%\n",
      "client_id::  3\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████████▊                                                                   | 2/5 [00:15<00:23,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Val Accuracy: 0.77661%\n",
      "Epoch 1/1, Val Fairness: -0.76841%\n",
      "final_global_score::  6.41726815385185\n",
      "final_global_score::  -1.8461972621868856\n",
      "final_global_score::  12.371875885474985\n",
      "final_global_score::  0.43395932575958085\n",
      "self.fair_global_t_step:: 0.43395932575958085\n",
      "client_id::  0\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.78571%\n",
      "Epoch 1/1, Val Fairness: 0.66301%\n",
      "client_id::  1\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.77616%\n",
      "Epoch 1/1, Val Fairness: -0.75785%\n",
      "client_id::  2\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.81137%\n",
      "Epoch 1/1, Val Fairness: 0.73125%\n",
      "client_id::  3\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████████████████████▏                                            | 3/5 [00:27<00:19,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Val Accuracy: 0.77409%\n",
      "Epoch 1/1, Val Fairness: -0.78923%\n",
      "final_global_score::  6.233316978270512\n",
      "final_global_score::  -1.9445948981381012\n",
      "final_global_score::  10.790700784445264\n",
      "final_global_score::  -1.48673450311526\n",
      "self.fair_global_t_step:: -1.48673450311526\n",
      "client_id::  0\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.78658%\n",
      "Epoch 1/1, Val Fairness: 0.67211%\n",
      "client_id::  1\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.78562%\n",
      "Epoch 1/1, Val Fairness: -0.71150%\n",
      "client_id::  2\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.81443%\n",
      "Epoch 1/1, Val Fairness: 0.76815%\n",
      "client_id::  3\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████████████████████████████▌                      | 4/5 [00:36<00:09,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Val Accuracy: 0.77409%\n",
      "Epoch 1/1, Val Fairness: -0.81708%\n",
      "final_global_score::  6.270107213386781\n",
      "final_global_score::  -1.3995159863958202\n",
      "final_global_score::  11.926816867582474\n",
      "final_global_score::  -0.7251842423104016\n",
      "self.fair_global_t_step:: -0.7251842423104016\n",
      "client_id::  0\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.79329%\n",
      "Epoch 1/1, Val Fairness: 0.70236%\n",
      "client_id::  1\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.78508%\n",
      "Epoch 1/1, Val Fairness: -0.74247%\n",
      "client_id::  2\n",
      "======Validation========\n",
      "Epoch 1/1, Val Accuracy: 0.81686%\n",
      "Epoch 1/1, Val Fairness: 0.77758%\n",
      "client_id::  3\n",
      "======Validation========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:48<00:00,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Val Accuracy: 0.77563%\n",
      "Epoch 1/1, Val Fairness: -0.78309%\n",
      "final_global_score::  6.574940590064427\n",
      "final_global_score::  -1.4419293293933713\n",
      "final_global_score::  12.077268285776949\n",
      "final_global_score::  -0.10597793534912014\n",
      "self.fair_global_t_step:: -0.10597793534912014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Serverbase:\n",
    "    def __init__ (self,model):\n",
    "        self.model = model\n",
    "        self.global_model=model\n",
    "        self.num_rounds=2\n",
    "        self.local_epoch=2\n",
    "        self.optimizer=2\n",
    "        self.lr=0.001\n",
    "        self.beta=1\n",
    "        self.batch_size=32\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "        self.client_id_indices, self.client_num_in_total = [0,1], 2 \n",
    "        \n",
    "        self.updated_params_cache = []\n",
    "        self.weights_cache = []\n",
    "        self.model_dict = []\n",
    "        \n",
    "        self.global_params_dict: OrderedDict[str : torch.Tensor] = None\n",
    "\n",
    "        self.backbone=DeepNet\n",
    "        _dummy_model = self.backbone()\n",
    "        self.global_params_dict = OrderedDict(_dummy_model.state_dict())\n",
    "\n",
    "        self.temp_dir=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "\n",
    "        self.fair_global_t_step=0\n",
    "        self.fair_local_client=0   \n",
    "        \n",
    "        self.acc_clients=[]\n",
    "        self.clients_id=[]\n",
    "        self.precision_clients=[]\n",
    "        self.recall_clients=[]\n",
    "        \n",
    "        self.global_acc=0\n",
    "        self.fairness_diff=[]\n",
    "        self.clients_weights=[]\n",
    "        self.final_agg_weights_clients=[]\n",
    "        self.selected_clients=[0,1,2,3]\n",
    "        self.statistics=0\n",
    "\n",
    "    def global_fairness(self,weights, all_clients_fairness): \n",
    "        # all_clients_fairness is based on equation: 7\n",
    "        # upper part is done in client class\n",
    "        # self.statistics cal. pr(y=1,a=0)\n",
    "        \n",
    "        # print(\"global_fairness::\",all_clients_fairness)\n",
    "        # print(\"weights::\",weights)\n",
    "        \n",
    "        weight_sum = sum(weights)  \n",
    "        # print(\"weights::\",weights)\n",
    "        final_global_score=0\n",
    "        \n",
    "        for i in range(len(all_clients_fairness)):\n",
    "            temp=weights[i]/weight_sum            \n",
    "            final_global_score+=temp*all_clients_fairness[i]\n",
    "            \n",
    "            print(\"final_global_score:: \",final_global_score)\n",
    "        self.fair_global=final_global_score\n",
    "\n",
    "    \n",
    "        \n",
    "    def fairFed(self, num_rounds = 2, local_epochs = 2, learning_rate = 0.001, beta = 1, alpha = 0.1, optimizer = 'adam'):\n",
    "        client = Client()\n",
    "        #before we start the training, we need statistics\n",
    "        self.statistics= client.get_stats()        \n",
    "        \n",
    "        for round_ in tqdm(range(num_rounds)):\n",
    "  \n",
    "            #each round we need empty lists\n",
    "            self.updated_params_cache = []\n",
    "            self.weights_cache = []\n",
    "            self.model_dict=[]\n",
    "            self.clients_weights=[]\n",
    "            self.final_agg_weights_clients=[]\n",
    "            self.fair_global=0\n",
    "            temp_ser_fairness=[]\n",
    "            \n",
    "            \n",
    "            for client_id in self.selected_clients:\n",
    "                self.global_acc=0\n",
    "                \n",
    "                print(\"client_id:: \",client_id)\n",
    "                # weight is length of dataset\n",
    "\n",
    "                models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "                #take a model of particular client\n",
    "                model_path = os.path.join(models_directory, f\"client_{client_id}_model.pth\")                       \n",
    "                \n",
    "                updated_params_list, weight, model_dict_list,fairness_client,ser_fairness = client.train(client_id, \n",
    "                                                                                                         model_path, \n",
    "                                                                                                         statistics=self.statistics,\n",
    "                                                                                                         num_epochs=local_epochs, \n",
    "                                                                                                         learning_rate=learning_rate)\n",
    "                \n",
    "                # loss_client, acc_client,precision_client,recall_client = client.client_evaluate(val=True)                \n",
    "                            \n",
    "                # store it for SecAgg\n",
    "                self.updated_params_cache.append(updated_params_list)\n",
    "                self.weights_cache.append(weight)\n",
    "                self.model_dict.append(model_dict_list)\n",
    "                temp_ser_fairness.append(ser_fairness)\n",
    "                \n",
    "                # print(\"temp_ser_fairness\",temp_ser_fairness)\n",
    "                #store it for FairFed agg\n",
    "                \n",
    "                # self.global_acc=acc_server\n",
    "                self.fair_local_client=fairness_client\n",
    "            \n",
    "            self.global_fairness(self.weights_cache, temp_ser_fairness)\n",
    "\n",
    "            print(\"self.fair_global_t_step::\",self.fair_global)\n",
    "            # loss_server, acc_server, precision_server, recall_server,fairness_global = client.server_evaluate()\n",
    "\n",
    "            # Update the weights of each client\n",
    "            self.aggregate_client_weight_FedFair_part_1(self.model_dict, self.weights_cache,self.acc_clients, self.global_acc,self.fair_local_client,\n",
    "                                                 self.fair_global)\n",
    "            self.client_weights_update_part_2(self.clients_weights)\n",
    "\n",
    "            # agg all the weights on serverside\n",
    "            self.aggregate_parameters_FedAvg_updated(self.final_agg_weights_clients)\n",
    "        \n",
    "            \n",
    "            torch.save(self.global_model.state_dict(), os.path.join(self.temp_dir, \"global_model_FF.pt\"),)\n",
    "\n",
    "        # Test Clients Models and Global Model\n",
    "        # loss_client, acc_client = client.client_evaluate()        \n",
    "        # loss_client, accuracy_server, pre_server, recall_ser,fairness_global = client.server_evaluate()\n",
    "            \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def aggregate_parameters_FedAvg(self, updated_params_cache, weights_cache):\n",
    "        weight_sum = sum(weights_cache)  \n",
    "        \n",
    "        weights = torch.tensor(weights_cache, device=self.device) / weight_sum\n",
    "        \n",
    "        aggregated_params = []\n",
    "\n",
    "        for params in zip(*updated_params_cache):\n",
    "            aggregated_params.append(\n",
    "                torch.sum(weights * torch.stack(params, dim=-1), dim=-1)\n",
    "            )\n",
    "\n",
    "        self.global_params_dict = OrderedDict(\n",
    "            zip(self.global_params_dict.keys(), aggregated_params)\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def aggregate_parameters_FedAvg_updated(self, model_dict_list):        \n",
    "        w_avg = copy.deepcopy(model_dict_list[0])\n",
    "        for k in w_avg.keys():\n",
    "            for i in range(1, len(model_dict_list)):\n",
    "                w_avg[k] += model_dict_list[i][k]\n",
    "            w_avg[k] = torch.div(w_avg[k], len(model_dict_list))\n",
    "    \n",
    "        self.global_model.load_state_dict(w_avg)\n",
    "        # torch.save(self.global_model.state_dict(), os.path.join(self.temp_dir, \"global_model_FA.pt\"),)        \n",
    "        # torch.save(self.global_model.state_dict(), os.path.join(self.temp_dir, \"global_model_FF.pt\"),)\n",
    "\n",
    "                \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def aggregate_client_weight_FedFair_part_1 (self, model_dict_list ,weights_cache, acc_clients, global_acc,fairness_client,fairness_global):\n",
    "        \n",
    "        if not self.fair_local_client:\n",
    "            \n",
    "            sum_acc_client=sum(acc_clients) /len(acc_clients)\n",
    "            Delta_t_C_i= abs(sum_acc_client-global_acc)\n",
    "            \n",
    "        else:            \n",
    "            Delta_t_C_i = abs(self.fair_global - self.fair_local_client) \n",
    "        \n",
    "        for client_id in range(len(self.selected_clients)):\n",
    "        \n",
    "            w_avg = copy.deepcopy(model_dict_list[client_id])\n",
    "            temp = copy.deepcopy(model_dict_list[client_id])\n",
    "            \n",
    "            for k in w_avg.keys():\n",
    "                for i in range(1, len(model_dict_list)):\n",
    "                    w_avg[k] += model_dict_list[i][k]\n",
    "                w_avg[k] = torch.div(w_avg[k], len(model_dict_list))\n",
    "                \n",
    "                w_avg[k]=temp[k]-(self.beta*(Delta_t_C_i-w_avg[k]))\n",
    "                \n",
    "            self.clients_weights.append(w_avg)\n",
    "\n",
    "            \n",
    "    def client_weights_update_part_2(self,agg_weights):\n",
    "        sum_params = OrderedDict()\n",
    "        final_agg_weights_clients=[]\n",
    "        for model in agg_weights:\n",
    "            for name, param in model.items():\n",
    "                if name in sum_params:\n",
    "                    sum_params[name] += param\n",
    "                else:\n",
    "                    sum_params[name] = param\n",
    "\n",
    "            updated_client_weights = OrderedDict()\n",
    "            \n",
    "            for name, param in model.items():\n",
    "                updated_param = torch.div(param, sum_params[name])\n",
    "                updated_client_weights[name] = updated_param\n",
    "\n",
    "                self.final_agg_weights_clients.append(updated_client_weights)\n",
    "        \n",
    "model = DeepNet()\n",
    "server = Serverbase(model)\n",
    "server.fairFed(num_rounds=3,local_epochs=15)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdf995c8-5238-44f1-aa4d-e927101b0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 136404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97600f-7474-47ae-bd82-89bcad80e6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b8580-35d9-4889-9a91-9e6fe5c52a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dceab3e-95e5-4632-b546-71af084db801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da6c4e-a098-47fd-be66-e6ff275679c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558d74f-aeef-4ec7-a86b-23e1fe0fe93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f77244b-4b61-4dee-b028-991dbaac5299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696f369-f476-4ff5-ba94-0f44bf35833e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
