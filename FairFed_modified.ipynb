{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a322e06-a3b8-4f81-8a9f-5205dbef18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FedAvg\n",
    "# FedFair\n",
    "# data distribution that we used\n",
    "\n",
    "# Recall\n",
    "# FedAvg + FairFed + normal model\n",
    "\n",
    "# Plots withing notbooks\n",
    "# Plots for Acc vs subGroup\n",
    "# Show data distrubution\n",
    "# Recall of positive class\n",
    "# the data split we use...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae9b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import glob\n",
    "import sys, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from folktables import ACSDataSource, ACSEmployment,ACSIncome\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "import torch, random, copy, os\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4bea641-8d82-477c-8c94-ce49034ebf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPR\n",
    "# Gender: \n",
    "# 1: Male, 0: Female\n",
    "# Fairness: Male- Female\n",
    "# eq-4: Global- TPR\n",
    "\n",
    "# Fk = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d23e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8550ad",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a70374e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "else:\n",
    "    # CUDA is not available\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6badffcd-029a-47e7-9d4e-40b52d32b39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4eb7f6d-5757-494b-8d6a-1192058aee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 14 : input shape\n",
    "        # 9-> we have 9 columns in data \n",
    "        self.layer1 = nn.Linear(9, 512)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(256, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e6ddc-37c5-4a04-ba53-7215bb513904",
   "metadata": {},
   "source": [
    "# assigning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3bb04f7-7bfb-48f1-abd5-77b8e1196396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create global model and client models\n",
    "temp_model = DeepNet()\n",
    "path=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model.pt\"\n",
    "torch.save(temp_model.state_dict(), path)\n",
    "\n",
    "# this has to be same in follwing code as well\n",
    "selected_clients=[0,1]\n",
    "\n",
    "for client_id in selected_clients:\n",
    "    client_model_path = f\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/client_{client_id}_model.pth\"\n",
    "    torch.save(temp_model.state_dict(), client_model_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52352bb-381e-4af7-baf1-e5900e214c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f23068-2ef5-42e3-89ba-6311f656685b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a24c1cb2-bf5f-4164-a4d5-9251d6358acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Client:\n",
    "    def __init__(self):\n",
    "        self.client_id: int = None\n",
    "        self.valset: DataLoader = None\n",
    "        self.trainset: DataLoader = None\n",
    "        self.testset: DataLoader = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")         \n",
    "        self.model = DeepNet().to(self.device)\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "\n",
    "        self.fainess_score=0\n",
    "\n",
    "\n",
    "    def get_client_local_dataset(self):\n",
    "                \n",
    "        temp_path_data=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/client_df\"\n",
    "        \n",
    "        with open(temp_path_data+\"/clients_training.pkl\", \"rb\") as f:\n",
    "            self.trainset = pickle.load(f)\n",
    "            \n",
    "        with open(temp_path_data+\"/clients_validation.pkl\", \"rb\") as f:\n",
    "            self.valset = pickle.load(f)\n",
    "         \n",
    "        with open(temp_path_data+\"/clients_testing.pkl\", \"rb\") as f:\n",
    "            self.testset  = pickle.load(f)\n",
    "\n",
    "        self.trainset = self.trainset[self.client_id]\n",
    "        self.valset = self.valset[self.client_id]       \n",
    "        self.testset = self.testset[self.client_id]\n",
    "\n",
    "    def calculate_fairness(self,y_hat, A, Y):\n",
    "        # Calculate counts using torch.sum\n",
    "        y_hat, A, Y = y_hat.to(self.device), A.to(self.device), Y.to(self.device)\n",
    "\n",
    "        # 1: Male, 0: Female\n",
    "        predict_Y_male = torch.sum((y_hat[(A == 1) & (Y == 1)] == 1)).item()\n",
    "        predict_Y_female = torch.sum((y_hat[(A == 0) & (Y == 1)] == 1)).item()\n",
    "        \n",
    "        count_Y_male = torch.sum((Y[(A == 1) & (Y == 1)] == 1)).item()\n",
    "        count_Y_female = torch.sum((Y[(A == 0) & (Y == 1)] == 1)).item()\n",
    "    \n",
    "        # Calculate probabilities\n",
    "        prob_Y_male = predict_Y_male / count_Y_male if count_Y_male > 0 else 0\n",
    "        prob_Y_female = predict_Y_female / count_Y_female if count_Y_female > 0 else 0\n",
    "    \n",
    "        # Calculate Fglobal\n",
    "        fairness_score = prob_Y_male - prob_Y_female\n",
    "        \n",
    "        return  fairness_score\n",
    "\n",
    "    def train(self, client_id: int, model_params: OrderedDict[str, torch.Tensor], num_epochs=5, learning_rate=0.001):\n",
    "        self.client_id = client_id\n",
    "        self.get_client_local_dataset()\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.fainess_score=0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Set the model to training mode\n",
    "            self.model.train()\n",
    "\n",
    "            for inputs, labels, sens in self.trainset:\n",
    "                \n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels.float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Calculate and print the training accuracy for this epoch (optional)\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            size = 0\n",
    "            loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            predicted_labels = []\n",
    "            true_labels = []\n",
    "            final_fairness=[]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                print(\"======Validation========\")\n",
    "                for inputs, labels,sens in self.valset:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    outputs = self.model(inputs)\n",
    "                    loss += self.criterion(outputs, labels)\n",
    "                    predicted = outputs > 0.5\n",
    "\n",
    "                    predicted_labels.extend(predicted.cpu().numpy())\n",
    "                    true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                    fairNess_per_batch=self.calculate_fairness(torch.round(outputs).squeeze(), sens.squeeze(), labels.squeeze())\n",
    "                    final_fairness.append(fairNess_per_batch)\n",
    "                    self.fainess_score=np.mean(final_fairness)\n",
    "\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            loss = loss / len(self.valset)        \n",
    "            accuracy = correct / total\n",
    "            \n",
    "            # accuracy = 100 * correct / total\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Training Accuracy: {accuracy:.2f}%\")\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Training Fairness: {self.fainess_score:.2f}%\")\n",
    "\n",
    "        # Optionally, save the trained model parameters\n",
    "        client_model_path = f\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/client_{self.client_id}_model.pth\"\n",
    "        torch.save(self.model.state_dict(), client_model_path)\n",
    "\n",
    "        # Return the trained model parameters\n",
    "        return list(self.model.state_dict().values()), len(self.trainset.dataset),self.model.state_dict(), self.fainess_score\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def client_evaluate(self, val=False):\n",
    "        \n",
    "        size = 0\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "\n",
    "        selected_clients=[0,1]\n",
    "        models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "                 \n",
    "        for client_id in selected_clients:\n",
    "            \n",
    "            print(\"===============Testing======================\")\n",
    "            # print(\" selected client for Testing:: \", client_id)\n",
    "            model_path = os.path.join(models_directory, f\"client_{client_id}_model.pth\")            \n",
    "        \n",
    "            self.model.load_state_dict(torch.load(model_path,map_location=self.device))\n",
    "\n",
    "            self.model.eval()\n",
    "\n",
    "            for inputs, targets,sens in self.testset:\n",
    "                \n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                loss += self.criterion(outputs, targets)\n",
    "                predicted = outputs > 0.5\n",
    "                \n",
    "                predicted_labels.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(targets.cpu().numpy())\n",
    "                \n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "                \n",
    "            \n",
    "            loss = loss / len(self.testset)\n",
    "            acc = correct / total\n",
    "            \n",
    "            # print(\"loss: %f\\n\" % (loss))\n",
    "            \n",
    "            print(f\" Accuracy: {acc:.2%}\")\n",
    "    #         print(predicted_labels,\" :: \",true_labels)\n",
    "            precision = precision_score(true_labels, predicted_labels,zero_division=0.0)\n",
    "            \n",
    "            recall = recall_score(true_labels, predicted_labels)\n",
    "    \n",
    "            # print(f\"Precision: {precision:.2%}\")\n",
    "            # print(f\"Recall: {recall:.2%}\")\n",
    "            \n",
    "            print(\"\\n\\n\")\n",
    "            \n",
    "        return loss, acc\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def server_evaluate(self):\n",
    "\n",
    "        # print(\"Global Model testing Starts\")\n",
    "        # print(\"kindly check the Path. Select it based on FedAvg Model\")\n",
    "        # print(\"warning: Test data has already been used\")\n",
    "        \n",
    "        path=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model.pt\"\n",
    "        path_2=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model_2.pt\"\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(path_2,map_location=self.device))\n",
    "        self.model.eval()\n",
    "        size = 0\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "        final_fairness=[]\n",
    "        for inputs, targets,sens in self.testset:\n",
    "            \n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "            \n",
    "            outputs = self.model(inputs)\n",
    "            loss += self.criterion(outputs, targets)\n",
    "            predicted = outputs > 0.5\n",
    "\n",
    "            fairNess_per_batch=self.calculate_fairness(torch.round(outputs).squeeze(), sens.squeeze(), targets.squeeze())\n",
    "            final_fairness.append(fairNess_per_batch)\n",
    "            self.fainess_score_global=np.mean(final_fairness)\n",
    "            \n",
    "#            print(\"predicted\",predicted)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(targets.cpu().numpy())\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "        \n",
    "        loss = loss / len(self.testset)\n",
    "        acc = correct / total\n",
    "        \n",
    "        # print(\"loss: %f\\n\" % (loss))\n",
    "        \n",
    "        print(f\"Global Testing Accuracy: {acc:.2%}\")\n",
    "        print(f\" Global Fairness: {self.fainess_score_global:.2f}%\")\n",
    "        precision = precision_score(true_labels, predicted_labels,zero_division=0.0)\n",
    "        \n",
    "        recall = recall_score(true_labels, predicted_labels)\n",
    "        \n",
    "        # print(f\"Global Precision: {precision:.2%}\")\n",
    "        # print(f\"Global Recall: {recall:.2%}\")\n",
    "        \n",
    "        return loss, acc, self.fainess_score_global\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "199eb51c-d78b-44f1-86b0-e8b325ce899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                        | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Validation========\n",
      "Epoch 1/2, Training Accuracy: 0.77%\n",
      "Epoch 1/2, Training Fairness: 0.01%\n",
      "======Validation========\n",
      "Epoch 2/2, Training Accuracy: 0.77%\n",
      "Epoch 2/2, Training Fairness: 0.03%\n",
      "===============Testing======================\n",
      " Accuracy: 78.24%\n",
      "\n",
      "\n",
      "\n",
      "===============Testing======================\n",
      " Accuracy: 77.79%\n",
      "\n",
      "\n",
      "\n",
      "Global Testing Accuracy: 61.36%\n",
      " Global Fairness: -0.06%\n",
      "======Validation========\n",
      "Epoch 1/2, Training Accuracy: 0.78%\n",
      "Epoch 1/2, Training Fairness: 0.04%\n",
      "======Validation========\n",
      "Epoch 2/2, Training Accuracy: 0.78%\n",
      "Epoch 2/2, Training Fairness: 0.01%\n",
      "===============Testing======================\n",
      " Accuracy: 78.24%\n",
      "\n",
      "\n",
      "\n",
      "===============Testing======================\n",
      " Accuracy: 77.99%\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████                                                        | 1/2 [00:03<00:03,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Testing Accuracy: 62.12%\n",
      " Global Fairness: -0.05%\n",
      "len:: 2\n",
      "======Validation========\n",
      "Epoch 1/2, Training Accuracy: 0.77%\n",
      "Epoch 1/2, Training Fairness: 0.02%\n",
      "======Validation========\n",
      "Epoch 2/2, Training Accuracy: 0.78%\n",
      "Epoch 2/2, Training Fairness: 0.02%\n",
      "===============Testing======================\n",
      " Accuracy: 78.42%\n",
      "\n",
      "\n",
      "\n",
      "===============Testing======================\n",
      " Accuracy: 77.94%\n",
      "\n",
      "\n",
      "\n",
      "Global Testing Accuracy: 42.40%\n",
      " Global Fairness: 0.00%\n",
      "======Validation========\n",
      "Epoch 1/2, Training Accuracy: 0.77%\n",
      "Epoch 1/2, Training Fairness: -0.03%\n",
      "======Validation========\n",
      "Epoch 2/2, Training Accuracy: 0.79%\n",
      "Epoch 2/2, Training Fairness: -0.00%\n",
      "===============Testing======================\n",
      " Accuracy: 78.79%\n",
      "\n",
      "\n",
      "\n",
      "===============Testing======================\n",
      " Accuracy: 77.93%\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:06<00:00,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Testing Accuracy: 41.23%\n",
      " Global Fairness: 0.00%\n",
      "len:: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Serverbase:\n",
    "    def __init__ (self,model):\n",
    "        self.model = model\n",
    "        self.global_model=model\n",
    "        self.num_rounds=5\n",
    "        self.local_epoch=10\n",
    "        self.optimizer=2\n",
    "        self.lr=0.001\n",
    "        self.beta=0.02\n",
    "        self.batch_size=32\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "        self.client_id_indices, self.client_num_in_total = [0,1], 2 \n",
    "        \n",
    "        self.updated_params_cache = []\n",
    "        self.weights_cache = []\n",
    "        self.model_dict = []\n",
    "        \n",
    "        self.global_params_dict: OrderedDict[str : torch.Tensor] = None\n",
    "\n",
    "        self.backbone=DeepNet\n",
    "        _dummy_model = self.backbone()\n",
    "        self.global_params_dict = OrderedDict(_dummy_model.state_dict())\n",
    "\n",
    "        self.temp_dir=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "\n",
    "        self.fair_global_t_step=0\n",
    "        self.fair_local_client=0   \n",
    "        self.acc_clients=[]\n",
    "        self.global_acc=0\n",
    "        self.fairness_diff=[]\n",
    "        self.clients_weights=[]\n",
    "        self.final_agg_weights_clients=[]\n",
    "        self.selected_clients=[0,1]\n",
    "        \n",
    "    def fairFed(self, num_rounds = 2, local_epochs = 2, learning_rate = 0.005, beta = 0.3, alpha = 0.1, optimizer = 'adam'):\n",
    "        \n",
    "        for round_ in tqdm(range(num_rounds)):\n",
    "  \n",
    "            #each round we need empty lists\n",
    "            self.updated_params_cache = []\n",
    "            self.weights_cache = []\n",
    "            self.model_dict=[]\n",
    "            self.clients_weights=[]\n",
    "            self.final_agg_weights_clients=[]\n",
    "            \n",
    "            for client_id in self.selected_clients:\n",
    "                self.global_acc=[]\n",
    "                client = Client()\n",
    "\n",
    "                # weight is length of dataset\n",
    "                updated_params_list, weight, model_dict_list,fairness_client = client.train(client_id, self.model.state_dict(), num_epochs=local_epochs, learning_rate=learning_rate)\n",
    "                loss_client, acc_client = client.client_evaluate(val=True)\n",
    "                loss_server, acc_server,fairness_global = client.server_evaluate()\n",
    "                \n",
    "                # store it for SecAgg\n",
    "                self.updated_params_cache.append(updated_params_list)\n",
    "                self.weights_cache.append(weight)\n",
    "                self.model_dict.append(model_dict_list)\n",
    "                \n",
    "                #store it for FairFed agg\n",
    "                self.acc_clients.append(acc_client)\n",
    "                self.global_acc=acc_server\n",
    "                self.fair_local_client=fairness_client\n",
    "                self.fair_global=fairness_global\n",
    "        \n",
    "            # self.aggregate_parameters_FedAvg(self.updated_params_cache, self.weights_cache)\n",
    "            \n",
    "            self.aggregate_client_weight_FedFair_part_1(self.model_dict, self.weights_cache,self.acc_clients, self.global_acc,self.fair_local_client,\n",
    "                                                 self.fair_global)\n",
    "            self.client_weights_update_part_2(self.clients_weights)\n",
    "            # print(\"self.model_dict\",self.model_dict)\n",
    "            self.aggregate_parameters_FedAvg_updated(self.final_agg_weights_clients)\n",
    "                \n",
    "            torch.save(self.global_params_dict, os.path.join(self.temp_dir, \"global_model.pt\"),)\n",
    "\n",
    "        # Test Clients Models and Global Model\n",
    "        # loss_client, acc_client = client.client_evaluate()        \n",
    "        # loss_server, acc_server = client.server_evaluate()\n",
    "        \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def aggregate_parameters_FedAvg(self, updated_params_cache, weights_cache):\n",
    "        weight_sum = sum(weights_cache)  \n",
    "        \n",
    "        weights = torch.tensor(weights_cache, device=self.device) / weight_sum\n",
    "        \n",
    "        aggregated_params = []\n",
    "\n",
    "        for params in zip(*updated_params_cache):\n",
    "            aggregated_params.append(\n",
    "                torch.sum(weights * torch.stack(params, dim=-1), dim=-1)\n",
    "            )\n",
    "\n",
    "        self.global_params_dict = OrderedDict(\n",
    "            zip(self.global_params_dict.keys(), aggregated_params)\n",
    "        )\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def aggregate_parameters_FedAvg_updated(self, model_dict_list):        \n",
    "        w_avg = copy.deepcopy(model_dict_list[0])\n",
    "        for k in w_avg.keys():\n",
    "            for i in range(1, len(model_dict_list)):\n",
    "                w_avg[k] += model_dict_list[i][k]\n",
    "            w_avg[k] = torch.div(w_avg[k], len(model_dict_list))\n",
    "    \n",
    "        self.global_model.load_state_dict(w_avg)\n",
    "        torch.save(self.global_model.state_dict(), os.path.join(self.temp_dir, \"global_model_2.pt\"),)\n",
    "            \n",
    "    def client_weights_update_part_2(self,agg_weights):\n",
    "        sum_params = OrderedDict()\n",
    "        final_agg_weights_clients=[]\n",
    "        for model in agg_weights:\n",
    "            for name, param in model.items():\n",
    "                if name in sum_params:\n",
    "                    sum_params[name] += param\n",
    "                else:\n",
    "                    sum_params[name] = param\n",
    "\n",
    "            updated_client_weights = OrderedDict()\n",
    "            \n",
    "            for name, param in model.items():\n",
    "                updated_param = torch.div(param, sum_params[name])\n",
    "                updated_client_weights[name] = updated_param\n",
    "\n",
    "                self.final_agg_weights_clients.append(updated_client_weights)\n",
    "                \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def aggregate_client_weight_FedFair_part_1 (self, model_dict_list ,weights_cache, acc_clients, global_acc,fairness_client,fairness_global):\n",
    "        print(\"len::\",len(model_dict_list))\n",
    "        \n",
    "        if not self.fair_local_client:\n",
    "            \n",
    "            sum_acc_client=sum(acc_clients) /len(acc_clients)\n",
    "            Delta_t_C_i= abs(sum_acc_client-global_acc)\n",
    "            \n",
    "        else:            \n",
    "            Delta_t_C_i = abs(self.fair_global - self.fair_local_client) \n",
    "        \n",
    "        for client_id in range(len(self.selected_clients)):\n",
    "        \n",
    "            w_avg = copy.deepcopy(model_dict_list[client_id])\n",
    "            temp = copy.deepcopy(model_dict_list[client_id])\n",
    "            \n",
    "            for k in w_avg.keys():\n",
    "                for i in range(1, len(model_dict_list)):\n",
    "                    w_avg[k] += model_dict_list[i][k]\n",
    "                w_avg[k] = torch.div(w_avg[k], len(model_dict_list))\n",
    "                \n",
    "                w_avg[k]=temp[k]-(self.beta*(Delta_t_C_i-w_avg[k]))\n",
    "                \n",
    "            self.clients_weights.append(w_avg)\n",
    "                        \n",
    "        \n",
    "model = DeepNet()\n",
    "server = Serverbase(model)\n",
    "server.fairFed(num_rounds=2,local_epochs=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf995c8-5238-44f1-aa4d-e927101b0a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "993fb90f-e47d-4c3f-aecb-03cebadc3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_after, acc_after = server.server_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b650167b-329a-4095-a85a-51be5a44cf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140125f5-4685-4629-b8dd-e216d1f08829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f556f7-6e48-4dbe-b684-c013780c1cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59865b8-df6d-42ed-8d96-2b73ac6b387c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57cd4f2-d82a-4148-ac18-9b20ba771a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa0911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1f1ce-58da-4e7a-80c2-5829408ceb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add874c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae9ecf-93b9-4a8f-bb9e-3856dd4509c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d2fcfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c6611-5dbf-410d-8d2b-202dd32d1d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee055f-0649-4e88-8722-45ea21e3a4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d89e85-7d94-49c2-8bf2-de4684cb6d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a71f21-152d-497e-9e8e-b49f3c62be0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b61f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a42d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def FedAvg(w, clients):\n",
    "        #lenghth of data is clients\n",
    "#     print(clients)\n",
    "#     w_avg = copy.deepcopy(w[0])\n",
    "#     for k in w_avg.keys():\n",
    "#         for i in range(1, len(w)):\n",
    "#             tens = torch.mul(w[i][k], clients[i])\n",
    "#             w_avg[k] += tens\n",
    "#         w_avg[k] = torch.div(w_avg[k], sum(clients))\n",
    "#     return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b05a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def FedAvg(w):\n",
    "#     w_avg = copy.deepcopy(w[0])\n",
    "#     for k in w_avg.keys():\n",
    "#         for i in range(1, len(w)):\n",
    "#             w_avg[k] += w[i][k]\n",
    "#         w_avg[k] = torch.div(w_avg[k], len(w))\n",
    "#     return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aeb53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc3c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
