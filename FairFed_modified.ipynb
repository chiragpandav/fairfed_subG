{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae9b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import copy\n",
    "import glob\n",
    "import sys, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from folktables import ACSDataSource, ACSEmployment,ACSIncome\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "import torch, random, copy, os\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d23e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8550ad",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70374e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Running on CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "else:\n",
    "    # CUDA is not available\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6badffcd-029a-47e7-9d4e-40b52d32b39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4eb7f6d-5757-494b-8d6a-1192058aee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 14 : input shape\n",
    "        # 9-> we have 9 columns in data \n",
    "        self.layer1 = nn.Linear(9, 512)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(256, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e6ddc-37c5-4a04-ba53-7215bb513904",
   "metadata": {},
   "source": [
    "# assigning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3bb04f7-7bfb-48f1-abd5-77b8e1196396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create global model and client models\n",
    "temp_model = DeepNet()\n",
    "path=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model.pt\"\n",
    "torch.save(temp_model.state_dict(), path)\n",
    "\n",
    "# this has to be same in follwing code as well\n",
    "selected_clients=[0,1]\n",
    "\n",
    "for client_id in selected_clients:\n",
    "    client_model_path = f\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/client_{client_id}_model.pth\"\n",
    "    torch.save(temp_model.state_dict(), client_model_path)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f23068-2ef5-42e3-89ba-6311f656685b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a24c1cb2-bf5f-4164-a4d5-9251d6358acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Client:\n",
    "    def __init__(self):\n",
    "        self.client_id: int = None\n",
    "        self.valset: DataLoader = None\n",
    "        self.trainset: DataLoader = None\n",
    "        self.testset: DataLoader = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "        print(self.device)\n",
    "        self.model = DeepNet().to(self.device)\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "\n",
    "    def get_client_local_dataset(self):\n",
    "        \n",
    "        print(\"self.client_id:: \",self.client_id)\n",
    "\n",
    "        temp_path_data=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/client_df\"\n",
    "        \n",
    "        with open(temp_path_data+\"/clients_training.pkl\", \"rb\") as f:\n",
    "            self.trainset = pickle.load(f)\n",
    "            \n",
    "        with open(temp_path_data+\"/clients_validation.pkl\", \"rb\") as f:\n",
    "            self.valset = pickle.load(f)\n",
    "         \n",
    "        with open(temp_path_data+\"/clients_testing.pkl\", \"rb\") as f:\n",
    "            self.testset  = pickle.load(f)\n",
    "\n",
    "        self.trainset = self.trainset[self.client_id]\n",
    "        self.valset = self.valset[self.client_id]       \n",
    "        self.testset = self.testset[self.client_id]\n",
    "\n",
    "    def train(self, client_id: int, model_params: OrderedDict[str, torch.Tensor], num_epochs=5, learning_rate=0.001):\n",
    "        self.client_id = client_id\n",
    "        self.get_client_local_dataset()\n",
    "\n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Set the model to training mode\n",
    "            self.model.train()\n",
    "            print(\"epoch\",epoch)\n",
    "\n",
    "            for inputs, labels in self.trainset:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels.float())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Calculate and print the training accuracy for this epoch (optional)\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            size = 0\n",
    "            loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            predicted_labels = []\n",
    "            true_labels = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in self.valset:\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                    \n",
    "                    outputs = self.model(inputs)\n",
    "                    loss += self.criterion(outputs, labels)\n",
    "                    predicted = outputs > 0.5\n",
    "\n",
    "                    predicted_labels.extend(predicted.cpu().numpy())\n",
    "                    true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            loss = loss / len(self.valset)        \n",
    "            accuracy = correct / total\n",
    "            \n",
    "            # accuracy = 100 * correct / total\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Training Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        # Optionally, save the trained model parameters\n",
    "        client_model_path = f\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/client_{self.client_id}_model.pth\"\n",
    "        torch.save(self.model.state_dict(), client_model_path)\n",
    "\n",
    "        # Return the trained model parameters\n",
    "        return list(self.model.state_dict().values()), len(self.trainset.dataset),self.model.state_dict()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def client_evaluate(self, val=False):\n",
    "        \n",
    "        size = 0\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "\n",
    "        selected_clients=[0,1]\n",
    "        models_directory = \"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "\n",
    "        #dataset\n",
    "        if val==True:\n",
    "            dataset=self.valset\n",
    "            print(\"------validation starts--------\")\n",
    "        else:\n",
    "            dataset=self.testset\n",
    "            print(\"--------Testing starts-------\")\n",
    "                    \n",
    "        for client_id in selected_clients:\n",
    "            \n",
    "            print(\"=============================================\")\n",
    "            print(\" selected client for Testing:: \", client_id)\n",
    "            model_path = os.path.join(models_directory, f\"client_{client_id}_model.pth\")            \n",
    "        \n",
    "            self.model.load_state_dict(torch.load(model_path,map_location=self.device))\n",
    "\n",
    "            self.model.eval()\n",
    "\n",
    "            for inputs, targets in dataset:\n",
    "                \n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                loss += self.criterion(outputs, targets)\n",
    "                predicted = outputs > 0.5\n",
    "                \n",
    "                predicted_labels.extend(predicted.cpu().numpy())\n",
    "                true_labels.extend(targets.cpu().numpy())\n",
    "                \n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "                \n",
    "            \n",
    "            loss = loss / len(self.testset)\n",
    "            acc = correct / total\n",
    "            \n",
    "            # print(\"loss: %f\\n\" % (loss))\n",
    "            \n",
    "            print(f\" Accuracy: {acc:.2%}\")\n",
    "    #         print(predicted_labels,\" :: \",true_labels)\n",
    "            precision = precision_score(true_labels, predicted_labels,zero_division=0.0)\n",
    "            \n",
    "            recall = recall_score(true_labels, predicted_labels)\n",
    "    \n",
    "            print(f\"Precision: {precision:.2%}\")\n",
    "            print(f\"Recall: {recall:.2%}\")\n",
    "            \n",
    "            print(\"\\n\\n\")\n",
    "            \n",
    "        return loss, acc\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def server_evaluate(self):\n",
    "\n",
    "        print(\"Global Model testing Starts\")\n",
    "        print(\"kindly check the Path. Select it based on FedAvg Model\")\n",
    "        \n",
    "        path=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model.pt\"\n",
    "        path_2=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/global_model_2.pt\"\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(path_2,map_location=self.device))\n",
    "        self.model.eval()\n",
    "        size = 0\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        true_labels = []\n",
    "        \n",
    "        for inputs, targets in self.testset:\n",
    "            \n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "            \n",
    "            outputs = self.model(inputs)\n",
    "            loss += self.criterion(outputs, targets)\n",
    "            predicted = outputs > 0.5\n",
    "            \n",
    "#             print(\"predicted\",predicted)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(targets.cpu().numpy())\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "        \n",
    "        loss = loss / len(self.testset)\n",
    "        acc = correct / total\n",
    "        \n",
    "        # print(\"loss: %f\\n\" % (loss))\n",
    "        \n",
    "        print(f\"Global Testing Accuracy: {acc:.2%}\")\n",
    "        precision = precision_score(true_labels, predicted_labels,zero_division=0.0)\n",
    "        \n",
    "        recall = recall_score(true_labels, predicted_labels)\n",
    "        \n",
    "        print(f\"Global Precision: {precision:.2%}\")\n",
    "        print(f\"Global Recall: {recall:.2%}\")\n",
    "        \n",
    "        return loss, acc\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "199eb51c-d78b-44f1-86b0-e8b325ce899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "self.client_id::  0\n",
      "epoch 0\n",
      "Epoch 1/2, Training Accuracy: 0.72%\n",
      "epoch 1\n",
      "Epoch 2/2, Training Accuracy: 0.74%\n",
      "------validation starts--------\n",
      "=============================================\n",
      " selected client for Testing::  0\n",
      " Accuracy: 75.56%\n",
      "Precision: 63.39%\n",
      "Recall: 87.73%\n",
      "\n",
      "\n",
      "\n",
      "=============================================\n",
      " selected client for Testing::  1\n",
      " Accuracy: 75.87%\n",
      "Precision: 65.92%\n",
      "Recall: 78.40%\n",
      "\n",
      "\n",
      "\n",
      "cpu\n",
      "self.client_id::  1\n",
      "epoch 0\n",
      "Epoch 1/2, Training Accuracy: 0.61%\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████████████▌                                                       | 1/2 [00:02<00:02,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Training Accuracy: 0.67%\n",
      "------validation starts--------\n",
      "=============================================\n",
      " selected client for Testing::  0\n",
      " Accuracy: 73.74%\n",
      "Precision: 61.26%\n",
      "Recall: 87.57%\n",
      "\n",
      "\n",
      "\n",
      "=============================================\n",
      " selected client for Testing::  1\n",
      " Accuracy: 69.80%\n",
      "Precision: 62.66%\n",
      "Recall: 54.52%\n",
      "\n",
      "\n",
      "\n",
      "aggregate_parameters_FedFair\n",
      "cpu\n",
      "self.client_id::  0\n",
      "epoch 0\n",
      "Epoch 1/2, Training Accuracy: 0.72%\n",
      "epoch 1\n",
      "Epoch 2/2, Training Accuracy: 0.75%\n",
      "------validation starts--------\n",
      "=============================================\n",
      " selected client for Testing::  0\n",
      " Accuracy: 76.13%\n",
      "Precision: 68.50%\n",
      "Recall: 71.33%\n",
      "\n",
      "\n",
      "\n",
      "=============================================\n",
      " selected client for Testing::  1\n",
      " Accuracy: 71.15%\n",
      "Precision: 69.22%\n",
      "Recall: 46.33%\n",
      "\n",
      "\n",
      "\n",
      "cpu\n",
      "self.client_id::  1\n",
      "epoch 0\n",
      "Epoch 1/2, Training Accuracy: 0.61%\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Training Accuracy: 0.68%\n",
      "------validation starts--------\n",
      "=============================================\n",
      " selected client for Testing::  0\n",
      " Accuracy: 77.68%\n",
      "Precision: 71.19%\n",
      "Recall: 71.19%\n",
      "\n",
      "\n",
      "\n",
      "=============================================\n",
      " selected client for Testing::  1\n",
      " Accuracy: 73.52%\n",
      "Precision: 62.17%\n",
      "Recall: 80.79%\n",
      "\n",
      "\n",
      "\n",
      "aggregate_parameters_FedFair\n",
      "--------Testing starts-------\n",
      "=============================================\n",
      " selected client for Testing::  0\n",
      " Accuracy: 76.28%\n",
      "Precision: 70.88%\n",
      "Recall: 71.03%\n",
      "\n",
      "\n",
      "\n",
      "=============================================\n",
      " selected client for Testing::  1\n",
      " Accuracy: 73.61%\n",
      "Precision: 64.08%\n",
      "Recall: 80.31%\n",
      "\n",
      "\n",
      "\n",
      "Global Model testing Starts\n",
      "kindly check the Path. Select it based on FedAvg Model\n",
      "Global Testing Accuracy: 58.07%\n",
      "Global Precision: 49.31%\n",
      "Global Recall: 99.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Serverbase:\n",
    "    def __init__ (self,model):\n",
    "        self.model = model\n",
    "        self.global_model=model\n",
    "        self.num_rounds=5\n",
    "        self.local_epoch=10\n",
    "        self.optimizer=2\n",
    "        self.lr=0.001\n",
    "        self.beta=0.2\n",
    "        self.batch_size=32\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "        self.client_id_indices, self.client_num_in_total = [0,1], 2 \n",
    "        \n",
    "        self.updated_params_cache = []\n",
    "        self.weights_cache = []\n",
    "        self.model_dict = []\n",
    "        \n",
    "        self.global_params_dict: OrderedDict[str : torch.Tensor] = None\n",
    "\n",
    "        self.backbone=DeepNet\n",
    "        _dummy_model = self.backbone()\n",
    "        self.global_params_dict = OrderedDict(_dummy_model.state_dict())\n",
    "\n",
    "        self.temp_dir=\"/home/chiragapandav/Downloads/Hiwi/Improving-Fairness-via-Federated-Learning/FedFB/models/\"\n",
    "\n",
    "        self.fair_global_t_step=[]\n",
    "        self.fair_local_client=[]   \n",
    "        self.acc_clients=[]\n",
    "        \n",
    "        \n",
    "    def fairFed(self, num_rounds = 2, local_epochs = 2, learning_rate = 0.005, beta = 0.3, alpha = 0.1, optimizer = 'adam'):\n",
    "        \n",
    "        for round_ in tqdm(range(num_rounds)):\n",
    "  \n",
    "            selected_clients=[0,1]\n",
    "            \n",
    "            for client_id in selected_clients:\n",
    "                client = Client()\n",
    "\n",
    "                # weight is length of dataset\n",
    "                updated_params_list, weight, model_dict_list = client.train(client_id, self.model.state_dict(), num_epochs=local_epochs, learning_rate=learning_rate)\n",
    "                loss_client, acc_client = client.client_evaluate(val=True)\n",
    "                \n",
    "                # store it for SecAgg\n",
    "                self.updated_params_cache.append(updated_params_list)\n",
    "                self.weights_cache.append(weight)\n",
    "                self.model_dict.append(model_dict_list)\n",
    "                \n",
    "                #store it for FairFed agg\n",
    "                self.acc_clients.append(acc_client)\n",
    "\n",
    "            \n",
    "            # self.aggregate_parameters_FedAvg(self.updated_params_cache, self.weights_cache)\n",
    "            self.aggregate_parameters_FedAvg_updated(self.model_dict)\n",
    "            self.aggregate_parameters_FedFair(self.updated_params_cache, self.weights_cache,self.acc_clients)\n",
    "                \n",
    "            torch.save(self.global_params_dict, os.path.join(self.temp_dir, \"global_model.pt\"),)\n",
    "\n",
    "        # Test Clients Models and Global Model\n",
    "        loss_client, acc_client = client.client_evaluate()\n",
    "        loss_server, acc_server = client.server_evaluate()\n",
    "    \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def aggregate_parameters_FedAvg(self, updated_params_cache, weights_cache):\n",
    "        print(\"weights_cache::\",weights_cache)\n",
    "        weight_sum = sum(weights_cache)  \n",
    "        \n",
    "        weights = torch.tensor(weights_cache, device=self.device) / weight_sum\n",
    "        \n",
    "        aggregated_params = []\n",
    "\n",
    "        for params in zip(*updated_params_cache):\n",
    "            aggregated_params.append(\n",
    "                torch.sum(weights * torch.stack(params, dim=-1), dim=-1)\n",
    "            )\n",
    "\n",
    "        self.global_params_dict = OrderedDict(\n",
    "            zip(self.global_params_dict.keys(), aggregated_params)\n",
    "        )\n",
    "\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def aggregate_parameters_FedAvg_updated(self, model_dict_list):        \n",
    "        w_avg = copy.deepcopy(model_dict_list[0])\n",
    "        for k in w_avg.keys():\n",
    "            for i in range(1, len(model_dict_list)):\n",
    "                w_avg[k] += model_dict_list[i][k]\n",
    "            w_avg[k] = torch.div(w_avg[k], len(model_dict_list))\n",
    "\n",
    "        self.global_params_dict = OrderedDict(\n",
    "            zip(self.global_params_dict.keys(), w_avg)\n",
    "        )\n",
    "        \n",
    "        self.global_model.load_state_dict(w_avg)\n",
    "        torch.save(self.global_model.state_dict(), os.path.join(self.temp_dir, \"global_model_2.pt\"),)\n",
    "            \n",
    "\n",
    "    # def global_acc(self,acc_clients):\n",
    "    #     #global model has to be there \n",
    "        \n",
    "    #     sum_acc_client=sum(acc_clients)\n",
    "\n",
    "        \n",
    "    # # def calc_fairness(self,):\n",
    "        \n",
    "    # @torch.no_grad()\n",
    "    def aggregate_parameters_FedFair (self, updated_params_cache,weights_cache,acc_clients):\n",
    "        print(\"aggregate_parameters_FedFair\")\n",
    "        # if not fair_local_client:\n",
    "        #     global_acc(acc_clients)\n",
    "        # else:\n",
    "        #     Delta_t_C_i = abs(fair_global_t_step - fair_local_client) \n",
    "        \n",
    "model = DeepNet()\n",
    "server = Serverbase(model)\n",
    "server.fairFed(num_rounds=2,local_epochs=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf995c8-5238-44f1-aa4d-e927101b0a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "993fb90f-e47d-4c3f-aecb-03cebadc3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_after, acc_after = server.server_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b650167b-329a-4095-a85a-51be5a44cf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140125f5-4685-4629-b8dd-e216d1f08829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f556f7-6e48-4dbe-b684-c013780c1cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59865b8-df6d-42ed-8d96-2b73ac6b387c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57cd4f2-d82a-4148-ac18-9b20ba771a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa0911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1f1ce-58da-4e7a-80c2-5829408ceb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add874c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae9ecf-93b9-4a8f-bb9e-3856dd4509c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d2fcfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c6611-5dbf-410d-8d2b-202dd32d1d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee055f-0649-4e88-8722-45ea21e3a4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d89e85-7d94-49c2-8bf2-de4684cb6d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a71f21-152d-497e-9e8e-b49f3c62be0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b61f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a42d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def FedAvg(w, clients):\n",
    "        #lenghth of data is clients\n",
    "#     print(clients)\n",
    "#     w_avg = copy.deepcopy(w[0])\n",
    "#     for k in w_avg.keys():\n",
    "#         for i in range(1, len(w)):\n",
    "#             tens = torch.mul(w[i][k], clients[i])\n",
    "#             w_avg[k] += tens\n",
    "#         w_avg[k] = torch.div(w_avg[k], sum(clients))\n",
    "#     return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b05a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def FedAvg(w):\n",
    "#     w_avg = copy.deepcopy(w[0])\n",
    "#     for k in w_avg.keys():\n",
    "#         for i in range(1, len(w)):\n",
    "#             w_avg[k] += w[i][k]\n",
    "#         w_avg[k] = torch.div(w_avg[k], len(w))\n",
    "#     return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aeb53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc3c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
